{"title": "LSTM based Conversation Models", "abstract": "In this paper, we present a conversational model that incorporates both context and participant role for two-party conversations. Different architectures are explored for integrating participant role and context information into a Long Short-term Memory (LSTM) language model. The conversational model can function as a language model or a language generation model. Experiments on the Ubuntu Dialog Corpus show that our model can capture multiple turn interaction between participants. The proposed method outperforms a traditional LSTM model as measured by language model perplexity and response ranking. Generated responses show characteristic differences between the two participant roles.", "year": 2016, "ssId": "72ae4bba9aaa30dfba45f6e7e076952a76e2d751", "arXivId": "1603.09457", "link": "https://arxiv.org/pdf/1603.09457.pdf", "openAccess": true, "authors": ["Yi Luan", "Yangfeng Ji", "Mari Ostendorf"]}