{"title": "CM3: A Causal Masked Multimodal Model of the Internet", "abstract": "We introduce CM3, a family of causally masked generative models trained over a large corpus of structured multi-modal documents that can contain both text and image tokens. Our new causally masked approach generates tokens left to right while also masking out a small number of long token spans that are generated at the end of the string, instead of their original positions. The casual masking object provides a type of hybrid of the more common causal and masked language models, by enabling full generative modeling while also providing bidirectional context when generating the masked spans. We train causally masked languageimage models on large-scale web and Wikipedia articles, where each document contains all of the text, hypertext markup, hyperlinks, and image tokens (from a VQVAE-GAN), provided in the order they appear in the original HTML source (before masking). The resulting CM3 models can generate rich structured, multimodal outputs while conditioning on arbitrary masked document contexts, and thereby implicitly learn a wide range of text, image, and cross modal tasks. They can be prompted to recover, in a zero-shot fashion, the functionality of models such as DALL-E, GENRE, and HTLM (Ramesh et al., 2021; De Cao et al., 2020; Aghajanyan et al., 2021). We set the new state-of-the-art in zero-shot summarization, entity linking, and entity disambiguation while maintaining competitive performance in the fine-tuning setting. We can generate images unconditionally, conditioned on text (like DALL-E) and do captioning all in a zero-shot setting with a single model.", "year": 2022, "ssId": "c783e1fb3ce8514f981925ee590c00884660ee4e", "arXivId": "2201.07520", "link": "https://arxiv.org/pdf/2201.07520.pdf", "openAccess": true, "authors": ["Armen Aghajanyan", "Bernie Huang", "Candace Ross", "Vladimir Karpukhin", "Hu Xu", "Naman Goyal", "Dmytro Okhonko", "Mandar Joshi", "Gargi Ghosh", "M. Lewis", "Luke Zettlemoyer"]}