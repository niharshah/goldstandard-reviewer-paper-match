arXiv:2009.11829v2 [cs.LG] 6 Oct 2020

Semi-supervised sequence classiï¬cation through change point detection
Nauman Ahad, Mark A. Davenport
October 7, 2020
Abstract
Sequential sensor data is generated in a wide variety of practical applications. A fundamental challenge involves learning eï¬€ective classiï¬ers for such sequential data. While deep learning has led to impressive performance gains in recent years in domains such as speech, this has relied on the availability of large datasets of sequences with high-quality labels. In many applications, however, the associated class labels are often extremely limited, with precise labelling/segmentation being too expensive to perform at a high volume. However, large amounts of unlabeled data may still be available. In this paper we propose a novel framework for semi-supervised learning in such contexts. In an unsupervised manner, change point detection methods can be used to identify points within a sequence corresponding to likely class changes. We show that change points provide examples of similar/dissimilar pairs of sequences which, when coupled with labeled, can be used in a semi-supervised classiï¬cation setting. Leveraging the change points and labeled data, we form examples of similar/dissimilar sequences to train a neural network to learn improved representations for classiï¬cation. We provide extensive synthetic simulations and show that the learned representations are superior to those learned through an autoencoder and obtain improved results on both simulated and real-world human activity recognition datasets.
1 Introduction
As devices ranging from smart watches to smart toasters are equipped with ever more sensors, machine learning problems involving sequential data are becoming increasingly ubiquitous. Sleep tracking, activity recognition and characterization, and machine health monitoring are just a few applications where machine learning can be applied to sequential data. In recent years, deep networks have been widely used for such tasks as these networks are able automatically learn suitable representations, helping them achieve state-ofthe-art performance [21]. However, such methods typically require large, accurately labeled training datasets in order to obtain these results. Unfortunately, especially in the context of sequential data, it is often the case that despite the availability of huge amounts of unlabeled data, labeled data is often scarce and expensive to obtain.
In such settings, semi-supervised techniques can provide signiï¬cant advantages over traditional supervised techniques. Over the past decade, there have been great advances in semi-supervised learning methods. Impressive classiï¬cation performance â€“ particularly in the ï¬elds of computer vision â€“ has been achieved by using large amounts of unlabeled data on top of limited labeled data. However, despite these advances, there has been comparatively much less work on semi-supervised classiï¬cation of sequential data.
A key intuition that most semi-supervised learning methods share is that the data should (in the right representation) exhibit some kind of clustering, where diï¬€erent classes correspond to diï¬€erent clusters. In the context of sequential data, the equivalent assumption is that data segments within a sequence corresponding to diï¬€erent classes should map to distinct clusters. In the context of sequential data, the challenge is that exploiting this clustering would require the sequence to be appropriately segmented, but segment boundaries are generally unknown a priori. If the start/end points of each segment were actually known, it would be much easier to apply traditional semi-supervised learning methods.
The authors are with the School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, 30332 USA (emails: nahad3@gatech.edu, mdav@gatech.edu)
1

In this paper, we show that standard (unsupervised) change point detection algorithms provide a natural and useful approach to segmenting an unlabeled sequence so that it can be more easily exploited in a semisupervised context. Speciï¬cally, change point-detection algorithms aim to identify instances in a sequence where the data distribution changes (indicating an underlying class change). We show that the resulting change points can be leveraged to learn improved representations for semi-supervised learning.
We propose a novel framework for semi-supervised sequential classiï¬cation using change point detection. We ï¬rst apply unsupervised change point detection to the unlabeled data. We assume that segments between two change points belong to the same distribution and should be classiï¬ed similarly, whereas adjacent segments which are on opposite sides of a change point belong to diï¬€erent distributions and should be classiï¬ed diï¬€erently. These similar/dissimilar pairs, derived from change points, can then be combined with similar/dissimilar pairs derived from labeled data. We use these combined similar/dissimilar constraints to train a neural network that preserves similarity/dissimilarity. The learned representation can then be fed into a multilayer feedforward network trained via existing semi-supervised techniques.
We show that this approach leads to improved results compared to sequential auto-encoders in a semisupervised setting. We show that even if the ï¬nal classiï¬er is trained using standard supervised techniques that ignore the unlabeled data, the learned representations (which utilize both label and unlabeled data pairs) result in competitive performance, indicating the value of incorporating change points to learning improved representations. The proposed method method is completely agnostic with respect to the change point detection procedure to be used â€“ any detection procedure can be used as long as it does well in detecting changes.
Our main contribution is to show that pairwise information generated via change points helps neural networks achieve improved classiï¬cation results in settings with limited labeled data. This, to the best of our knowledge, is the ï¬rst work to recognize the utility of change points within the context of semisupervised sequence classiï¬cation. The proposed method should not be considered a substitute for existing semi-supervised methods, but should be taken as a complementary procedure that produces representations which are better suited for existing semi-supervised methods.
2 Related work
The fundamental idea of semi-supervised learning is that unlabeled data contains useful information that can be leveraged to more eï¬ƒciently learn from a small subset of labeled data. For example, in the context of classiï¬cation, an intuitive justiï¬cation for why this might be possible might involve an implicit expectation that instances belonging to diï¬€erent classes will map to diï¬€erent clusters. More concretely, most semisupervised approaches make assumptions on the data such as: that instances corresponding to diï¬€erent classes lie on diï¬€erent submanifolds, that class boundaries are smooth, or that class boundaries pass through regions of low data density [19].
Perhaps the simplest semi-supervised learning method is to use transductive methods to learn a classiï¬er on the unlabeled data and then assign â€œpseudo labelsâ€ to some or all of the unlabeled data, which can be used together with the labeled data to retrain the classiï¬er. Transductive SVMs and graphical label propagation are examples of such methods [11, 26]. See [25] for a survey of such methods. However, such self-training semi-supervised methods struggle when the initial model trained from limited labels is poor.
A more common approach to semi-supervised learning is to employ methods that try to learn class boundaries that are smooth or pass through areas of low data density [17]. Entropy regularization can be used to encourage class boundaries to pass through low density regions [8]. Consistency-based methods such as denoising autoencoders, ladder networks [18] and the Ï€ method [14] attempt to learn smooth class boundaries by augmenting the data. Speciï¬cally, unlabeled instances can be perturbed by adding noise, and while both the original and perturbed instances are unlabeled, we can ask that they both be assigned the same class. This approach is particularly eï¬€ective in computer vision tasks, where rather than using only noise perturbations, we can exploit class-preserving augmentations such as rotation, mirroring, and other transformations [3]. By enforcing the classiï¬er to produce the same labels for original and transformed images, decision boundaries are encouraged to be smooth, leading to good generalization.
Unfortunately, due to a lack of natural segmentation and the diï¬ƒculty of deï¬ning class-preserving transformations, there has been comparatively little work on semi-supervised classiï¬cation of sequences. Most prior
2

ğ‘‹!"

ğ‘‹!#

ğ‘‹$"

ğ‘‹$#

Changepoint at ğ‘–

ğ‘– âˆ’ 2ğ‘ 

ğ‘–âˆ’ğ‘ 

ğ‘–

ğ‘–+ğ‘ 

ğ‘– + 2ğ‘  ğ‘†ğ‘’ğ‘ ğ¿ğ‘’ğ‘›ğ‘”ğ‘¡â„

Similar Pairs
(ğ‘‹!", ğ‘‹!#) (ğ‘‹$", ğ‘‹$#)

Dissimilar Pairs
(ğ‘‹!#, ğ‘‹$") (ğ‘‹!", ğ‘‹$#)

Figure 1: Using change points to generate similar and dissimilar pairs of size s.

work (e.g., [5, 18] ) use sequential autoencoders (or their variants) as a consistency-based method to learn representations that lead to improved classiï¬cation performance. Such autoencoders have been exploited successfully in the context of semi-supervised classiï¬cation for human activity recognition [23]. However, while such consistency-based approaches do encourage smooth class boundaries, they do not necessarily promote the kind of clustering behavior that we need in cases where there are extremely few labels available.
An alternative approach that more explicitly separates diï¬€erent classes involves learning representations that directly incorporate pairwise similarity information about diï¬€erent instances. One example of this approach is metric learning â€“ as an early example, [22] showed that improved classiï¬cation could be achieved by learning a Mahalanobis distance using pairwise constraints based on class membership. The learned metric leads to a representation in which diï¬€erent classes map to diï¬€erent clusters. A similar approach learns a more general non-linear metric to encourage the formation of clusters while adhering to the provided pairwise constraints [1]. Neural networks such as Siamese [12] and Triplet networks also learn representations from available similar/dissimilar pairs. In [10] it was shown that such similar/dissimilar pairs (obtained from labeled data) can be used for clustering data where each cluster belongs to a diï¬€erent class in the dataset.
Our approach is similar in spirit to that of [10]. While this prior work used pairwise similarity constraints derived from labeled images to learn clustered representations, our goal is to apply this idea in the semisupervised context. At the core of our approach is the observation that pairwise similarity constraints on sequential data can be derived through unsupervised methods. Speciï¬cally, change point detection can be used to identify points within a sequence corresponding to distribution shifts, which can then be used to obtain pairwise similarity constraints. When the availability of labeled data is limited, this can be a valuable source of additional information.
3 Proposed method
3.1 Change point detection
Given a sequence X : x1, . . . , xN of N vectors xi P RD, the ï¬rst step in our procedure is to detect all change points within X in an unsupervised way. Note that this is a diï¬€erent problem than quickest change detection, where only a single change point is to be detected in the fastest possible manner. To detect a change at a point i in the sequence, two consecutive length-w windows (Xpi and Xfi ) are ï¬rst formed:
Xpi â€œ xiÂ´1, xiÂ´2...xiÂ´w Xfi â€œ xi, xi`1...xi`w.
A change statistic, mi, is then computed via some function that quantiï¬es the diï¬€erence between the distributions generating Xpi and Xfi . If mi is greater than a speciï¬ed constant Ï„ , a change point is detected at the point i.
As one example, many change point detection procedures assume a parametric form on the distributions generating Xpi and Xfi . In this case, the distribution parameters (Î¸Ë†pi and Î¸Ë†fi ) can be estimated from Xpi and
3

Sequence instance distribution

ğ‘“! ğ‘¥%

2< l a t e x i t s h a 1 _ b a s e 6 4 = " 5 4 w f / x I t x K / Q 6 G h W 5 7 s 0 N 7 5 7 z 2 Q = " > A A A B 8 3 i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e x K Q L 0 F 4 8 F j B P O A 7 B p m J 5 1 k y O z s M j M r h J D f 8 O J B E a / + j D f / x k m y B 0 0 s a C i q u u n u C h P B t X H d b y e 3 t r 6 x u Z X f L u z s 7 u 0 f F A + P m j p O F c M G i 0 W s 2 i H V K L j E h u F G Y D t R S K N Q Y C s c 1 W Z + 6 w m V 5 r F 8 M O M E g 4 g O J O 9 z R o 2 V f J 9 L 4 t + i M P S x 1 i 2 W 3 L I 7 B 1 k l X k Z K k K H e L X 7 5 v Z i l E U r D B N W 6 4 7 m J C S Z U G c 4 E T g t + q j G h b E Q H 2 L F U 0 g h 1 M J n f P C V n V u m R f q x s S U P m 6 u + J C Y 2 0 H k e h 7 Y y o G e p l b y b + 5 3 V S 0 7 8 K J l w m q U H J F o v 6 q S A m J r M A S I 8 r Z E a M L a F M c X s r Y U O q K D M 2 p o I N w V t + e Z U 0 L 8 p e p X x 9 X y l V b 7 I 4 8 n A C p 3 A O H l x C F e 6 g D g 1 g k M A z v M K b k z o v z r v z s W j N O d n M M f y B 8 / k D S g C R O A = = < / l a t e x i t >

C

ğ‘š x ğ¶ linear layer

ğ‘“! ğ‘¥"
softmax

Mean Empirical distribution = ğ‘“!(ğ‘‹)

ğ‘“! ğ‘¥#

ğ‘“! ğ‘¥$

softmax

softmax

Layer k

Filter slides

Diluted 1D Conv Filter

Channel 1

Channel m

Layer 1

Filter slides

1D Conv Filter

1D Conv Filter Channel 1

Channel m

Input sub-sequence ğ‘‹

ğ‘¥"

ğ‘¥#

ğ‘¥$

Figure 2: Neural network diagram (fÎ¸) for learning representations.

Xfi via, e.g., maximum likelihood estimation. Given these parameter estimates, a symmetrical KL-divergence can be used to quantify the diï¬€erence between the distributions [16]:

mi â€œ KLpÎ¸Ë†pi , Î¸Ë†fi q ` KLpÎ¸Ë†fi , Î¸Ë†pi q.

(1)

More commonly in practice, the underlying distributions generating the sequence are unknown. In this
case, non-parametric techniques can be used to estimate the diï¬€erence between the distributions of Xpi and Xfi . One such approach uses the maximum mean discrepancy (MMD) as a change statistic [9]. The MMD has been used to identify change points in [15] and [4]. The MMD statistic is given below, where
Kai,Â´b :â€œ kpxi`a, xiÂ´bq represents a kernel-based measure of the similarity between xi`a and xiÂ´b:

mi â€œ MMDpXfi , Xpi q

1

w
Ã¿

i

i

1

w
Ã¿

i

â€œ `wË˜

2pKa,b ` KÂ´a,Â´bq ` w2

2Ka,Â´b.

2 a,bâ€œ1

a,bâ€œ1

aâ€°b

Throughout this paper, MMD with a radial basis function kernel is used to detect change points unless otherwise speciï¬ed. However, we again emphasize that any change point detection method can be used as long as it performs well in identifying changes points.
The labeled data can be used to set the change point detection threshold Ï„ and the window size w to balance between false and missed change points. While we simply ï¬x these parameters in advance using labeled data, these could also be considered as tuning parameters whose values can be set based on performance on a hold-out validation dataset.

3.2 Pairwise constraints via change point detection
Equipped with the detected change points, similar and dissimilar pairs of sub-sequences can be obtained in an unsupervised manner as shown in Figure 1. The idea is to form four consecutive non-overlapping sub-sequences. The ï¬rst two sub-sequences pXp1, Xp2q both occur before the change point. Since the change point detection algorithm did not determine that there was a change point in the combined segment of pXp1, Xp2q, we assume these two segments are generated by the same distribution and should be classiï¬ed

4

similarly. Similarly, the last two sub-sequences pXf1, Xf2q both occur after the change point and are also taken as a similar pair. In contrast, the segments on opposite sides of the change point have been identiï¬ed as having diï¬€erent underlying distributions. In order to lead to a balanced distribution of similar/dissimilar pairs, we only use the constraints that pXf1, Xp2q and pXf2, Xp1q should be classiï¬ed diï¬€erently. Each of the subsequences above is chosen to be of a ï¬xed length s (determined by the spacing between change points).

3.3 Clustered representations via pairwise constraints
Using the approach described above, we can obtain similarity constraints from the unlabeled data. We can also obtain such constraints from labeled data via the assumption that sub-sequences corresponding to the same (diï¬€erent) class labels are similar (dissimilar) respectively. We can represent these as a set PS consisting of sub-sequence pairs pX1, X2q that are similar and a set PD of dissimilar pairs. For compactness, we use the notation P â€œ pX1, X2q to refer to a sub-sequence pair belonging to PS or PD.
These sub-sequences are then fed into a 1D temporal convolutional neural network [2], as illustrated in Figure 2. The neural network consists of 6 convolutional layers (or 3 temporal blocks as deï¬ned by [2]) followed by 1 linear layer. We use a RELU activation function after every convolutional layer. We choose this architecture because the dilated ï¬lter structure leads to improved performance at classifying time series while being less computationally expensive than recurrent networks such as RNNs and LSTMs, although our framework could also easily accommodate either of these alternate network architectures.
Each instance xi, in the input sub-sequence X, is passed through the neural network where the ï¬nal linear layer transforms the output from the last convolutional layer into RC, where C is the number of classes. A softmax function is then applied to obtain the empirical distribution fÎ¸pxiq for each instance xi. For a length-N sequence X, we deï¬ne the mean empirical distribution as:

1

N
Ã¿

fÄ Î¸pXq â€œ N fÎ¸pxiq.

iâ€œ1

We then compute the KL divergence between the mean empirical distributions for each sub-sequence within

a pair P â€œ pX1, X2q. Our loss function is constructed applying a hinge loss (with margin parameter Ï) to

this KL divergence:

# KLpfÄ Î¸pX1q, fÄ Î¸pX2qq
hÎ¸pP q â€œ Ï Â´ KLpfÄ Î¸pX1q, fÄ Î¸pX2qq

P P XS, P P XD.

The network is then trained according to the loss function:

1Ã¿

Î»R Ã¿

LRpÎ¸q â€œ

hÎ¸pP q `

hÎ¸pP q.

|PL| P PPL

|PU | P PPU

Here, PL and PU denote the sets of sub-sequence pairs in PS Y PD formed from the labeled and unlabeled data, respectively, and Î»r is a tuning parameter which controls the inï¬‚uence of the unsupervised part of the loss function.

3.4 Training a classiï¬er
Once trained, the network fÎ¸ is ï¬xed. The mean empirical distribution for an input sub-sequence X, fÄ Î¸pXq, can then be used as a representation of X that can serve as input to classiï¬er network fÏˆ. We use a 2-layer feedforward neural network followed by a softmax function to obtain a distribution over the diï¬€erent classes. Labeled as well as unlabeled sub-sequences (which correspond to the generated pairs from change points) are passed through this classiï¬cation network. Since the learned representations encourage unlabeled data points to cluster around provided labeled data points, known semi-supervised methods can be also used to incorporate unlabeled data while training fÏˆ. We use entropy regularization [8] to exploit the unlabeled data by encouraging the classiï¬er boundary to pass through low density regions.
The training data is comprised of two sets: XL and XU . Each element of XL consists of a pair pX, Y q, where X denotes a sequence x1, . . . , xN of vectors in RD and Y denotes a one-hot encoding of the class label for X (and is hence in RC where C is the number of classes). Each element of XU consists of a sub-sequence

5

X identiï¬ed by the change point detection step (i.e., the individual sub-sequences in the set PU ). The loss function that we use to train fÏˆ is given by:

1 LCpÏˆq â€œ

Ã¿

Î»C Ã¿

LCEpX, Y q `

LNE pX q.

|XL| pX,Y qPXL

|XU | XPXU

Here, Î»C is a tuning parameter, LCE is the cross entropy loss, and LNE is the negative entropy loss:

C

Ã¿

`

Ë˜

LCEpX, Y q â€œ Â´ Yc log fÏˆ fÄ Î¸pXq c

câ€œ1

C

Ã¿`

Ë˜

`

Ë˜

LNEpXq â€œ Â´ fÏˆ fÄ Î¸ pXq c log fÏˆ fÄ Î¸pXq c .

câ€œ1

Above, fÏˆ represents the output of the feedforward classiï¬cation network which ends with a softmax distribution over C classes. The input to fÏˆ is the mean empirical representations learned by network fÎ¸ for input sequence X. The negative entropy loss encourages the network fÏˆ to produce low entropy empirical class distributions for unlabeled data. This encourages unlabeled data to be mapped to a distribution that concentrates on a single class, pushing the classiï¬er boundary to fÏˆ towards low-density regions.
A summary of our overall approach to semi-supervised learning via change point detection is given in Algorithm 1.

Algorithm 1 SSL via change point detection
Inputs: Unlabeled sequence X, labeled sequences tXl, Yl}, CP detection parameters Ï„, w,
Output: Trained networks: fÎ¸, fÏˆ
Init: Add similar/dissimilar pairs from tXlu to PS, PD
for i â€œ 1 to lengthpXq do Form windows: Xpi , Xfi mi â€œ MMDpXpi , Xfi q if mi Ä… Ï„ then Form two segments before CP: Xpi1, Xpi2 Form two segments after CP: Xfi 1, Xfi 2 Add pairs pXpi1, Xpi2q and pXfi 1, Xfi 2q to PS Add pairs (Xfi 1, Xpi2) and pXfi 2, Xpi1q to PD
for j â€œ 1 to num epochs do Train network fÎ¸ by optimizing loss LR
for j â€œ 1 to num epochs do Train network fÏˆ by optimizing loss LC

4 Experiments
4.1 Baselines
All of the following baselines use the same representation network fÎ¸ and classiï¬cation network fÏˆ architectures.

Supervised

In the supervised setting, only the labeled sequence is passed through through both the representation fÎ¸ and classiï¬er networks fÏˆ. We train the two networks in an end-to-end manner by minimizing:

1Ã¿

LSpÎ¸, Ïˆq â€œ |XL|

LCEpX, Y q.

pX,Y qPXL

6

Unlabelled points Class 1 Class 2 Class 3 Class 4

Class 1 Class 2 Class 3 Class 4

(a) Autoencoder

(b) True labels: Autoencoder

Pairs from CP Class 1 Class 2 Class 3 Class 4
(c) SSL-CP

Class 1 Class 2 Class 3 Class 4
(d) True labels: SSL-CP

Figure 3: T-SNE visualizations for the representations learned by the representation network (fÎ¸) on the Mackay-Glass example when 5 labels are provided from each class. Figure 3(a) shows representations learned by an autoencoder using both labeled and unlabeled data. It can be seen in 3(b) that diï¬€erent classes overlap in this representation. Figure 3(c) show the representations learned by SSL-CP, which are clustered and non-overlapping. This leads to improved classiï¬cation when limited labels are provided. True labels for these representations are shown in Figure 3(d).

Denoising autoencoder

A denoising autoencoder [5] or its variants such as the ladder network (where the reconstruction error for
intermediate layers is also minimized) [23] are often employed for semi-supervised learning with sequential
data. Since it has been previously shown that the performance gap between these approaches is marginal
[23] â€“ which we have observed as well â€“ we focus only on the autoencoder as a baseline. In this approach,
for every X P XU , we also consider a perturbed version Xp produced by adding noise to X. Both X and Xp are passed through an encoder network fÎ¸ to obtain embeddings which are used by a decoder network fÎ¸1 to reconstruct the unlabeled data. A reconstruction loss of the form CpXq â€œ }X Â´ fÎ¸1 pfÎ¸pXpqq}2 is incorporated into the loss function to exploit the unlabeled data. The labeled data is ï¬rst passed through the encoder
network fÎ¸ to obtain embeddings, which are then fed into a classiï¬er network fÏˆ. We train the two networks in an end-to-end manner by minimizing:

1 LAEpÎ¸, Ïˆq â€œ

Ã¿

Î»C Ã¿

LCEpX, Y q `

C pX q.

|XL| pX,Y qPXL

|XU | XPXU

Table 1: Classiï¬er performance for mean, variance change

Method
Supervised Autoencoder SSL-CP SSL-CP (ER)

10 labels
0.90 Ë˜0.02 0.87 Ë˜0.03 0.99 Ë˜ 0.01 0.99 Ë˜ 0.01

30 labels
0.98 Ë˜0.01 0.99 Ë˜0.01 0.99 Ë˜ 0.01 0.99 Ë˜ 0.01

4.2 Synthetic experiments
In all of the results below, we use the mean F1 score (unweighted) as an evaluation metric. In all synthetic simulations, we split the data in a 70/30 ratio where we use the larger split for training and the smaller split as a test dataset. We further split the training data in a ratio of 10/60/30. We use the smallest of these splits to obtain labeled data, the largest as unlabeled data for the semi-supervised setting, and the last split for validation. We use a small sub-sequence (comprising of 20 segments) in the unlabeled split to tune the parameters for change point detection. In our results, SSL-CP denotes our approach to semi-supervised learning via change points, but without the inclusion of the negative entropy term in the loss function. SSL-CP (ER) denotes our approach when including this entropy regularization term.
7

Mackay-Glass switching sequence

2

Class 1

Class 2

Class 3

1.5

Class 4

Sequence values

1

0.5

0 1000 2000 3000 4000 5000 6000 Sequence length
Figure 4: Example switching Mackay-Glass sequence.

Table 2: Mackay-Glass: Classiï¬er performance for diï¬€erent number of labeled examples

Model
Supervised Autoencoder SSL-CP SSL-CP (ER)

20 labels
0.55 Ë˜0.07 0.73 Ë˜ 0.04 0.96 Ë˜0.02 0.99 Ë˜ 0.02

30 labels
0.86 Ë˜ 0.04 0.90 Ë˜ 0.02 0.98 Ë˜ 0.01 0.99 Ë˜ 0.01

60 labels
0.95 Ë˜ 0.02 0.98 Ë˜ 0.01 0.99 Ë˜ 0.01 0.99 Ë˜ 0.01

Changing mean and variance
This example consists of data generated by a univariate normal distribution that switches its parameters pÂµ, Ïƒ2q every 500 samples. We use 1500 such random switches to produce a sequence of data with ï¬ve classes, correspond to the parameter settings tp2, 0.1q, p4, 0.1q, p4, 0.7q, p10, 0.1q, p0, 0.1qu. We use the symmetrical KL divergence from (1) to detect change points in the unlabeled data. This is a simple change point detection problem where we detect all change points correctly. We use small sub-sequences of length 20 as labeled and unlabeled data. and we show the resulting performance in Table 1. This is a relatively simple sequence classiï¬cation problem as it requires merely learning that the mean and variance determine class membership. Both the supervised and autoencoder baselines do reasonably well. However, classes 2 and 3 have the same mean but diï¬€erent variance, and both baselines struggle compared to SSL-CP in separating these classes when only 10 labels are provided.

Mackay-Glass equation The Mackay-Glass equation [7] is a non linear time delay diï¬€erential equation deï¬ned as

dpxptqq

Î²xptqpt Â´ Ï„ q

dptq â€œ Â´0.1xptq ` 1 ` xpt Â´ Ï„ q10 .

In a manner similar to [13], we generate a sequence by randomly switching between parameters pÎ², Ï„ q P tp0.2, 8q, p0.18, 16q, p0.2, 22q, p0.22, 30qu every 1400 samples. We deï¬ne class membership according to the parameter settings of each segment. We generated 2000 such segments and added N p0, 0.1q noise to the entire sequence. A small sub-sequence is shown in Figure 4. We obtained pairs of sequences of size 100 using change points detected on the unlabeled dataset, where almost all true change points were detected correctly. There were about 4000 such pairs. We obtained 8100 non-overlapping windows of size 100 from the unlabeled-split for use by the autoencoder. Labeled data is also formed using non-overlapping windows of size 100 were used as labels. Table 2 shows results for diï¬€erent numbers of provided labels. We see that SSL-CP approach signiï¬cantly outperforms the baselines. The representations learned by the autoencoder and SSLCP are visualized in Figure 3, which illustrates that the autoencoder does not perform as well because it fails to learn representations that exhibit suï¬ƒcient clustering. The inï¬‚uence of varying the number of provided pairs is shown in Table 3. We note that entropy regularization enhances the performance of SSL-CP when amount of unlabeled data is large.

8

Table 3: Mackay-Glass: Classiï¬er performance for diï¬€erent amounts of unlabeled data

Model
SSL-CP SSL-CP (ER)

600 Pairs
0.87 Ë˜0.2 0.87 Ë˜0.2

1800 Pairs
0.94 Ë˜0.1 0.95 Ë˜0.1

4000 Pairs
0.96 Ë˜0.1 0.99 Ë˜0.2

Table 4: HCI: Mean classiï¬er performance when using one label per class

Supervised 0.63

Autoencoder 0.68

SSL-CP 0.72

4.3 Real-world datasets
HCI: Gesture recognition
The HCI gesture recognition dataset consists of a user performing 5 diï¬€erent gestures using the right arm [6]. Data is obtained from 8 IMUs placed on the arm. The gestures recorded included drawing triangle up, circle, inï¬nity, square, and triangle down. We also consider the null case (where the user is not performing an activity) as a class. We use the free-hand subset from this dataset as it presents a relatively challenging classiï¬cation problem when compared with the more controlled subset. Rather than using consecutive nonoverlapping windows (as the resulting sub-sequences are too small to contain a single class, since the duration of the null class can be very small), the sequential data is ï¬rst divided into 100 segments using the labels. 30 segments are left as test data.
This dataset presents a challenge to the SSL-CP approach in that most classes never appear adjacent to each other in the data set as they are always separated by a period in the null class. To obtain similarity constraints involving class pairs that do not include the null class, we generate a sequence by repeating a randomly sampled segment and concatenating it with another repeated randomly sampled segment. Change detection is then applied on this concatenated sequence to provide similar and dissimilar pairs. 600 of such similar dissimilar pairs were obtained.
When all labels within the dataset are provided, the mean F1 score for the supervised approach is 0.88. Such a score can actually sometimes be achieved by the supervised classiï¬er even when only 1 label from each class is provided. However in this setting, the results can vary dramatically depending on exactly which instances are labeled. We obtained classiï¬cation results across 30 trials, with a diï¬€erent random choice of which instance in each class were labeled. We show the average results in Table 4. In Table 5 we show the percentage of trials in which each method performed best.
WISDM: Activity recognition
The WISDM activity recognition dataset [6] consists of 36 users performing 6 activities which include running, walking, ascending stairs, descending stairs, sitting, and standing. Data is collected through an accelerometer mounted on the participantâ€™s chest which provides 3 dimensional data sampled at 20Hz. For our experiments, we retained data from users 33, 34, and 35 as test set. We split the data from the rest of the users in a 70/30 ratio, using the large split for training and the small split for validation. We used a small sub-sequence (consisting of about 20 change points) to tune the change detection parameters. Once tuned, we obtained change points on the entire training set to obtain pairs of size 50. We obtained a total of about 4000 such pairs. We used about 7000 non-overlapping windows of size 50 as unlabeled data for the autoencoder. We used non-overlapping windows of size 50 as labeled data. In all experiments, we used a balanced number of labels from each class.
Table 6 shows results when 48 labels (6 from each class). When pairs from all detected change points within the training set (4000 in number) are used, the performance of SSL-CP is slightly worse than that of the autoencoder. This is because many false change points are detected (up to about 40% false change points) for a small number of users, leading to erroneous similarity constraints. After the removal of 10 such users, the number of falsely detected change points is reduced (to below 10% across all users) and about

9

Table 5: HCI: Percentage of trials in which each method performs best when using one label per class

Supervised 11%

Autoencoder 26%

SSL-CP 63%

1600 pairs are obtained. The performance of SSL-CP for this case (ï¬ltered users) is notably better than the autoencoder. The performance further improves when all true change points are provided. In such a case, the number of unlabeled pairs are larger leading to improved performance of entropy regularization as well. Figure 5 shows the relationship between classiï¬cation performance and the number of labels available. In this experiment, only pairs derived from change points on the ï¬ltered users are used.
Table 6: WISDM: Classiï¬er performance with 48 labels

Method
Supervised Autoencoder
SSL-CP (All users) SSL-CP (Filtered users) SSL-CP (True CPs, all users) SSL-CP-ER (Filtered users) SSL-CP-ER (True CPs, all users)

F1 score
0.45 Ë˜ 0.04 0.54 Ë˜ 0.02
0.53 Ë˜ 0.03 0.65 Ë˜ 0.02 0.66 Ë˜ 0.01 0.65 Ë˜ 0.01 0.69 Ë˜ 0.01

F1 score

0.85 0.8
0.75 0.7
0.65 0.6
0.55 0.5
0.45 0.4 50

Supervised Autoencoder SSL-CP Supervised on all labels

100

200

400

800

Number of labels

Figure 5: Performance on WISDM as the the number of provided labels increases. (Filtered users)

10

5 Discussion and Conclusion
As highlighted by the performance on the WISDM dataset, the performance of our proposed method depends critically on the successful detection of change points. The detection of too many false change points can lead to corrupt similarity/dissimiarity constraints, that can potentially deteriorate performance. The other main limitation of the SSL-CP approach is that obtaining a rich set of similarity/dissimilarity constraints across all possible combinations of classes requires that these classes appear adjacent in the data. However, as we observed in the HCI dataset, the generation of additional sequences can provide a synthetic solution to this problem that is eï¬€ective in practice.
Despite these limitations, SSL-CP consistently outperformed our baselines on both synthetic and realworld datasets. This clearly shows the potential utility of incorporating information from change points in semi-supervised learning. Moreover, the results on the WISDM dataset clearly illustrate the potential improvement that could be realized by a more robust change point detection procedures. Historically, change point detection has been mostly restricted to detecting anomalies or segmenting data. We hope that this work will encourage the community to recognize the utility of change point detection in semi-supervised learning and to devote more attention to developing improved non-parameteric change point detection procedures.
References
[1] Mahdieh Soleymani Baghshah and Saeed Bagheri Shouraki. Semi-supervised metric learning using pairwise constraints. In Proc. Int. Joint Conf. on Artiï¬cial Intelligence (IJCAI), 2009.
[2] Shaojie Bai, Zico Kolter, and Vladlen Koltun. An empirical evaluation of generic convolutional and recurrent networks for sequence modeling. arXiv:1803.01271, 2018.
[3] David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital Oliver, and Colin A Raï¬€el. Mixmatch: A holistic approach to semi-supervised learning. In Proc. Adv. in Neural Inf. Proc. Sys. (NeurIPS), 2019.
[4] Wei-Cheng Chang, Chun-Liang Li, Yiming Yang, and BarnabÂ´as PÂ´oczos. Kernel change-point detection with auxiliary deep generative models. In Proc. Int. Conf. on Learning Representations (ICLR), 2019.
[5] Andrew Dai and Quoc Le. Semi-supervised sequence learning. In Proc. Adv. in Neural Inf. Proc. Sys. (NeurIPS), 2015.
[6] Kilian Forster, Daniel Roggen, and Gerhard Troster. Unsupervised classiï¬er self-calibration through repeated context occurences: Is there robustness against sensor displacement to gain? In 2009 IEEE Int. Symp. on Wearable Computers (ISWC), 2009.
[7] Leon Glass and Michael Mackey. Mackey-Glass equation. Scholarpedia, 5(3):6908, 2010.
[8] Yves Grandvalet and Yoshua Bengio. Semi-supervised learning by entropy minimization. In Proc. Adv. in Neural Inf. Proc. Sys. (NeurIPS), 2005.
[9] Arthur Gretton, Karsten Borgwardt, Malte Rasch, Bernhard SchÂ¨olkopf, and Alexander Smola. A kernel two-sample test. Journal of Machine Learning Research, 13:723â€“773, 2012.
[10] Yen-Chang Hsu and Zsolt Kira. Neural network-based clustering using pairwise constraints. In Proc. Int. Conf. on Learning Representations Workshop Track, 2016.
[11] Thorsten Joachims. Transductive inference for text classiï¬cation using support vector machines. In Proc. Int. Conf. on Machine Learning (ICML), 1999.
[12] Gregory Koch, Richard Zemel, and Ruslan Salakhutdinov. Siamese neural networks for one-shot image recognition. In Proc. Int. Conf. on Machine Learning Workshop in Deeplearning, 2015.
[13] Jens Kohlmorgen and Steven Lemm. A dynamic hmm for on-line segmentation of sequential data. In Proc. Adv. in Neural Inf. Proc. Sys. (NeurIPS), 2002.
11

[14] Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. arXiv:1610.02242, 2016.
[15] Shuang Li, Yao Xie, Hanjun Dai, and Le Song. M-statistic for kernel change-point detection. In Proc. Adv. in Neural Inf. Proc. Sys. (NeurIPS), 2015.
[16] Song Liu, Makoto Yamada, Nigel Collier, and Masashi Sugiyama. Change-point detection in time-series data by relative density-ratio estimation. Neural Networks, 43:72â€“83, 2013.
[17] Avital Oliver, Augustus Odena, Colin A Raï¬€el, Ekin Dogus Cubuk, and Ian Goodfellow. Realistic evaluation of deep semi-supervised learning algorithms. In Proc. Adv. in Neural Inf. Proc. Sys. (NeurIPS), 2018.
[18] Antti Rasmus, Mathias Berglund, Mikko Honkala, Harri Valpola, and Tapani Raiko. Semi-supervised learning with ladder networks. In Proc. Adv. in Neural Inf. Proc. Sys. (NeurIPS), 2015.
[19] Jesper Van Engelen and Holger Hoos. A survey on semi-supervised learning. Machine Learning, 109(2):373â€“440, 2020.
[20] Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, StÂ´efan J. van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, Robert Kern, Eric Larson, CJ Carey, IË™lhan Polat, Yu Feng, Eric W. Moore, Jake Vand erPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero, Charles R Harris, Anne M. Archibald, AntË†onio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1.0 Contributors. SciPy 1.0: Fundamental Algorithms for Scientiï¬c Computing in Python. Nature Methods, 17:261â€“272, 2020.
[21] Jindong Wang, Yiqiang Chen, Shuji Hao, Xiaohui Peng, and Lisha Hu. Deep learning for sensor-based activity recognition: A survey. Pattern Recognition Letters, 119:3â€“11, 2019.
[22] Eric Xing, Michael Jordan, Stuart Russell, and Andrew Ng. Distance metric learning with application to clustering with side-information. In Proc. Adv. in Neural Inf. Proc. Sys. (NeurIPS), 2003.
[23] Ming Zeng, Tong Yu, Xiao Wang, Le T Nguyen, Ole J Mengshoel, and Ian Lane. Semi-supervised convolutional neural networks for human activity recognition. In 2017 IEEE Int. Conf. on Big Data (BigData), 2017.
[24] Xu Zhang, Felix Xinnan Yu, Svebor Karaman, Wei Zhang, and Shih-Fu Chang. Heated-up softmax embedding. arXiv: 1809.04157, 2018.
[25] Xiaojin Zhu. Semi-supervised learning literature survey. Technical report, University of WisconsinMadison Department of Computer Sciences, 2005.
[26] Xiaojin Zhu, Zoubin Ghahramani, and John D Laï¬€erty. Semi-supervised learning using gaussian ï¬elds and harmonic functions. In Proc. Int. Conf. on Machine Learning (ICML), 2003.
12

6 Appendix
6.1 Technical details on training neural networks
Preprocessing Inputs to all the networks are scaled to be between 0 and 1.

Network architecture and training details
The neural network fÎ¸ used to learn representations from change points consists of three temporal blocks, where each of the blocks consists of 100 channels. Here a temporal block is deï¬ned as in [2] where each temporal block consists of two convolution layers with the same ï¬lter dilation. Each convolution layer is followed by weight normalization which is followed by a RELU activation and a dropout layer of 0.2.
For each successive temporal block, the ï¬lter was dilated by a factor of 2. The number of epochs needed to minimize training loss for fÎ¸ was reduced by multiplying a constant (temperature [24]) to the embedding provided to the ï¬nal softmax layer. Details for these parameters can be found in Table 8. The ï¬rst column refers to the diï¬€erent ï¬lters sizes (without dilation) used for each experiment. The second column lists the Ï parameter for the hinge loss while the third parameter lists the temperature values used.
2000 epochs were provided to train fÎ¸ through pairwise change points. The ADAM optimizer with a learning rate of 0.0001 was used for all experiments to train fÎ¸.

Table 7: Parameters for training fÎ¸

Experiment Mean var Mackay-Glass
HCI WISDM

Filter size 5 10 30 10

Hinge param Ï 4 8 8 4

Temp 5 10 5 10

The feedforward fully connected network fÏˆ was trained using a learning rate of 0.001 through the ADAM optimizer and had two hidden layers of sizes 400 and 100 respectively. A RELU activation is used after each of these hidden layers. 400 epochs were provided to train the feed forward network.
For both the autoencoder and the supervised baselines, 1000 epochs were provided for training as the loss (for both validation and training, the loss became constant at the 700th iteration and was constant until the 1000th epoch.)
Each of the reported experiments was repeated 5 times, with mean and deviation (diï¬€erence from the largest deviation from the mean) reported. The seed for functions based on randomness was ï¬xed to a value 5.

6.2 Detecting change points
Change points are also detected on sequences that are scaled between 0 and 1. This is not necessary but makes it convenient to get scaled similar/dissimilar pairs for the neural network fÎ¸ directly from the sequence on which change points are detected.
An example of detecting change points on the Mackay-Glass sequence can be seen in Figure 6. This is a short sequence consisting of about 15 segments which can be used to set parameters needed for detecting change points. The ï¬rst subplot shows the Mackay-Glass sequence. The second subplot shows the values of the MMD function as well as the detected changes while the third subplot shows the labels corresponding to diï¬€erent segments within the sequence. Note the mountain/hill like features for the MMD statistic in the second subplot. These hills arise because the MMD function starts increasing when the future window Xf starts overlapping with the segment belonging to the next class in the sequence. The peak value within this hill corresponds to the change point. The MMD function starts decreasing when the previous window Xp starts overlapping with the sequence class corresponding to Xf
The peak function within the scipy [20] python package can be applied on change statistics mi to obtain change points. The peak function is used with two options. One is the â€˜peak heightâ€™ which is equivalent to

13

Sequence values

Change detection : Mackay-Glass sequence 1
Sequence value 0.5

MMD statistic

0 0
0.2 0.15
0.1 0.05
0 0

2000

4000

6000

8000

10000

12000 14000 16000
MMD statistic Detected change points

2000

4000

6000

8000 10000 12000 14000 16000

Sequence labels

5

Labels

4

3

2

1

0

0

2000

4000

6000

8000 10000 12000 14000 16000

Sequence length

Figure 6: Detected change points on Mackay-Glass sequence

the change detection threshold Ï„ . The second argument is distance which speciï¬es the minimum distance between detected change points.
The parameters used for detecting change points are listed below. Ï„ is the detection threshold, w is the size of the windows for Xf and Xp and distance is the minimum distance between change points provided to the peak function.

Table 8: Parameters for detecting change points

Experiment

Ï„

w distance

Mean var

3 100 100

Mackay-Glass 0.025 800 800

HCI

0.18 600 600

WISDM 0.025 200 200

14

