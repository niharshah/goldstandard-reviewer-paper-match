arXiv:2111.00965v1 [cs.LG] 1 Nov 2021

iFlow: Numerically Invertible Flows for Efï¬cient Lossless Compression via a Uniform Coder
Shifeng Zhang, Ning Kang, Tom Ryder, Zhenguo Li Huawei Noahâ€™s Ark Lab
{zhangshifeng4, kang.ning2, tom.ryder1, li.zhenguo}.huawei.com
Abstract
It was estimated that the world produced 59ZB (5.9 Ã— 1013GB) of data in 2020, resulting in the enormous costs of both data storage and transmission. Fortunately, recent advances in deep generative models have spearheaded a new class of socalled "neural compression" algorithms, which signiï¬cantly outperform traditional codecs in terms of compression ratio. Unfortunately, the application of neural compression garners little commercial interest due to its limited bandwidth; therefore, developing highly efï¬cient frameworks is of critical practical importance. In this paper, we discuss lossless compression using normalizing ï¬‚ows which have demonstrated a great capacity for achieving high compression ratios. As such, we introduce iFlow, a new method for achieving efï¬cient lossless compression. We ï¬rst propose Modular Scale Transform (MST) and a novel family of numerically invertible ï¬‚ow transformations based on MST. Then we introduce the Uniform Base Conversion System (UBCS), a fast uniform-distribution codec incorporated into iFlow, enabling efï¬cient compression. iFlow achieves state-of-the-art compression ratios and is 5Ã— quicker than other high-performance schemes. Furthermore, the techniques presented in this paper can be used to accelerate coding time for a broad class of ï¬‚ow-based algorithms.
1 Introduction
The volume of data, measured in terms of IP trafï¬c, is currently witnessing an exponential yearon-year growth [13]. Consequently, the cost of transmitting and storing data is rapidly becoming prohibitive for service providers, such as cloud and streaming platforms. These challenges increasingly necessitate the need for the development of high-performance lossless compression codecs.
One promising solution to this problem has been the development of a new class of so-called â€œneural compressionâ€ algorithms [30, 38, 18, 4, 17, 37, 26, 31, 6, 41]. These methods typically posit a deep probabilistic model of the data distribution, which, in combination with entropy coders, can be used to compress data with the minimal codelength bounded by the negative log-likelihood [29]. However, despite reliably improved compression performance compared to traditional codecs [14, 33, 9, 34], meaningful commercial applications have been limited by impractically slow coding speed.
In this paper, we focus on developing approaches with deep probabilistic models based on normalizing ï¬‚ows [11, 25, 32, 27, 7, 28, 23]. A normalizing ï¬‚ow admits a learnable bijective mapping between input data and a latent variable representation. In this paradigm, inputs can be compressed by ï¬rst transforming data to latent variables, with the resulting output encoded by a prior distribution. Compared to other classes of generative models, normalizing ï¬‚ows typically perform best in both tasks of probability density estimation (as compared with variational autoencoders [24, 15, 8]) and inference speed (as compared with autoregressive factorizations [35, 39, 22]). This suggests that compression with ï¬‚ows can jointly achieve high compression ratios along with fast coding times.
35th Conference on Neural Information Processing Systems (NeurIPS 2021), Sydney, Australia.

IDF(++), iVPF
âŒŠÎ˜âŒ‰

encoding
ğ³ Quantize

Î¦â‹…ğ‘¥ ğ‘§
Direct/MAT
ğ‘¥
Direct: ğ‘§ â† ğ‘¥ Î¦ = 1 MAT: ğ‘§ â† Î¦ â‹… ğ‘¥ âˆÎ¦ = 1

ğ‘§ = Î¦ â‹… ğ‘¥ + Î˜ Flow layer
(Î¦ = 1 or âˆÎ¦ = 1)
Quantize

ğ‘§=ğ‘“ ğ‘¥

Flow layer

decoding Dequant

decoding

ğ±

LBB
encoding

De ğ‘ 0, ğœğ‘“â€² 2
ğ‘“ğ‘¥ ğ‘§

iFlow (Proposed)

encoding

ğ‘“ ğ‘¥ğ‘™ ğ‘§ ğ‘“ ğ‘¥â„
MST

ğ³ ğ‘¥ ğ‘“âˆ’1 ğ‘§ En ğ‘ 0, ğœ2 de/encoding

ğ³ ğ‘¥ ğ‘¥ğ‘™ ğ‘¥â„ MST: ğ‘§ â† ğ‘ â‹… ğ‘¥ âˆ’ ğ‘¥ğ‘™ ğ‘ = ğ‘“ ğ‘¥â„ âˆ’ğ‘“ ğ‘¥ğ‘™ ğ‘¥â„âˆ’ğ‘¥ğ‘™

+ ğ‘“ ğ‘¥ğ‘™ ,

Flow layer

ğ‘§ = ğ‘“ ğ‘¥ iFlow layer MST

de/encoding Flow layer

iFlow layer MST

Dequant
ğ±

decoding

Dequant
ğ±

Compression ratio

Compression bandwidth

Figure 1: Illustration of IDF(++), iVPF, LBB and the proposed iFlow method. Flow layers with darker color denote higher expressive power. The top-right of each model illustration shows the key procedure of exact bijections between xÂ¯ and zÂ¯. The compression ratio and bandwidth are listed below.

Unfortunately, lossless compression requires discrete data for entropy coding, and the continuous bijections of normalizing ï¬‚ows would not guarantee discrete latent variables. As such, transformations would require discretization, resulting in a loss of information [41, 3]. To resolve this issue, Integer Discrete Flows (IDF) [18, 4] (Fig. 1, left) proposed an invertible mapping between discrete data and latent variables. Similarly, iVPF [41] achieves a discrete-space bijection using volume-preserving ï¬‚ows. However, the above models must introduce constraints on ï¬‚ow layers to ensure a discretespace bijection, which limits the expressivity of the transformation. Local Bits-Back Coding (LBB) [17] (Fig. 1, middle) was the ï¬rst approach to succeed in lossless coding with the ï¬‚exible family of continuous ï¬‚ows. It resolves the information loss by coding numerical errors with the rANS coder [12]. However, the coder is extraordinarily slow, making the method impractical.
In this paper, we introduce iFlow: a numerically invertible ï¬‚ow-based neural compression codec that bridges the gap between high-ï¬delity density estimators and practical coding speed. To achieve this we introduce two novelties: Modular Scale Transform (MST) and Uniform Base Conversion Systems (UBCS). MST presents a ï¬‚exible family of bijections in discrete space, deriving an invertible class of ï¬‚ows suitable for lossless compression. UBCS, built on the uniform distribution, permits a highly efï¬cient entropy coding compatible with MST. The main ideas are illustrated in Fig. 1(right). We test our approach across a range of image datasets against both traditional and neural compression techniques. Experimentally we demonstrate that our method achieves state-of-the-art compression ratios, with coding time 5Ã— quicker than that of the next-best scheme, LBB.

2 Numerically Invertible Flows and Lossless Compression

Let f : X â†’ Z be our normalizing ï¬‚ow, which we build as a composition of layers such that f = fL â—¦ ... â—¦ f2 â—¦ f1. Deï¬ning d-dimensional y0 = x âˆˆ X and yL = z âˆˆ Z, the latents can be computed as yl = fl(ylâˆ’1), with pX (x) calculated according to

L

log pX (x) = log pZ (z) + log | det Jfl (ylâˆ’1)|,

(1)

l=1

where Jfl (x) is the Jocabian matrix of the transformation fl at ylâˆ’1. In this paper, we use log to denote base 2 logarithms. Training the ï¬‚ow should minimize the negative log-likelihood âˆ’ log pX (x). The inverse ï¬‚ow is deï¬ned as f âˆ’1 = f1âˆ’1 â—¦ ... â—¦ fLâˆ’1, such that f âˆ’1(z) = x. There are many types of invertible bijections, fl. Popular choices include element-wise, autoregressive (e.g. coupling
layers) [41] and 1 Ã— 1 convolution transformations [25].

To perform lossless compression with normalizing ï¬‚ows, the input data should be transformed to latent variables, which are then encoded with a prior distribution. As data and encoded bits should be in binary format, x and z must be discrete, with a bijection between discrete inputs and outputs

2

established. However, as discussed, this operation is usually intractable with popular classes of transformations used in continuous ï¬‚ows due to the numerical errors induced by discretization.
In this section, we introduce a novel algorithm derived from continuous ï¬‚ows that allows us to achieve an exact bijiective mapping between discrete x and discrete z. We present the general idea of a ï¬‚ow layerâ€™s numerical invertibility in discrete space in Sec. 2.1. We then introduce our ï¬‚ow layers in Sec. 2.2 and 2.3, with their application to compression discussed in Sec. 2.4 and 2.5.

2.1 Invertibility of Flows in Discrete Space

To discretize the data, we follow [41] and adopt k-precision quantization to assign ï¬‚oating points to

discretization bins such that

2k Â· x

xÂ¯ = 2k ,

(2)

where Â· is the ï¬‚oor function. The associated quantization error is bounded by |xÂ¯ âˆ’ x| < 2âˆ’k. Any

d-dimensional x can be quantized into bins with volume Î´ = 2âˆ’kd. The probability mass of xÂ¯ can

then be approximated by P (xÂ¯) = p(xÂ¯)Î´, such that the theoretical codelength is âˆ’ log(p(xÂ¯)Î´).

Denote our proposed numerically invertible ï¬‚ow (iFlow) according to fÂ¯ = fÂ¯L â—¦ ... â—¦ fÂ¯1. The input
and output should be subject to k-precision quantization, where each layer should be appropriately invertible such that yÂ¯lâˆ’1 â‰¡ fÂ¯lâˆ’1(fÂ¯l(yÂ¯lâˆ’1)). Denoting yÂ¯0 = x and zÂ¯ = yÂ¯L, it is further expected that zÂ¯ = fÂ¯(x) and x â‰¡ fÂ¯âˆ’1(zÂ¯). We will show in the following subsections that fÂ¯ can be derived from any continuous ï¬‚ow f in such a way that the error between fÂ¯(x) and f (x) is negligible.

2.2 Numerically Invertible Element-Wise Flows
We begin by describing our approach for element-wise ï¬‚ows z = f (x), where f is a monotonic element-wise transformation. For notation simplicity, we assume that the ï¬‚ow contains just one layer. In most cases, f does not present a unique inverse in discrete space, such that f âˆ’1(zÂ¯) = x. In what follows, we introduce an approach to derive an invertible, discrete-space operation from any element-wise ï¬‚ow transformation. For simplicity, we denote the inputs and output pairs of a continuous ï¬‚ow as x and z = f (x); and we denote the k-precision quantized input-output pairs of iFlow as xÂ¯ and zÂ¯ = fÂ¯(xÂ¯).

2.2.1 Scale Flow

Algorithm 1 Modular Scale Transform (MST): Numerically Invertible Scale Flow f (x) = R/S Â· x.

Forward MST: zÂ¯ = fÂ¯(xÂ¯).
1: xË† â† 2k Â· xÂ¯; 2: Decode rd using U (0, R); yË† â† R Â· xË† + rd; 3: zË† â† yË†/S , re â† yË† mod S; 4: Encode re using U (0, S); 5: return zÂ¯ â† zË†/2k.

Inverse MST: xÂ¯ = fÂ¯âˆ’1(zÂ¯).
1: zË† â† 2k Â· zÂ¯; 2: Decode re using U (0, S); yË† â† S Â· zË† + re; 3: xË† â† yË†/R , rd â† yË† mod R; 4: Encode rd using U (0, R); 5: return xÂ¯ â† xË†/2k.

We begin with the scale transformation deï¬ned as z = f (x) = a Â· x, (a > 0), from which we are able to build more complex ï¬‚ow layers. The input can be converted to an integer with xË† = 2k Â· xÂ¯, and the latent variable zÂ¯ can be recovered from integer zË† by zÂ¯ = zË†/2k. Inspired by MAT in iVPF [41], we ï¬rst approximate a with a fractional such that a â‰ˆ RS , where R, S âˆˆ N. Denote yË† = R Â· xË† + rd where rd is sampled uniformly from {0, 1, ..., R âˆ’ 1}, we can obtain zË† with zË† = yË†/S , and the remainder re = yË† mod R can be encoded to eliminate the error. It is clear that (xË†, rd) â†” yË† â†” (zË†, re) are bijections.
Let U (0, A) be the uniform distribution such that P (s) = A1 , s âˆˆ {0, 1, ..., A âˆ’ 1}. The numerically invertible scale ï¬‚ow fÂ¯ is displayed in Alg. 1. As the modular operation is essential to Alg. 1, we name it the Modular Scale Transform (MST). Setting S and R = round(S Â· a) to be large, we observe that the following propositions hold.
Proposition 1. [41] |zÂ¯ âˆ’ f (xÂ¯)| < O(Sâˆ’1, 2âˆ’k).
Proposition 2. The codelength of MST is Lf (xÂ¯, zÂ¯) = log S âˆ’ log R â‰ˆ âˆ’ log |a| = âˆ’ log |f (xÂ¯)|.

3

Proposition 1 establishes that the error is small if S and k are large. Proposition 2 demonstrates that the codelength is almost exactly the log-Jocabian of f . The above properties and the correctness of the algorithm are discussed in the Appendix. Further note that, with the exception of the usual encoding and decoding processes, MSTâ€™s operations can be parallelized, resulting in minimal additional overhead. In contrast, MATâ€™s operation in iVPF [41] only deals with volume-preserving afï¬ne transform and is performed sequentially along dimensions, limiting its usage and efï¬ciency.
2.2.2 General Element-wise Flow

Algorithm 2 Numerically Invertible Element-wise Flows

Forward: zÂ¯ = fÂ¯(xÂ¯).

1: Get xÂ¯l, xÂ¯h, zÂ¯l, zÂ¯h given xÂ¯, so that xÂ¯ âˆˆ [xÂ¯l, xÂ¯h);

2: Set large S; get R with Eq. (4); xÂ¯ â† xÂ¯ âˆ’ xÂ¯l;

3: Get zÂ¯ with forward MST in Alg. 1, given input xÂ¯

and coefï¬cients R, S;

4: return zÂ¯ = zÂ¯ + zÂ¯l.

zÂ¯ âˆˆ [zÂ¯l, zÂ¯h).

Inverse: xÂ¯ = fÂ¯âˆ’1(zÂ¯).

1: Get xÂ¯l, xÂ¯h, zÂ¯l, zÂ¯h given zÂ¯, so that zÂ¯ âˆˆ [zÂ¯l, zÂ¯h);

2: Set large S; get R with Eq. (4); zÂ¯ â† zÂ¯ âˆ’ zÂ¯l;

3: Get xÂ¯ with inverse MST in Alg. 1, given input zÂ¯

and coefï¬cients R, S;

4: return xÂ¯ = xÂ¯ + xÂ¯l.

xÂ¯ âˆˆ [xÂ¯l, xÂ¯h).

For simplicity, we assume the non-linear f is monotonically increasing. For a monotonically decreasing f , we simply invert the sign: âˆ’f .
MST in Alg. 1 works with linear transformations, and is incompatible with non-linear functions. Motivated by linear interpolation, we can approximate the non-linear ï¬‚ow with a piecewise linear function. In general, consider input xÂ¯ to be within an interval xÂ¯ âˆˆ [xÂ¯l, xÂ¯h)1 and zÂ¯l = f (xÂ¯l), zÂ¯h = f (xÂ¯h). The linear interpolation of f is then

finp(x) = zÂ¯h âˆ’ zÂ¯l (xÂ¯ âˆ’ xÂ¯l) + zÂ¯l. (3) xÂ¯h âˆ’ xÂ¯l

It follows that zÂ¯ can be derived from MST with input xÂ¯âˆ’xÂ¯l followed by adding zÂ¯l. Furthermore, zÂ¯ and
xÂ¯ can be recovered with the corresponding inverse transformation. To preserve monotonicity, zÂ¯ must be within interval zÂ¯ âˆˆ [zÂ¯l, zÂ¯h). Denoting the invertible linear ï¬‚ow derived from finp as fÂ¯inp, it must hold that fÂ¯inp(xÂ¯l) â‰¥ zÂ¯l, fÂ¯inp(xÂ¯h âˆ’2âˆ’k) â‰¤ zÂ¯h âˆ’2âˆ’k. As we use MST in Alg. 1, we observe that when xÂ¯zÂ¯hhâˆ’âˆ’xzÂ¯Â¯ll is approximated with R/S, the minimum possible value of fÂ¯inp(xÂ¯l) is zÂ¯l (when rd = 0 in Line 2) and the maximum possible value of fÂ¯inp(xÂ¯hâˆ’2âˆ’k) is (RÂ·2k(xÂ¯hâˆ’xÂ¯lâˆ’2âˆ’k)+Râˆ’1)/(SÂ·2k) +zÂ¯l
(when rd = R âˆ’ 1 in Line 2). Given large S, the largest possible value of R should be

(2k Â· (zÂ¯h âˆ’ zÂ¯l) âˆ’ 1) Â· S + 1

R = 2k Â· (xÂ¯h âˆ’ xÂ¯l) .

(4)

Another difï¬culty is in determining the correct interpolation interval [xÂ¯l, xÂ¯h). One simple solution is to split the input domain into uniform intervals with length 2âˆ’h such that xÂ¯l = (2h Â· xÂ¯)/2h , xÂ¯h = xÂ¯l + 2âˆ’h. However, for the inverse computation given zÂ¯, it is not easy to recover the interpolation interval as f âˆ’1(zÂ¯) may not be within [xÂ¯l, xÂ¯h). Instead, as zÂ¯ âˆˆ [zÂ¯h, zÂ¯l), the interval [xÂ¯l, xÂ¯h) can be
obtained via a binary search in which xÂ¯l is obtained with zÂ¯ âˆˆ [f (xÂ¯l), f (xÂ¯h)). Another approach is to split the co-domain into uniform intervals such that zÂ¯l = (2h Â· zÂ¯)/2h , zÂ¯h = zÂ¯l + 2âˆ’h, with xÂ¯l = f âˆ’1(zÂ¯l), xÂ¯h = f âˆ’1(zÂ¯h). In this case, determining [zÂ¯l, zÂ¯h) during the inverse computation is simple. While for the forward pass, [zÂ¯l, zÂ¯h) should be determined with a binary search such that xÂ¯ âˆˆ [f âˆ’1(zÂ¯l), f âˆ’1(zÂ¯h)). In practice, we have simpler tricks to determine the correct interval [xÂ¯l, xÂ¯h), [zÂ¯l, xÂ¯h) for both the forward and inverse computation, which can be found in the Appendix.
The general idea of the non-linear ï¬‚ow adaptations are summarized in Alg. 2. Note that Alg. 2 can be used in any element-wise ï¬‚ow including linear ï¬‚ow. In Alg. 2, Proposition 2 holds such that Lf (xÂ¯, zÂ¯) = âˆ’ log(R/S) â‰ˆ âˆ’ log xÂ¯zÂ¯hhâˆ’âˆ’zxÂ¯Â¯ll â‰ˆ âˆ’ log |f (xÂ¯)|. It is possible to arrive at a similar conclusion in Proposition 1 where the corresponding error is |zÂ¯ âˆ’ f (xÂ¯)| < O(Sâˆ’1, 2âˆ’k, 2âˆ’2h).

1All intervals must partition the domain of f .

4

2.3 Practical Numerically Invertible Flow Layers
Whilst one can use many types of complex transformations to build richly expressive ï¬‚ow-based models, to ensure the existence and uniqueness of the inverse computation, these layers are generally constructed with element-wise transformations. In this subsection, we demonstrate the invertibility of discretized analogs to some of the most widely used ï¬‚ow layers using the operators as described in Sec. 2.2. Such ï¬‚ows include autoregressive ï¬‚ows [20] (including coupling ï¬‚ows [10, 11, 16]) and 1 Ã— 1 convolutional ï¬‚ows [25].
2.3.1 Autoregressive and Coupling Flows

Algorithm 3 Numerically Invertible Autoregressive Flow

Forward: zÂ¯ = fÂ¯(xÂ¯).
1: for i = m, ..., 1 do 2: zÂ¯i â† fÂ¯i(xÂ¯i, xÂ¯<i) with Alg. 2 (forward); 3: end for 4: return zÂ¯ = [zÂ¯1, ..., zÂ¯m] .

Inverse: xÂ¯ = fÂ¯âˆ’1(zÂ¯).
1: for i = 1, ..., m do 2: xÂ¯i â† fÂ¯iâˆ’1(zÂ¯i, xÂ¯<i) with Alg. 2 (inverse); 3: end for 4: return zÂ¯ = [zÂ¯1, ..., zÂ¯m] .

Supposing that the inputs and outputs, x and z, are split into m parts x = [x1, ..., xm] , z = [z1, ..., zm] , the autoregressive ï¬‚ow z = f (x) can be represented as zi = fi(xi; x<i), where fi(Â·; x<i) is the element-wise ï¬‚ow (discussed in Sec. 2.2), conditioned on x<i. Now let fÂ¯i(Â·; x<i) denote the invertible element-wise ï¬‚ow transformation as discussed in Alg. 1-2. Alg. 3 then illustrates the details of an invertible autoregressive ï¬‚ow fÂ¯.

Propositions 1 and 2 hold in our discretized autoregressive transformation. In fact, the log-determinant

of Jacobian is given by log | det Jf (x)| =

m i=1

log

|

det

Jfi

(xi;

x<i)|,

and

the

expected

codelength

is simply Lf (xÂ¯, zÂ¯) =

m i=1

Lf

(xÂ¯i,

zÂ¯i)

â‰ˆ

âˆ’

m i=1

log

|

det

Jfi

(xÂ¯i;

xÂ¯<i)|

=

âˆ’

log

|

det

Jf

(xÂ¯)|.

When m = 2 and f1(x1) = x1, the autoregressive ï¬‚ow is reduced to a coupling ï¬‚ow, which is widely used in ï¬‚ow-based models [10, 11, 16]. It is therefore trivially clear that the coupling ï¬‚ow is additionally compatible with Alg. 3.

2.3.2 1 Ã— 1 Convolutional Flow
1 Ã— 1 convolutional layers can be viewed as a matrix multiplication along a channel dimension [25]. Let xÂ¯, zÂ¯ âˆˆ Rc be inputs and outputs along channels, and W âˆˆ RcÃ—c the weights of our network. The objective is to obtain zÂ¯ = fÂ¯(xÂ¯) where f (x) = Wx.
We use the ideas of iVPF [41] to achieve a numerically invertible 1 Ã— 1 convolutional transformation. In particular, we begin by performing an LU decomposition such that W = PLÎ›U. It then follows that the 1 Ã— 1 convolution is performed with successive matrix multiplications with U, Î›, L and P. In iVPF, the authors extensively discussed matrix multiplications with factors U, L and P [41]. Meanwhile, one can view the matrix multiplication with Î› as a scale transform, such that f (x) = Î» x, where is an element-wise multiplication and Î» are the diagonal elements of Î›. MST in Alg. 1 can then be applied. In such a case, it is clear that Proposition 1 and 2 hold for a 1 Ã— 1 convolutional ï¬‚ow. For Proposition 2, it is observed that Lf (xÂ¯, zÂ¯) â‰ˆ âˆ’sum(log Î») = âˆ’ log | det Î›| = âˆ’ log | det W| = âˆ’ log | det Jf (xÂ¯)|.

2.4 Building Numerically Invertible Flows
Our ï¬‚ow model is constructed as a composition of layers f = fL â—¦ ... â—¦ f2 â—¦ f1, where each layer is a transformation of the type discussed in Sec. 2.2 and 2.3. Let us represent the resulting ï¬‚ow as fÂ¯ = fÂ¯L â—¦ ... â—¦ fÂ¯1, where fÂ¯l is a discretized transformation derived from the corresponding continuous f . It is clear that the quantized input xÂ¯(= yÂ¯0) and latent zÂ¯(= yÂ¯L) establish a bijection with successive transformations between discrete inputs and outputs. For the forward pass, zÂ¯ is computed with yÂ¯l = fÂ¯(yÂ¯lâˆ’1), l = 1, 2, ..., L; for the inverse pass, xÂ¯ is recovered with the inverse ï¬‚ow fÂ¯âˆ’1 = fÂ¯1âˆ’1 â—¦ ... â—¦ fÂ¯Lâˆ’1 such that yÂ¯lâˆ’1 = flâˆ’1(yÂ¯l).

5

For our resultant ï¬‚ow model, we can draw similar conclusions as in Propositions 1 and 2. Firstly, the error of zÂ¯ = fÂ¯(xÂ¯) and z = f (xÂ¯) is small, bounded by |zÂ¯ âˆ’ z| < O(LSâˆ’1, L2âˆ’k, L2âˆ’2h). Secondly,

the codelength is approximately Lf (xÂ¯, zÂ¯) =

L l=1

Lfl (yÂ¯lâˆ’1,

yÂ¯l)

â‰ˆ

âˆ’

L l=1

log

|

det

Jfl

(yÂ¯lâˆ’1

)|.

2.5 Lossless Compression with Flows via Bits-back Dequantization

Armed with our ï¬‚ow model fÂ¯, performing lossless compression is straight-forward. For the encoding process, the latent is generated according to zÂ¯ = fÂ¯(xÂ¯). We then encode zÂ¯ with probability pZ(zÂ¯)Î´. For the decoding process, zÂ¯ is decoded with pZ(zÂ¯)Î´, and xÂ¯ is recovered with fÂ¯âˆ’1(zÂ¯). The expected codelength is approximately âˆ’ log(pX (xÂ¯)Î´) such that

L

L(xÂ¯) â‰ˆ âˆ’ log(pZ (zÂ¯)Î´) âˆ’ log | det Jfl (yÂ¯lâˆ’1)| â‰ˆ âˆ’ log(pX (xÂ¯)Î´).

(5)

l=1

However, we note that if k is large, âˆ’ log Î´ = kd and the codelengths will also be large, resulting in a
waste of bits. For what follows, we adopt the bits-back trick in LBB [17] to reduce the codelength. In particular, consider coding with input data xâ—¦ âˆˆ Zd, where a k-precision noise vector uÂ¯ âˆˆ [0, 1)d is decoded with q(uÂ¯|xâ—¦)Î´ and added to input data such that xÂ¯ = xâ—¦ + uÂ¯. In this way, xÂ¯ is then encoded with our ï¬‚ow fÂ¯. For the decoding process, xâ—¦ is recovered by applying the inverse transformation.
We name this coding process Bits-back Dequantization, which is summarized in Alg. 4.

Algorithm 4 Lossless Compression with iFlow.
Encode xâ—¦. 1: Decode uÂ¯ using q(uÂ¯|xâ—¦)Î´; 2: zÂ¯ â† fÂ¯(xâ—¦ + uÂ¯); 3: Encode zÂ¯ using pZ (zÂ¯)Î´.

Decode.
1: Decode zÂ¯ using pZ (zÂ¯)Î´; 2: xÂ¯ â† fÂ¯âˆ’1(zÂ¯), xâ—¦ â† xÂ¯ ; 3: Encode uÂ¯ = xÂ¯ âˆ’ xâ—¦ using q(uÂ¯|xâ—¦)Î´; 4: return xâ—¦.

In practice, q(u|xâ—¦) is constructed with a ï¬‚ow model such that u = g( ; xâ—¦) where âˆ¼ p( ). uÂ¯ is decoded by ï¬rst decoding Â¯ with p(Â¯)Î´, and then applying uÂ¯ = gÂ¯(Â¯; xâ—¦). Thus decoding uÂ¯ involves âˆ’ log(q(uÂ¯|xâ—¦)Î´) bits. Overall, the expected codelength is exactly the dequantization lower
bound [19] such that

L(xâ—¦) â‰ˆ q(uÂ¯|xâ—¦)Î´[log(q(uÂ¯|xâ—¦)Î´) âˆ’ log(p(xâ—¦ + uÂ¯)Î´)]

uÂ¯

(6)

â‰ˆ Eq(uÂ¯|xâ—¦)[log q(uÂ¯|xâ—¦) âˆ’ log p(xâ—¦ + uÂ¯)].

2.6 Extensions

With novel modiï¬cations, ï¬‚ow models can be applied to the generation of various data types, obtaining
superior performance [7, 28, 23]. These models can be used for improved lossless compression. In general, given input data xâ—¦, these models generate intermediate data v with q(v|xâ—¦), and the density
of v is modelled with ï¬‚ow model z = f (v). For generation, when v is generated with the inverse ï¬‚ow, x is generated with p(xâ—¦|v). It is clear that p(x) can be estimated with variational lower bound such that log p(xâ—¦) â‰¥ Eq(v|xâ—¦)[log P (xâ—¦|v) + log p(v) âˆ’ log q(v|xâ—¦)]. For lossless compression, xâ—¦ can be coded with bits-back coding, which is similar with Alg. 4. In the encoding process, we ï¬rst decode vÂ¯ with q(vÂ¯|xâ—¦)Î´ and then encode xâ—¦ with P (xâ—¦|vÂ¯) (similar with Line 1 in Alg. 4-Encode). We then obtain the prior zÂ¯ = fÂ¯(vÂ¯) (Line 2), before ï¬nally encoding zÂ¯ with pZ(zÂ¯)Î´ (Line 3). In the decoding process, zÂ¯ is ï¬rstly decoded with pZ(zÂ¯)Î´ (similar to Line 1 in Alg. 4-Decode), and then recovered vÂ¯ and decoded xâ—¦ with P (xâ—¦|vÂ¯) (Line 2). Finally, we encode using vÂ¯ with q(vÂ¯|xâ—¦) [38].
The expected codelength is approximately

L(xâ—¦) â‰ˆ Eq(vÂ¯|xâ—¦)[log q(vÂ¯|xâ—¦) âˆ’ log P (xâ—¦|vÂ¯) âˆ’ log p(vÂ¯)].

(7)

We introduce a selection of recent, state-of-the-art ï¬‚ow-based models modiï¬ed according to the above. Each model corresponds to a certain coding algorithm.
VFlow [7]. VFlow expands the input data dimension with variational data augmentation to resolve the bottleneck problem in the ï¬‚ow model. In VFlow, v = [xâ—¦ + u, r](u âˆˆ [0, 1)d), where u âˆ¼

6

qu(u|xâ—¦), r âˆ¼ qr(r|xâ—¦ +u), is modelled with ï¬‚ows gu, gr such that u = gu( u; xâ—¦), r = gr( r; xâ—¦ + u) ( u, r are priors). Then we have q(v|xâ—¦) = qu(u|xâ—¦)qr(r|xâ—¦ + u), P (xâ—¦|v) = 1 (as v â†’ (xâ—¦ + u) â†’ xâ—¦). Thus for the encoding process, Â¯u, Â¯r are decoded. To construct vÂ¯ we have uÂ¯ = gÂ¯u(Â¯u; xâ—¦), Â¯r = gÂ¯r(Â¯r; xâ—¦ + uÂ¯); and then vÂ¯ is encoded with iFlow. For the decoding process, vÂ¯ is decoded with the inverse iFlow, and then xâ—¦, uÂ¯, Â¯r is recovered with vÂ¯. Here uÂ¯, Â¯r is encoded and xâ—¦ is the decoded output. As VFlow achieves better generation results compared with general ï¬‚ows, one would expect a better compression ratio with VFlow.

Categorical Normalizing Flow [28]. Categorical Normalizing Flows (CNF) succeed in mod-

elling categorical data such as text, graphs, etc. Given categorical data xâ—¦ = [x1, ..., xn], xi âˆˆ {1, 2, ..., C}n, v = [v1, ..., vn] is represented with word embeddings such that q(vi|xi) =

qe(vi|Âµ(xi), Ïƒ(xi)), in which qe could be a Gaussian or logistic distribution. Then P (xi|vi) =

pËœ(xi )q (vi |xi )
C

with pËœ being the prior over categories. Thus q(v|xâ—¦) =

pËœ(c)q(v |c)

n i=1

q(vi|xi),

P

(xâ—¦|v)

=

c=1

i

n i=1

P

(xi|vi),

and

xâ—¦

can

be

coded

with

Alg.

8

given

q(v|xâ—¦),

P

(xâ—¦|v)

and

the

iFlow.

3 Uniform Base Conversion Systems

Algorithm 5 Uniform Base Conversion Systems

ENCODE s using U (0, R)(R < 2K ).
Input: symbol s, state c, bit-stream bs. Output: new state c and bit-stream bs.
1: c â† c Â· R + s; 2: if c â‰¥ 2M+K then 3: bs.push_back(c mod 2K );
bits to bit-stream. 4: c â† 2cK ; 5: end if 6: return c, bs.

push K

DECODE with U (0, R)(R < 2K ).

Input: state c, bit-stream bs.

Output: decoded s, new state c and bit-stream bs.

1: if c < 2M Â· R then 2: c â† 2K Â· c+bs.pop_back();

get last

K bits from bit-stream and pop them.

3: end if

4: s â† c mod R;

5: c â† c/R ;

6: return s, c, bs.

The previous section demonstrates that coding with a uniform distribution is central to our algorithm. Note that the distribution varies in each coding process, thus dynamic entropy coder is expected. Compared to the Gaussian distribution used in LBB [17], a uniform distribution is simpler, yielding improved coding speed. As follows, we introduce our Uniform Base Conversion Systems (UBCS), which is easy to implement and the coding bandwidth is much greater than that of rANS [12].
UBCS is implemented based on a number-base conversion. The code state c is represented as an integer. For coding some symbol s âˆˆ {0, 1, ..., R âˆ’ 1} with a uniform distribution U (0, R), the new state c is obtained by converting an R-base digit s to an integer such that

c = E(c, s) = c Â· R + s.

(8)

For decoding with U (0, R), given state c , the symbol s and state c are recovered by converting the integer to an R-base digit such that

c

s = c mod R, c = D(c , s) = .

(9)

R

We note, however, that c will become large when more symbols are encoded, and computing Eq. (8-9)

with large c will be inefï¬cient. Similar to rANS, we deï¬ne a â€œnormalized intervalâ€ which bounds the

state c such that c âˆˆ [2M , 2K+M ) (K, M are some integers values) after coding each symbol. For

the encoding process, if c â‰¥ 2K+M , the lower K bits are written to disk, and the remaining bits are

reserved such that c â†

c 2K

. For the decoding process, if c < 2M Â· R, the stored K bits should be

read and appended to the state before decoding. In this way, the decoded state is contained within the

interval [2M , 2K+M ). The initial state can be set such that c = 2M . We illustrate this idea in Alg. 5.

The correctness of Alg. 5 is illustrated in the following theorem. P1 demonstrates that the symbols can be correctly decoded with a UBCS coder, with coding performed in a ï¬rst-in-last-out (FILO) fashion. P2 shows that the codelength closely approximates the entropy of a uniform distribution, subject to a large M and K. The proof of the theorem is in the Appendix.

7

Table 2: Coding performance of iFlow, LBB and iVPF on CIFAR10 dataset. We use batch size 64.

ï¬‚ow arch. Flow++
iVPF

compression technique
LBB [17] iFlow (Ours)
iVPF [41] iFlow (Ours)

nll 3.116 3.195

bpd
3.118 3.118
3.201 3.196

aux. bits
39.86 34.28
6.00 7.00

encoding time (ms) inference coding

16.2Â±0.3

116Â±1.0 21.0Â±0.5

5.5Â±0.1

11.4Â±0.2 7.1Â±0.2

decoding time (ms) inference coding

32.4Â±0.2

112Â±1.5 37.7Â±0.5

5.2Â±0.1

13.5Â±0.3 9.7Â±0.2

Theorem 3. Consider coding symbols s1, ...sn with si âˆ¼ U (0, Ri), (i = 1, 2, ..., n, Ri < 2K ) using
Alg. 5, and then decode sn, snâˆ’1, ..., s1 sequentially. Suppose (1) the initial state and bit-stream are c0 = 2M , bs0 = empty respectively; (2) After coding si, the state is ci and the bit-stream is bsi;
(3) After decoding si+1, the state is ci and the bit-stream is bsi. We have

P1: si = si+1, ci = ci, bsi = bsi for all i = 0, ..., n âˆ’ 1.

P2: Denote by the codelength li = log ci + len(bsi) where len is the total number of bits in

the

bit-stream.

Then

ln

âˆ’ l0

<

1 1âˆ’1/(ln 2Â·2M Â·K)

n i=1

Ri

+

1

+

(ln

2

Â·

2M

)âˆ’1

.

In practice, we set K = 32 and M = 4. Compared to rANS [12] and Arithmetric Coding (AC) [40], UBCS is of greater efï¬ciency as it necessitates fewer operations (more discussions are shown in the Appendix). UBCS can achieve greater computational efï¬ciency via instantiating multiple UBCS coders in parallel with multi-threading. Table 1 demonstrates that UBCS achieves coding bandwidths in excess of giga-symbol/s â€“ speed signiï¬cantly greater than rANS.

Table 1: Coding bandwidth (M symbol/s) of UBCS and rANS coder on different threads(thrd). We use the implementations in [17] for evaluating rANS.

# thrd rANS UBCS

Encoder 1

5.1Â±0.3

380Â±5

16 21.6Â±1.1 2075Â±353

Decoder

1

0.8Â±0.02 66.2Â±1.7

16

7.4Â±0.5 552Â±50

4 Experiments

In this section, we perform a number of experiments to establish the effectiveness of iFlow. We will investigate: (1) how closely the codelength matches the theoretical bound; (2) the efï¬ciency of iFlow as compared with the LBB [17] baseline; (3) the compression performance of iFlow on a series low and high-resolution images.

4.1 Flow Architectures and Datasets
We adopt two types of ï¬‚ow architectures for evaluation: Flow++ [16] and iVPF [41]. Flow++ is a state-of-the-art model using complex non-linear coupling layers and variational dequantizations [19]. iVPF is derived from a volume-preserving ï¬‚ow in which numerically invertible discrete-space operations are introduced. The models are re-implemented or directly taken from the corresponding authors. Unless speciï¬ed, we use h = 12, k = 28 and set large S â€“ around 216, which we analyse further in the Appendix. To reduce the auxiliary bits in the bits-back coding scheme, we partition the d-dimensional data into b splits and perform MST (in Alg. 1 and 2) for each split sequentially. In this case, the auxiliary bits can be reduced to 1/b in MST. We use b = 4 in this experiment.
Following the lossless compression community [16, 4, 18, 37, 41], we perform evaluation using toy datasets CIFAR10, ImageNet32 and ImageNet64. Results for alternate methods are obtained via re-implementation or taken directly from the corresponding papers, where available. We further test the generalization capabilities of iFlow in which all toy datasets are compressed with a model trained on ImageNet32. For benchmarking our performance on high-resolution images, we evaluate iFlow using CLIC.mobile, CLIC.pro2 and DIV2k [1]. For this purpose, we adopt our ImageNet32/64 model for evaluation, and process an image in terms of 32 Ã— 32 or 64 Ã— 64 patches, respectively. The experiment is conducted with PyTorch framework with one Tesla P100 GPU.
2https://www.compression.cc/challenge/

8

Table 3: Compression performance in bpd on benchmarking datasets. â€  denotes the generation performance in which the models are trained on ImageNet32 and tested on other datasets. â€¡ denotes
compression of high-resolution datasets with our ImageNet64-trained model.

PNG [5] FLIF [36] JPEG-XL [2]
L3C [30] RC [31] Bit-Swap [26]
IDF [18] IDF++ [4] iVPF [41] LBB [17] iFlow (Ours)
HiLLoC [37]â€  IDF [18]â€  iVPFâ€  [41] iFlow (Ours)â€ 

ImageNet32
6.39 4.52 6.39
4.76 -
4.50
4.18 4.12 4.03 3.88 3.88
4.20 4.18 4.03 3.88

ImageNet64
5.71 4.19 5.74
4.42 -
3.90 3.81 3.75 3.70 3.70
3.90 3.94 3.79 3.65

CIFAR10
5.87 4.19 5.89
3.82
3.34 3.26 3.20 3.12 3.12
3.56 3.60 3.49 3.36

CLIC.mobile
3.90 2.49 2.36
2.64 2.54
-
-
2.47/2.39â€¡ 2.26/2.26â€¡

CLIC.pro
4.00 2.78 2.63
2.94 2.93
-
-
2.63/2.54â€¡ 2.45/2.44â€¡

DIV2K
3.09 2.91 2.79
3.09 3.08
-
-
2.77/2.68â€¡ 2.60/2.57â€¡

4.2 Compression Performance
For our experiments, we use the evaluation protocols of codelength and compression bandwidth. The codelength is deï¬ned in terms of the average bits per dimension (bpd). For no compression, the bpd is assumed to be 8. The compression bandwidth evaluates coding efï¬ciency, which we deï¬ne in terms of symbols compressed per unit time.
Table 2 demonstrates the compression results on CIFAR10. Note that we only report the encoding time (results on decoding time are similar, and are available in the Appendix). For iVPF, we use settings almost identical to the original paper [41] such that k = 14.
Firstly, we observe that, when using both the Flow++ and iVPF architectures, iFlow achieves a bpd very close to theoretically minimal codelength. When using Flow++, iFlow achieves identical performance as that of LBB. For the iVPF architecture, iFlow outperforms the underlying iVPF as it avoids the need to store 16 bits for each data sample.
Secondly, the coding latency highlights the main advantage of iFlow: we achieve encoding 5Ã— faster than that of LBB and over 1.5Ã— that of iVPF. In fact, the use of UBCS only represents 20% of the total coding time for all symbols (4.8ms in Flow++ and 1.6ms in iVPF). In contrast, the rANS coder of LBB commands over 85% of the total coding latency, which is the principal cause of LBBâ€™s impracticality. Indeed, Table 1 demonstrates that our UBCS coder achieves a speed-up in excess of 50Ã— that of rANS (which results in a coder latency of 4.8ms in iFlow vs. 99.8ms in LBB).
Lastly, compared with LBB, iFlow necessitates fewer auxiliary bits. In fact, LBB requires crica 2k + log Ïƒ bits per dimension (for Î´ = 2âˆ’k and small Ïƒ in [17]). Meanwhile, iFlow requires approximately k + 1b log S, and 1b log S is usually small with large b.
4.3 Comparison with the State-of-the-Art
To further demonstrate the effectiveness of iFlow, we compare the compression performance on benchmarking datasets against a variety of neural compression techniques. These include, L3C [30], Bit-swap [26], HilLoc [37], and ï¬‚ow-based models IDF [18], IDF++ [4], iVPF [41], LBB [17]. We additionally include a number of conventional methods, such as PNG [5], FLIF [36] and JPEG-XL [2].
Experiments on Low Resolution Images. Compression results on our described selection of datasets are available in left three columns of Table 3. Here we observe that iFlow obtains improved compression performance over all approaches with the exception of LBB on low-resolution images, for which we achieve identical results.
9

Generalization. The last four rows in Table 3 demonstrate the literature-standard test of generalization, in which ImageNet32 trained model are used for testing. From these results, it is clear that iFlow achieves the best generalization performance in this test. It is worth noting that we obtain an improved performance on ImageNet64 when using our ImageNet32-trained model.
Experiments on High Resolution Images. Finally, we test iFlow across a number of high-resolution image datasets. Here images are processed into non-overlapping 32 Ã— 32 and 64 Ã— 64 patches for our ImageNet32 and ImageNet64-trained models. The right three columns in Table 3 display the results, which is observed that iFlow outperforms all compression methods across all available benchmarks. Note that as we crop patches for compression, the compression bandwidth is the same as that in small images like CIFAR10, i.e., 5 times faster than LBB and 30% speedup compared with iVPF.
5 Related Work
Dynamic Entropy coders, such as Arithmetic Coding (AC) [40] and Asymmetric Numerical Systems (ANS) [12], form the basis of lossless compression. However, the binary search protocol required at decode time and their comparatively high number of numerical operations make them both relatively time-consuming. The term dynamic means that the data symbols are in different distributions, in this case, efï¬cient entropy coders like Huffman coding [21] and tANS [12] are incompatible. Our proposed UBCS is dynamic coder, which requires only two operations per symbol, producing an faster algorithm than AC and ANS.
In order to utilise entropy coders, one must estimate the data distribution. For this purpose, the wider community has employed a variety of density estimators. One of the most popular, autoregressive models [35], estimates the joint density with per-pixel autoregressive factorizations. Whilst commonly achieving state-of-the-art compression ratios, the sequential pixel-by-pixel nature of encoding and/or decoding makes them impractically time-consuming. Alternatively, variational autoencoders (VAEs) [24, 26, 37] maximise a lower bound on the marginal data likelihood (otherwise known as the ELBO). With the bits-back coding framework [38], the theoretical codelength is exactly equal to the ELBO. However, in most cases, VAE formulations typically produce inferior compression ratios as there exists a gap between the ELBO and the true data likelihood.
As discussed, ï¬‚ow-based models [16, 25, 11], which admit exact likelihood computation, represent an alternative route for density estimation. IDF [18] and IDF++ [4] proposed the titular integer discrete ï¬‚ow to preserve the existence and uniqueness of an invertible mapping between discrete data and latent variables. In a similar vein, iVPF [41] achieved a mapping with volume-preserving ï¬‚ows. Here the remainders of a division operation are stored as auxiliary states to eliminate the numerical error arising from discretizing latent variables. However, all of these models must introduce constraints on the underlying transform, limiting their representational power. LBB [17] was the ï¬rst ï¬‚owbased lossless compression approach to admit a broad class of invertible ï¬‚ows based on continuous transforms. LBB established this family of ï¬‚exible bijections by introducing local bits-back coding techniques to encode numerical errors. However, LBB typical requires the coding of many such errors and does so with the ANS scheme, posing obvious challenges to computational efï¬ciency.
6 Conclusions and Discussions
In this paper, we have proposed iFlow, a numerically invertible ï¬‚ow-based model for achieving efï¬cient lossless compression with state-of-the-art compression ratios. To achieve this, we have introduced the Modular Scale Transform and Uniform Base Conversion Systems, which jointly permit an efï¬cient bijection between discrete data and latent variables. Experiments demonstrate that the codelength comes extremely close to the theoretically minimal value, with compression achieved much faster than the next-best high-performance scheme. Moreover, iFlow is able to achieve state-of-the-art compression ratios on real-word image benchmarks.
We additionally consider the potential for extending iFlow. That is, recent advances in normalizing ï¬‚ows have achieved improved generation performance across various data types [28, 7, 23]. We have discussed the possible extension to incorporate these advancements in Sec. 2.6, and consider its application as future work. We further recognise that compression aproaches, of which iFlow is one, present signiï¬cant data privacy issues. That is, the generative model used for compression may induce data leakage; therefore, the codec should be treated carefully as to observe data-privacy laws.
10

References
[1] Eirikur Agustsson and Radu Timofte. Ntire 2017 challenge on single image super-resolution: Dataset and study. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pages 126â€“135, 2017.
[2] Jyrki Alakuijala, Ruud van Asseldonk, Sami Boukortt, Martin Bruse, Iulia-Maria Coms, a, Moritz Firsching, Thomas Fischbacher, Evgenii Kliuchnikov, Sebastian Gomez, Robert Obryk, et al. Jpeg xl next-generation image compression architecture and coding tools. In Applications of Digital Image Processing XLII, volume 11137, page 111370K. International Society for Optics and Photonics, 2019.
[3] Jens Behrmann, Paul Vicol, Kuan-Chieh Wang, Roger Grosse, and JÃ¶rn-Henrik Jacobsen. Understanding and mitigating exploding inverses in invertible neural networks. arXiv preprint arXiv:2006.09347, 2020.
[4] Rianne van den Berg, Alexey A Gritsenko, Mostafa Dehghani, Casper Kaae SÃ¸nderby, and Tim Salimans. Idf++: Analyzing and improving integer discrete ï¬‚ows for lossless compression. arXiv preprint arXiv:2006.12459, 2020.
[5] Thomas Boutell and T Lane. Png (portable network graphics) speciï¬cation version 1.0. Network Working Group, pages 1â€“102, 1997.
[6] Sheng Cao, Chao-Yuan Wu, and Philipp KrÃ¤henbÃ¼hl. Lossless image compression through super-resolution. arXiv preprint arXiv:2004.02872, 2020.
[7] Jianfei Chen, Cheng Lu, Biqi Chenli, Jun Zhu, and Tian Tian. Vï¬‚ow: More expressive generative ï¬‚ows with variational data augmentation. In International Conference on Machine Learning, pages 1660â€“1669. PMLR, 2020.
[8] Rewon Child. Very deep vaes generalize autoregressive models and can outperform them on images. arXiv preprint arXiv:2011.10650, 2020.
[9] Yann Collet and Chip Turner. Smaller and faster data compression with zstandard. Facebook Code [online], 2016.
[10] Laurent Dinh, David Krueger, and Yoshua Bengio. Nice: Non-linear independent components estimation. arXiv preprint arXiv:1410.8516, 2014.
[11] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation using real nvp. arXiv preprint arXiv:1605.08803, 2016.
[12] Jarek Duda. Asymmetric numeral systems: entropy coding combining speed of huffman coding with compression rate of arithmetic coding. arXiv preprint arXiv:1311.2540, 2013.
[13] GMDT Forecast. Cisco visual networking index: global mobile data trafï¬c forecast update, 2018â€“2023. Update, 2018:2023, 2010.
[14] Philip Gage. A new algorithm for data compression. C Users Journal, 12(2):23â€“38, 1994.
[15] Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-vae: Learning basic visual concepts with a constrained variational framework. 2016.
[16] Jonathan Ho, Xi Chen, Aravind Srinivas, Yan Duan, and Pieter Abbeel. Flow++: Improving ï¬‚ow-based generative models with variational dequantization and architecture design. arXiv preprint arXiv:1902.00275, 2019.
[17] Jonathan Ho, Evan Lohn, and Pieter Abbeel. Compression with ï¬‚ows via local bits-back coding. In Advances in Neural Information Processing Systems, pages 3879â€“3888, 2019.
[18] Emiel Hoogeboom, Jorn Peters, Rianne van den Berg, and Max Welling. Integer discrete ï¬‚ows and lossless compression. In Advances in Neural Information Processing Systems, pages 12134â€“12144, 2019.
[19] Emiel Hoogeboom, Taco S Cohen, and Jakub M Tomczak. Learning discrete distributions by dequantization. arXiv preprint arXiv:2001.11235, 2020.
[20] Chin-Wei Huang, David Krueger, Alexandre Lacoste, and Aaron Courville. Neural autoregressive ï¬‚ows. In Proceedings of the 35th International Conference on Machine Learning, volume 80, pages 2078â€“2087. PMLR, 2018.
11

[21] David A Huffman. A method for the construction of minimum-redundancy codes. Proceedings of the IRE, 40(9):1098â€“1101, 1952.
[22] Heewoo Jun, Rewon Child, Mark Chen, John Schulman, Aditya Ramesh, Alec Radford, and Ilya Sutskever. Distribution augmentation for generative modeling. In International Conference on Machine Learning, pages 5006â€“5019. PMLR, 2020.
[23] Hyeongju Kim, Hyeonseung Lee, Woo Hyun Kang, Joun Yeop Lee, and Nam Soo Kim. Softï¬‚ow: Probabilistic framework for normalizing ï¬‚ow on manifolds. Advances in Neural Information Processing Systems, 33, 2020.
[24] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.
[25] Durk P Kingma and Prafulla Dhariwal. Glow: Generative ï¬‚ow with invertible 1x1 convolutions. In Advances in neural information processing systems, pages 10215â€“10224, 2018.
[26] Friso H Kingma, Pieter Abbeel, and Jonathan Ho. Bit-swap: Recursive bits-back coding for lossless compression with hierarchical latent variables. arXiv preprint arXiv:1905.06845, 2019.
[27] Manoj Kumar, Mohammad Babaeizadeh, Dumitru Erhan, Chelsea Finn, Sergey Levine, Laurent Dinh, and Durk Kingma. Videoï¬‚ow: A ï¬‚ow-based generative model for video. arXiv preprint arXiv:1903.01434, 2 (5), 2019.
[28] Phillip Lippe and Efstratios Gavves. Categorical normalizing ï¬‚ows via continuous transformations. arXiv preprint arXiv:2006.09790, 2020.
[29] David JC MacKay and David JC Mac Kay. Information theory, inference and learning algorithms. Cambridge university press, 2003.
[30] Fabian Mentzer, Eirikur Agustsson, Michael Tschannen, Radu Timofte, and Luc Van Gool. Practical full resolution learned lossless image compression. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 10629â€“10638, 2019.
[31] Fabian Mentzer, Luc Van Gool, and Michael Tschannen. Learning better lossless compression using lossy compression. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 6638â€“6647, 2020.
[32] Ryan Prenger, Rafael Valle, and Bryan Catanzaro. Waveglow: A ï¬‚ow-based generative network for speech synthesis. In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 3617â€“3621. IEEE, 2019.
[33] Majid Rabbani. Jpeg2000: Image compression fundamentals, standards and practice. Journal of Electronic Imaging, 11(2):286, 2002.
[34] Greg Roelofs and Richard Koman. PNG: the deï¬nitive guide. Oâ€™Reilly & Associates, Inc., 1999.
[35] Tim Salimans, Andrej Karpathy, Xi Chen, and Diederik P Kingma. Pixelcnn++: Improving the pixelcnn with discretized logistic mixture likelihood and other modiï¬cations. arXiv preprint arXiv:1701.05517, 2017.
[36] Jon Sneyers and Pieter Wuille. Flif: Free lossless image format based on maniac compression. In 2016 IEEE International Conference on Image Processing (ICIP), pages 66â€“70. IEEE, 2016.
[37] James Townsend, Thomas Bird, Julius Kunze, and David Barber. Hilloc: Lossless image compression with hierarchical latent variable models. arXiv preprint arXiv:1912.09953, 2019.
[38] James Townsend, Tom Bird, and David Barber. Practical lossless compression with latent variables using bits back coding. arXiv preprint arXiv:1901.04866, 2019.
[39] Aaron Van den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex Graves, et al. Conditional image generation with pixelcnn decoders. In Advances in neural information processing systems, pages 4790â€“4798, 2016.
[40] Ian H Witten, Radford M Neal, and John G Cleary. Arithmetic coding for data compression. Communications of the ACM, 30(6):520â€“540, 1987.
[41] Shifeng Zhang, Chen Zhang, Ning Kang, and Zhenguo Li. ivpf: Numerical invertible volume preserving ï¬‚ow for efï¬cient lossless compression. arXiv preprint arXiv:2103.16211, 2021.
12

A Proofs
A.1 Correctness of MST (Alg. 1)
As xÂ¯, zÂ¯ are quantized to k-precision, xË† and xÂ¯ form a bijection, and so do zË† and zÂ¯. Thus MST is correct if and only if xË† and zË† are valid bijections. In particular, denoting xË†d = (S Â· zË† + re)/R , rdd = (S Â· zË† + re) mod R, we will show xË†d â‰¡ xË†, rdd â‰¡ rd. In fact, according to forward MST, zË† = (R Â· xË† + rd)/S , re = (R Â· xË† + rd) mod S, thus S Â· zË† + re = R Â· xË† + rd. Considering re is ï¬rst accurately decoded by inverse MST (in Line 2), it is clear that xË†d = (S Â·zË†+re)/R = (RÂ·xË†+rd)/R = xË†, and rdd = (S Â·zË†+re) mod R = (RÂ·xË†+rd) mod R = rd. Thus the correctness of MST is proven.

A.2 Propositions 1-2 in MST (Alg. 1)
Firstly, as S Â· a âˆ’ 0.5 â‰¤ R < S Â· a + 0.5, we have |a âˆ’ RS | â‰¤ 0S.5 = O(Sâˆ’1). Secondly, as zÂ¯ = (R Â· 2k Â· xÂ¯ + rd)/S /2k where rd âˆˆ [0, R), we have zÂ¯ < (R Â· 2k Â· xÂ¯ + R)/(S Â· 2k) = R/SÂ·xÂ¯+(Râˆ’1)/(SÂ·2k) and zÂ¯ > (RÂ·2k Â·xÂ¯/Sâˆ’1)/2k = R/SÂ·xÂ¯âˆ’2âˆ’k, thus |zÂ¯âˆ’R/SÂ·xÂ¯| < O(2âˆ’k). Then the error between zÂ¯ and f (xÂ¯) is |zÂ¯ âˆ’ a Â· xÂ¯| â‰¤ |zÂ¯ âˆ’ R/S Â· xÂ¯| + |(a âˆ’ R/S) Â· xÂ¯| = O(Sâˆ’1, 2âˆ’k); therefore, Proposition 1 holds.
For Proposition 2, decoding from U (0, R) involves âˆ’ log R bits, and encoding U (0, S) involves log S bits. As |a âˆ’ R/S| < O(Sâˆ’1) and f (xÂ¯) = a, the codelength of MST is Lf (xÂ¯, zÂ¯) = log S âˆ’ log R = âˆ’ log |a + O(Sâˆ’1)| = âˆ’ log |f (xÂ¯)| + O(Sâˆ’1) â‰ˆ âˆ’ log |f (xÂ¯)|. Thus Proposition 2 holds.

A.3 Correctness of our Invertible Non-linear Flows (Alg. 2)

If the interpolation interval [xÂ¯l, xÂ¯h) and [zÂ¯l, zÂ¯h)(zÂ¯l = f (xÂ¯l), zÂ¯l = f (xÂ¯h)) are identical in both the forward and inverse processes, finp is additionally identical in both the forward and inverse processes. Consequently, an exact bijection with MST algorithm is trivially achieved. Thus we principally seek to show that the interpolation interval can be correctly determined. Before the proof, it must be emphasised that the interpolation interval should demonstrate the following properties:

1. The interpolation interval is counted and covers the domain/co-domain. xÂ¯l, xÂ¯h must be within the discretized set such that xÂ¯l, xÂ¯h âˆˆ Xinp (e.g. Xinp = {2âˆ’h Â· n, n âˆˆ Z});
2. The interpolation interval must be not intersected. There does not exist x such that x âˆˆ [xÂ¯l, xÂ¯h) and x âˆˆ Xinp \ {xÂ¯l}.

Firstly, we show that in the forward computation, zÂ¯ will always be within [zÂ¯l, zÂ¯h). In fact, zÂ¯ = RÂ·2k(xÂ¯âˆ’SxÂ¯l)+rd /2k+zÂ¯l where rd âˆˆ [0, R). As xÂ¯ â‰¥ xÂ¯l, zÂ¯ â‰¥ RÂ·0S+0 /2k+zÂ¯l = zÂ¯l. As xÂ¯ â‰¤ xÂ¯hâˆ’2âˆ’k,
zÂ¯ â‰¤ RÂ·2k(xÂ¯hâˆ’xÂ¯lSâˆ’2âˆ’k)+Râˆ’1 /2k +zÂ¯l, following from Eq. (4) it is clear that zÂ¯ â‰¤ zÂ¯h âˆ’2âˆ’k. Therefore, it holds that zÂ¯ âˆˆ [zÂ¯l, zÂ¯h).

Secondly, we show that during the inverse computation, the interpolation intervals [xÂ¯l, xÂ¯h) and

[zÂ¯l, zÂ¯h) are the same as that in the forward process. In other words, if the interpolation interval is

[xÂ¯dl , xÂ¯dh), [zÂ¯ld, zÂ¯hd) given zÂ¯,

it holds that xÂ¯dl

â‰¡

xÂ¯l

,

xÂ¯

d h

â‰¡

xÂ¯h.

In fact,

xÂ¯dl

â‰¥

xÂ¯h

is not preserved,

as

f (xÂ¯dl ) â‰¥ zÂ¯. It then follows that zÂ¯ could not be in [zÂ¯ld, zÂ¯hd). Similarly, xÂ¯h â‰¤ xÂ¯l is not preserved â€“

otherwise f (xÂ¯dh) â‰¤ zÂ¯ and zÂ¯ could not be in [zÂ¯ld, zÂ¯hd). Overall, xÂ¯dl < xÂ¯h and xÂ¯dh > xÂ¯l, such that only xÂ¯dl = xÂ¯l, xÂ¯dh = xÂ¯h satisfy this condition.

A.4 Propositions 1-2 in Invertible Non-linear Flows (Alg. 2)
In general, f (x), f (x) is bounded for all x. Consider f (xÂ¯) in the small interval such that xÂ¯h âˆ’ xÂ¯l â‰¤ 2âˆ’h or zÂ¯h âˆ’ zÂ¯l â‰¤ 2âˆ’h (k h). We ï¬rst prove the following two propositions in [xÂ¯l, xÂ¯h):
1. |f (xÂ¯) âˆ’ xÂ¯zÂ¯hhâˆ’âˆ’xzÂ¯Â¯ll | < O(2âˆ’h, 2hâˆ’k); 2. |finp(xÂ¯) âˆ’ f (xÂ¯)| < O(2âˆ’2h, 2âˆ’k)

13

In fact, by performing the Taylor expansion at xÂ¯, we have f (xÂ¯l) = f (xÂ¯) + (xÂ¯l âˆ’ xÂ¯) Â· f (xÂ¯) + (xÂ¯lâˆ’2xÂ¯)2 Â· f (Î¾l) and f (xÂ¯h) = f (xÂ¯) + (xÂ¯h âˆ’ xÂ¯) Â· f (xÂ¯) + (xÂ¯hâˆ’2 xÂ¯)2 Â· f (Î¾h), where Î¾h, Î¾l âˆˆ (xÂ¯l, xÂ¯h).
Firstly, f (xÂ¯h) âˆ’ f (xÂ¯l) = (xÂ¯h âˆ’ xÂ¯l) Â· f (x) + [ (xÂ¯hâˆ’2 xÂ¯)2 Â· f (Î¾h) âˆ’ (xÂ¯lâˆ’2xÂ¯)2 Â· f (Î¾l)]. As f (x), f (x) are bounded, xÂ¯h âˆ’ xÂ¯l â‰¤ O(2âˆ’h), and we have f (xÂ¯h) âˆ’ f (xÂ¯l) = (xÂ¯h âˆ’ xÂ¯l) Â· f (x) + O(2âˆ’2h). As |zÂ¯l âˆ’ f (xÂ¯l)| < 2âˆ’k, |zÂ¯l âˆ’ f (xÂ¯l)| < 2âˆ’k, then |zÂ¯h âˆ’ zÂ¯l âˆ’ (xÂ¯h âˆ’ xÂ¯l) Â· f (x)| < O(2âˆ’k, 2âˆ’2h). Finally, |f (xÂ¯) âˆ’ xÂ¯zÂ¯hhâˆ’âˆ’zxÂ¯Â¯ll | < O(2âˆ’h, 2hâˆ’k).
Secondly, by denoting g(xÂ¯) = f(xÂ¯xÂ¯hh)âˆ’âˆ’xfÂ¯l(xÂ¯l) (xÂ¯âˆ’xÂ¯l)+f (xÂ¯l) and replacing f (xÂ¯l), f (xÂ¯h) with its Taylor expansion, we have g(xÂ¯) = f (xÂ¯) + 2(xÂ¯h1âˆ’xÂ¯l) (xÂ¯h âˆ’ xÂ¯)(xÂ¯ âˆ’ xÂ¯l)[(xÂ¯h âˆ’ xÂ¯)f (Î¾h) + (xÂ¯ âˆ’ xÂ¯l)f (Î¾l)]. As f (x) is bounded, |g(xÂ¯) âˆ’ f (xÂ¯)| < O(2âˆ’2h). Moreover, it is clear that |finp(xÂ¯) âˆ’ g(xÂ¯)| < O(2âˆ’k), and as such it ï¬nally holds that |finp(xÂ¯) âˆ’ f (xÂ¯)| < O(2âˆ’2h, 2âˆ’k).
For Proposition 1, with MST, we have zÂ¯ âˆ’ zÂ¯l = RÂ·2kÂ·(xÂ¯Sâˆ’xÂ¯l)+rd /2k where rd âˆˆ [0, R), thus |zÂ¯âˆ’zÂ¯lâˆ’ RS Â·(xÂ¯âˆ’xÂ¯l)| < O(2âˆ’k). Moreover, with Eq. (4), it is easy to arrive at that zÂ¯hâˆ’zÂ¯lâˆ’xÂ¯2hâˆ’âˆ’kxÂ¯(1l âˆ’Sâˆ’1) âˆ’ Sâˆ’1 < RS â‰¤ zÂ¯hâˆ’zÂ¯lâˆ’xÂ¯2hâˆ’âˆ’kxÂ¯(1l âˆ’Sâˆ’1) , and therefore | RS âˆ’ xÂ¯zÂ¯hhâˆ’âˆ’xzÂ¯Â¯ll | < O(Sâˆ’1, 2hâˆ’k). Overall, |zÂ¯ âˆ’ finp(xÂ¯)| = |(zÂ¯ âˆ’ zÂ¯l âˆ’ RS Â· (xÂ¯ âˆ’ xÂ¯l)) + (( RS âˆ’ xÂ¯zÂ¯hhâˆ’âˆ’zxÂ¯Â¯ll ) Â· (xÂ¯ âˆ’ xÂ¯l))| < O(Sâˆ’1, 2âˆ’k), and ï¬nally |zÂ¯ âˆ’ f (xÂ¯)| â‰¤ |zÂ¯ âˆ’ finp(xÂ¯)| + |finp(xÂ¯) âˆ’ f (xÂ¯)| < O(Sâˆ’1, 2âˆ’k, 2âˆ’2h).
For Proposition 2, with | RS âˆ’ xÂ¯zÂ¯hhâˆ’âˆ’zxÂ¯Â¯ll | < O(Sâˆ’1, 2hâˆ’k), it is clear that the expected codelength is Lf (xÂ¯, zÂ¯) = âˆ’ log(R/S) = âˆ’ log xÂ¯zÂ¯hhâˆ’âˆ’zxÂ¯Â¯ll + O(Sâˆ’1, 2hâˆ’k) = âˆ’ log |f (xÂ¯)| + O(Sâˆ’1, 2hâˆ’k, 2âˆ’h). Overall, Lf (xÂ¯, zÂ¯) â‰ˆ âˆ’ log |f (xÂ¯)| if S, k, h are large and k h.

A.5 Theorem 3 in UBCS (Alg. 5)

P1. We begin by showing that ci âˆˆ [2M , 2K+M) for all i = 0, ..., n with mathematical induction. In fact, when i = 0, c0 = 2M âˆˆ [2M , 2K+M ). When i = k and ck âˆˆ [2M , 2K+M ), denote câ—¦k+1 = ck Â· Rk+1 + sk+1. It is therefore clear that câ—¦k+1 = [2M Â· Rk+1, 2M+K Â· Rk+1). Note that Rk+1 < 2K and therefore 2M Â· Rk+1 < 2M+K . If câ—¦k+1 < 2K+M , ck+1 = câ—¦k+1 âˆˆ [2M Â· Rk+1, 2M+K ), it follows that câ—¦k+1 â‰¥ 2K+M , ck+1 = câ—¦k+1/2K âˆˆ [2M , 2K Â· Rk+1). Overall, ck+1 âˆˆ [2M , 2K+M ). Thus ci âˆˆ [2M , 2K+M ) for all i = 1, ..., n such that

ciâˆ’1 Â· Ri + si âˆˆ [2M Â· Ri, 2K+M ), ciâˆ’1 Â· Ri + si < 2K+M

ci = ciâˆ’12Â·RKi+si âˆˆ [2M , 2M Â· Ri),

ciâˆ’1 Â· Ri + si â‰¥ 2K+M

(10)

We will now demonstrate that si = si+1, ci = ci, bsi = bsi for all i = 0, ..., n âˆ’ 1. Denote câ—¦i = ciâˆ’1 Â· Ri + si.
(i) Consider i = n âˆ’ 1. (a) If cn < 2M Â· Rn, the last K bits (denoted by rn) will be popped from bsn and added to cn. In this case, according to Eq. (10), rn = câ—¦n mod 2K must be encoded to form bsn. Thus in the decoding process, rn is popped from bsn, and therefore bsnâˆ’1 = bsnâˆ’1, cnâˆ’1 = (2K Â·cn +rn)/Rn = câ—¦nâˆ’1/Rn = (cnâˆ’1 Â·Rn +snâˆ’1)/Rn = cnâˆ’1, and snâˆ’1 = (2K Â·cn +rn) mod Rn = (cnâˆ’1 Â· Rn + snâˆ’1) mod Rn = snâˆ’1. (b) If cn â‰¥ 2M Â· R, no bits are popped from bsn such that bsnâˆ’1 = bsn. In this case, according to Eq. (10), no bits are pushed to bsnâˆ’1 and therefore bsnâˆ’1 = bsn = bsnâˆ’1. In the decoding process, cnâˆ’1 = câ—¦nâˆ’1/Rn = cnâˆ’1, snâˆ’1 = câ—¦nâˆ’1 mod Rn = snâˆ’1. Overall, P1 holds for i = n âˆ’ 1.
(ii) If P1 holds for i = k, we will prove that P1 holds for i = k âˆ’ 1. (a) If ck < 2M Â· Rk, the last K bits will be popped from bsk and added to ck. In this case, in the encoding process, as ck = ck, according to Eq. (10), rk = câ—¦k mod 2K must be encoded to form bsk to obtain ck. In the decoding process, as bsk = bsk, rk is popped from bsk in the decoding process, it is therefore seen that bskâˆ’1 = bskâˆ’1. Finally we obtain ckâˆ’1 = (2K Â· ck + rk)/Rk = (2K Â·ck+rk)/Rk = câ—¦kâˆ’1/Rk = ckâˆ’1, and skâˆ’1 = (2K Â·ck+rk) mod Rk = (ckâˆ’1Â·Rn+skâˆ’1) mod Rn = skâˆ’1. (b) If ck â‰¥ 2M Â· R, no bits are popped from bsk such that bskâˆ’1 = bsk. In this case, in the encoding process, as ck = ck, according to Eq. (10), no bits are pushed to

14

bskâˆ’1 to obtain ck and therefore bskâˆ’1 = bsk = bsk = bskâˆ’1. In the decoding process, we have ckâˆ’1 = (ckâˆ’1 Â· Rk + skâˆ’1)/Rk = câ—¦kâˆ’1/Rk = ckâˆ’1, skâˆ’1 = (ckâˆ’1 Â· Rk + skâˆ’1) mod Rk = skâˆ’1. Overall, P1 holds for i = k âˆ’ 1. From (i)(ii), it is concluded that P1 holds by proof of mathematical induction.

P2. Denote that the lower K bits of ci need to be push to bsi at i = m1, ..., mT (mt < mt+1, mt âˆˆ {1, ..., n âˆ’ 1} for all t = 1, ..., T âˆ’ 1). In other words, we have

ci =

, ciâˆ’1 Â·Ri +si
2K

i âˆˆ {m1, ..., mT }

(11)

ciâˆ’1 Â· Ri + si, otherwise

Firstly, it is clear that len(bsmt+1 ) = len(bsmt )+K. Secondly, for any i âˆˆ {mt+1, ..., mt+1âˆ’ 1}, as ci = ciâˆ’1 Â· Ri + si, si âˆˆ [0, Ri), it is clear that ciâˆ’1 Â· Ri â‰¤ ci â‰¤ ciâˆ’1 Â· Ri + Ri âˆ’ 1. Thus cmt Â· m i=tm+1tâˆ’+11 Ri â‰¤ cmt+1âˆ’1 â‰¤ (cmt + 1) Â· m i=tm+1tâˆ’+11 Ri âˆ’ 1, and therefore

cmt Â·

R mt+1
i=mt+1 i
2K

â‰¤ cmt+1 â‰¤

(cmt + 1) Â· m i=tm+1t+1 Ri âˆ’ 1 . 2K

(12)

Note that the above inequality also holds for t = 0 in which m0 = 0. With Eq. (12), log cmt+1 â‰¤

(cmt +1)Â· m i=tm+1+1 Riâˆ’1

(cmt +1)Â· m i=tm+1+1 Ri

mt+1

log

t
2K

< log

t
2K

= log cmt + i=mt+1 log Ri + log(1 +

câˆ’m1t ) âˆ’ K < log cmt + im=tm+1t+1 log Ri + (ln 2 Â· cmt )âˆ’1 âˆ’ K. As cmt âˆˆ [2M , 2M Â· Rmt ), it holds

that

mt+1

log cmt+1 + len(bsmt+1 ) < log cmt + len(bsmt ) +

log Ri + (ln 2 Â· 2M )âˆ’1 (13)

i=mi +1

If mT = n, log cn+len(bsn) = log cmT +len(bsmT ); otherwise, len(bsn) = len(bsmT ) and log cn â‰¤ log(cmT + 1) + ni=mT +1 Ri < log cmT + ni=mT +1 Ri + (ln 2 Â· 2M )âˆ’1. Overall, we ï¬nally obtain
n
log cn + len(bsn) < log c0 + len(bs0) + log Ri + (T + 1) Â· (ln 2 Â· 2M )âˆ’1 (14)
i=1

Note that as cn â‰¥ 2M = c0, len(bsn) = T K and l0 = M = log c0 + len(bs0), it is clear that log cn + len(bsn) > T K + l0. With Eq. (14), the codelength is ï¬nally computed as

1 ln âˆ’ l0 â‰¤ log cn + len(bsn) âˆ’ l0 + 1 <

n
Ri + 1 + (ln 2 Â· 2M )âˆ’1 (15)

1 âˆ’ 1/(ln 2 Â· 2M Â· K)

i=1

which completes the proof.

B Details of Alg. 2 in iFlow
The main difï¬culty is in determining the interpolation interval [xÂ¯l, xÂ¯h), [zÂ¯l, zÂ¯h) given xÂ¯ or zÂ¯. The main paper discusses two interpolation tricks: (1) interpolating uniform intervals in domain x and (2) interpolating uniform intervals in co-domain z.
Interpolating uniform intervals in x. This usually applies in the case that f is large (e.g. inverse sigmoid). The uniform interval in domain x is deï¬ned as xÂ¯l = (2h Â· xÂ¯)/2h , xÂ¯h = xÂ¯l + 2âˆ’h. The corresponding interval in the co-domain is zÂ¯l = f (xÂ¯l), zÂ¯h = f (xÂ¯h). For the forward pass, given xÂ¯, the interval can be obtained as above. For the inverse pass, we ï¬rst compute x = f âˆ’1(zÂ¯) and then compute xÂ¯m = round(2h Â· x )/2h, xÂ¯l = xÂ¯m âˆ’ 2âˆ’h, xÂ¯h = xÂ¯m + 2âˆ’h. Finally, we have zÂ¯{l,m,h} = f (xÂ¯{l,m,h}). If zÂ¯ < zÂ¯m, we set the interval xÂ¯l = xÂ¯l, xÂ¯h = xÂ¯m; otherwise xÂ¯l = xÂ¯m, xÂ¯h = xÂ¯h. The method is summarized in Alg. 6.
The correctness of the algorithm is guaranteed provided that f is Lipchitz continuous and the numerical error between f âˆ’1(f (xÂ¯)) and x is limited. Let |f âˆ’1(f (x)) âˆ’ x| < for all x and

15

Algorithm 6 Uniform interpolating interval x in numerically invertible element-wise ï¬‚ows.

Determine xÂ¯l, xÂ¯h, zÂ¯l, zÂ¯h given xÂ¯. 1: xÂ¯l = (2h Â· xÂ¯)/2h , xÂ¯h = xÂ¯l + 2âˆ’h; 2: zÂ¯l = f (xÂ¯l), zÂ¯h = f (xÂ¯h); 3: return xÂ¯l, xÂ¯h, zÂ¯l, zÂ¯h.
Determine xÂ¯l, xÂ¯h, zÂ¯l, zÂ¯h given zÂ¯. 1: x = f âˆ’1(zÂ¯);

2: xÂ¯m = round(2h Â· x )/2h, xÂ¯l = xÂ¯m âˆ’ 2âˆ’h, xÂ¯h = xÂ¯m + 2âˆ’h;
3: zÂ¯{l,m,h} = f (xÂ¯{l,m,h});
4: if zÂ¯ < zÂ¯m then 5: xÂ¯l = xÂ¯l, xÂ¯h = xÂ¯m, zÂ¯l = zÂ¯l, zÂ¯h = zÂ¯m; 6: else
7: xÂ¯l = xÂ¯m, xÂ¯h = xÂ¯h, zÂ¯l = zÂ¯m, zÂ¯h = zÂ¯h 8: end if
9: return xÂ¯l, xÂ¯h, zÂ¯l, zÂ¯h.

|f âˆ’1(x1) âˆ’ f âˆ’1(x2)| < Âµ|x1 âˆ’ x2| for all x1, x2. We will show that Alg. 6 is correct if Îµ =

2âˆ’kÂµ + < 2âˆ’hâˆ’1. In fact, it is clear that |f âˆ’1(zÂ¯l) âˆ’ xÂ¯l| â‰¤ |f âˆ’1(zÂ¯l) âˆ’ f âˆ’1(f (xÂ¯l))| + |xÂ¯l âˆ’

f âˆ’1(f (xÂ¯l))| < 2âˆ’kÂµ + = Îµ. Similarly, |f âˆ’1(zÂ¯h) âˆ’ xÂ¯h| < Îµ. As f âˆ’1 is monotonically increasing

and zÂ¯ âˆˆ (zÂ¯l, zÂ¯h), it is clear that x = f âˆ’1(zÂ¯) âˆˆ [xÂ¯l âˆ’ Îµ, xÂ¯h + Îµ). As |xÂ¯m âˆ’ x | â‰¤ 2âˆ’hâˆ’1, we have xÂ¯m âˆˆ (xÂ¯l âˆ’ Îµ âˆ’ 2âˆ’hâˆ’1, xÂ¯h + Îµ + 2âˆ’hâˆ’1). (i) When zÂ¯ < zÂ¯m, it corresponds to xÂ¯ < xÂ¯m. As xÂ¯ âˆˆ [xÂ¯l, xÂ¯h), it is clear that xÂ¯m âˆˆ (xÂ¯l, xÂ¯h + Îµ + 2âˆ’hâˆ’1) = (xÂ¯h âˆ’ 2âˆ’h, xÂ¯h + Îµ + 2âˆ’hâˆ’1). Note that xÂ¯m, xÂ¯h âˆˆ {2âˆ’h Â· n, n âˆˆ Z} when Îµ < 2âˆ’hâˆ’1; therefore, it must hold that xÂ¯m = xÂ¯h. (ii) When zÂ¯ â‰¥ zÂ¯m, it corresponds to xÂ¯ â‰¥ xÂ¯m. It is clear that xÂ¯m âˆˆ (xÂ¯l âˆ’Îµâˆ’2âˆ’hâˆ’1, xÂ¯h) = (xÂ¯l âˆ’Îµâˆ’2âˆ’hâˆ’1, xÂ¯l +2âˆ’h)

â€“ thus it must hold that xÂ¯m = xÂ¯l. In fact, as h Îµ < 2âˆ’hâˆ’1, the correctness of Alg. 6 follows.

k, Âµ is bounded and is rather small, such that

Algorithm 7 Uniform interpolating interval z in numerically invertible element-wise ï¬‚ows.

Determine xÂ¯l, xÂ¯h, zÂ¯l, zÂ¯h given xÂ¯.
1: z = f (zÂ¯); 2: zÂ¯m = round(2h Â· z )/2h, zÂ¯l = zÂ¯m âˆ’ 2âˆ’h, zÂ¯h =
zÂ¯m + 2âˆ’h; 3: xÂ¯{l,m,h} = f âˆ’1(zÂ¯{l,m,h});
4: if xÂ¯ < xÂ¯m then 5: xÂ¯l = xÂ¯l, xÂ¯h = xÂ¯m, zÂ¯l = zÂ¯l, zÂ¯h = zÂ¯m; 6: else

7: xÂ¯l = xÂ¯m, xÂ¯h = xÂ¯h, zÂ¯l = zÂ¯m, zÂ¯h = zÂ¯h 8: end if 9: return xÂ¯l, xÂ¯h, zÂ¯l, zÂ¯h.
Determine xÂ¯l, xÂ¯h, zÂ¯l, zÂ¯h given zÂ¯. 1: zÂ¯l = (2h Â· zÂ¯)/2h , zÂ¯h = zÂ¯l + 2âˆ’h; 2: xÂ¯l = f âˆ’1(xÂ¯l), xÂ¯h = f âˆ’1(zÂ¯h); 3: return xÂ¯l, xÂ¯h, zÂ¯l, zÂ¯h.

Interpolating uniform intervals in z. This usually applies in the case that f is small (e.g. sigmoid). The uniform interval in co-domain z is deï¬ned as zÂ¯l = (2h Â· zÂ¯)/2h , zÂ¯h = zÂ¯l + 2âˆ’h.
The corresponding interval in the domain is xÂ¯l = f âˆ’1(zÂ¯l), xÂ¯h = f âˆ’1(zÂ¯h). For the inverse pass given zÂ¯, the interval can be obtained as above. For the forward pass, we ï¬rst compute z = f (xÂ¯), and then
compute zÂ¯m = round(2h Â· z )/2h, zÂ¯l = zÂ¯m âˆ’ 2âˆ’h, zÂ¯h = zÂ¯m + 2âˆ’h, and xÂ¯{l,m,h} = f âˆ’1(zÂ¯{l,m,h}).
If xÂ¯ < xÂ¯m, we set the interval zÂ¯l = zÂ¯l, zÂ¯h = zÂ¯m; otherwise zÂ¯l = zÂ¯m, zÂ¯h = zÂ¯h. The method is summarized in Alg. 7.

Similarly as in Alg. 6, the correctness of Alg. 7 is ensured by h The proof is very similar as to that of Alg. 6.

k and the limited numerical errors.

C Extensions of iFlow

Algorithm 8 Lossless Compression with Flows.
Encode xâ—¦. 1: Decode vÂ¯ using q(vÂ¯|xâ—¦)Î´; 2: zÂ¯ â† fÂ¯(vÂ¯); 3: Encode zÂ¯ using pZ (zÂ¯)Î´; 4: Encode xâ—¦ using P (xâ—¦|vÂ¯).

Decode.
1: Decode zÂ¯ using pZ (zÂ¯)Î´; 2: vÂ¯ â† fÂ¯âˆ’1(zÂ¯); 3: Decode xâ—¦ using P (xâ—¦|vÂ¯); 4: Encode vÂ¯ using q(vÂ¯|xâ—¦)Î´; 5: return xâ—¦.

16

The extension of iFlow for lossless compression is summarized in Alg. 8. Note that for Variational Dequantization Flow [19, 17] (Alg. 4), v = xâ—¦ + u(u âˆˆ [0, 1)d), q(v|xâ—¦) = q(u|xâ—¦), P (xâ—¦|v) =
1. Thus the above coding procedure reduces to Alg. 4.

D Dynamic Uniform Entropy Coder in AC, ANS and UBCS

In this section we will demonstrate the effectiveness of UBCS compared with AC and ANS. Both AC and ANS use probability mass function (PMF) and cumulative distribution function (CDF) for encoding and inverse CDF for decoding. For ease of coding, the PMF and CDF are all mapped to integers in [0, m). For uniform distribution U (0, R) in which P (s) = 1/R, s âˆˆ {0, 1, ..., R âˆ’ 1}, the most simple way to compute PMF and CDF are

m/R , ls = PMF(s) =

s<Râˆ’1,

m âˆ’ (R âˆ’ 1) Â· m/R , s = R âˆ’ 1

(16)

bs = CDF(s âˆ’ 1) = m/R Â· s

Given b âˆˆ [0, m), the output of inverse CDF s = CDFâˆ’1(b), should be exactly b âˆˆ [bs, bs + ls). The general way to determine CDFâˆ’1 is binary search. But for uniform distribution, we can directly
obtain the inverse CDF such that

s = CDFâˆ’1(b) = min( b/l , R âˆ’ 1), l = m/R

(17)

We summarize uniform entropy coder AC, rANS and UBCS as follows: For AC:

â€¢ Initial state: interval [lo, hi);
â€¢ Encoding: get m = hi âˆ’ ho, get ls, bs with Eq. (16), update interval [lo , hi ) such that lo = lo + bs, hi = lo + ls, get c âˆˆ [lo , hi ) as the encoded bits;
â€¢ Decoding: for encoded bits c âˆˆ [lo, hi) and current interval [lo, hi), get m = hi âˆ’ lo, b = c âˆ’ lo, decode s = CDFâˆ’1(b) with Eq. (17), update interval [lo , hi ) such that lo = lo + bs, hi = lo + ls;
â€¢ Number of atom operations in encoding: one division, one multiplication3;
â€¢ Number of atom operations in decoding: two divisions, one multiplication. Binary search may involve if Eq. (17) is not used.

For rANS:

â€¢ Initial state: number c; â€¢ Encoding: set m = 2K , get ls, bs with Eq. (16), update c = c/ls Â· m + (c mod ls) + bs; â€¢ Decoding: set m = 2K , for encoded bits c , get b = c mod m, decode s = CDFâˆ’1(b)
with Eq. (17), update c = ls Â· c /m + (c mod m) âˆ’ bs; â€¢ Number of atom operations in encoding: two divisions, two multiplications4;
â€¢ Number of atom operations in decoding: two divisions, one multiplication. Binary search may involve if Eq. (17) is not used.

For UBCS:

â€¢ Initial state: number c; â€¢ Encoding: update c = c Â· R + s; â€¢ Decoding: for encoded bits c , decode s = c mod R, update c = â€¢ Number of atom operations in encoding: one multiplication;

c /R ;

3We omit add/sub operations as they are negligible compared with multiplication/division. 4The multiplication/division/mod with m = 2K only involve bit operations. With the result of c/ls , c mod ls only involve one multiplication.

17

Table 4: More results on coding bandwidth (M symbol/s) of UBCS and rANS coder. We use the implementations in [17] for evaluating rANS.

Encoder Decoder

# threads
1 4 8 16
1 4 8 16

rANS
5.1Â±0.3 10.8Â±1.9 15.9Â±1.4 21.6Â±1.1
0.80Â±0.02 2.8Â±0.1 5.5Â±0.2 7.4Â±0.5

UBCS
380Â±5 709Â±56 1297Â±137 2075Â±353
66.2Â±1.7 248Â±8 460Â±16 552Â±50

â€¢ Number of atom operations in decoding: one division with remainder.
Overall, UBCS uses the least number of atom operations, which conveys that UBCS performs the best. Moreover, with PMF and CDF in Eq. (16), the optimal entropy coder cannot be guaranteed.

E More Experiments

In this section we will demonstrate our performance attributes across more benchmarking datasets. All experiments are conducted in PyTorch framework on one NVIDIA Tesla P100 GPU and Intel(R) Xeon(R) CPU E5-2690 @ 2.60GHz CPU. The code for LBB and the Flow++ model is directly taken from the original paper under MIT license.

E.1 Coding Efï¬ciency of UBCS

Table 5: Detailed results on the coding performance of iFlow and LBB on ImageNet32. We use a batch size of 64.

ï¬‚ow arch.
Flow++

compression technique
LBB [17] iFlow (Ours)

nll 3.871

bpd
3.875 3.873

aux. bits
45.96 34.40

encoding time (ms) inference coding

58.7Â±0.1

176Â±2.8 66.6Â±0.3

decoding time (ms) inference coding

83.2Â±0.4

172Â±4.7 95.3Â±0.3

Table 6: Detailed results on the coding performance of iFlow and LBB on ImageNet64. We use a batch size of 64.

ï¬‚ow arch.
Flow++

compression technique
LBB [17] iFlow (Ours)

nll 3.701

bpd
3.703 3.703

aux. bits
38.00 34.42

encoding time (ms) inference coding

24.4Â±0.0

284Â±2.5 45.0Â±1.7

decoding time (ms) inference coding

35.7Â±0.1

281Â±2.2 57.0Â±1.4

The detailed experiments is shown in Table 4.
E.2 Compression Performance
Detailed experimental results on ImageNet32 and ImageNet64 datasets are displayed in Tables 5 and 6. Note that we further report the decoding time, which we observe is close to the model inference time.
E.3 Hyper-parameters
As discussed in Sec. 2.4, the codelength will be affected by the choices of h, k and S. As S is set to a large value â€“ and will minimally affect the codelength resulting from MST â€“ we mainly discuss h and k. Tables 7, 8 and 9 illustrate the codelength and auxiliary bits (in bpd) for differing choices

18

of h and k. It is clear that, for large k, the codelength decreases with a larger h. This is expected as larger h corresponds to a greater numerical precision of our linear interpolation. On the other hand, for a ï¬xed h, the codelength becomes larger with a smaller k, as a smaller k corresponds to a greater quantization error. A smaller k may even lead to the failure of iFlow entirely â€“ especially if k is close to h, which would result in the potential of a zero-valued R in Eq. (4) for sufï¬ciently small |f (xÂ¯)|. On the other hand, the auxiliary bits are principally affected by k and not h. Therefore we note that a smaller k is preferred. To conclude, we can nonetheless achieve a near-optimal codelength with a considered choice of hyper-parameters. Thus we set k = 28 and h = 12 for the experiments.

Table 7: Codelengths in terms of bpd and auxiliary length on different h and k on the CIFAR10 dataset. N/A denotes the failure of the compression procedure. The theoretical bpd (nll) is 3.116.

h

6

8

10

12

14

bpd

18 3.229Â±0.000

N/A

N/A

N/A

N/A

20 3.225Â±0.000 3.152Â±0.000

N/A

N/A

N/A

22 3.224Â±0.000 3.147Â±0.000 3.130Â±0.000

N/A

N/A

k 24 3.224Â±0.000 3.146Â±0.000 3.126Â±0.000 3.124Â±0.000

N/A

26 3.224Â±0.000 3.146Â±0.000 3.125Â±0.000 3.119Â±0.000 3.122Â±0.000

28 3.224Â±0.000 3.146Â±0.000 3.124Â±0.000 3.118Â±0.000 3.118Â±0.000

30 3.224Â±0.000 3.146Â±0.000 3.124Â±0.000 3.118Â±0.000 3.116Â±0.000

32 3.224Â±0.000 3.146Â±0.000 3.124Â±0.000 3.118Â±0.000 3.116Â±0.000

auxiliary length

18 20 22 k 24 26 28 30 32

24.25Â±0.01 26.25Â±0.01 28.26Â±0.01 30.25Â±0.01 32.25Â±0.01 34.25Â±0.01 36.25Â±0.01 38.25Â±0.01

N/A 26.27Â±0.01 28.27Â±0.01 30.27Â±0.01 32.27Â±0.01 34.27Â±0.01 36.26Â±0.01 38.26Â±0.01

N/A N/A 28.27Â±0.01 30.27Â±0.01 32.27Â±0.01 34.27Â±0.01 36.27Â±0.01 38.27Â±0.01

N/A N/A N/A 30.27Â±0.01 32.27Â±0.01 34.27Â±0.01 36.27Â±0.01 38.27Â±0.01

N/A N/A N/A N/A 32.27Â±0.01 34.27Â±0.01 36.27Â±0.01 38.27Â±0.01

Table 8: Codelengths in terms of bpd and auxiliary length on different h and k on a SUBSET of ImageNet32 dataset. N/A denotes the failure of the compression procedure. The theoretical bpd (nll) is 3.883.

h

6

8

10

12

14

bpd

18 3.994Â±0.000 3.953Â±0.000

N/A

N/A

N/A

20 3.985Â±0.000 3.919Â±0.000

N/A

N/A

N/A

22 3.983Â±0.000 3.910Â±0.000 3.900Â±0.000

N/A

N/A

k 24 3.983Â±0.000 3.908Â±0.000 3.892Â±0.000 3.896Â±0.000 3.928Â±0.000 26 3.983Â±0.000 3.908Â±0.000 3.890Â±0.000 3.887Â±0.000 3.894Â±0.000

28 3.983Â±0.000 3.908Â±0.000 3.889Â±0.000 3.885Â±0.000 3.886Â±0.000

30 3.982Â±0.000 3.908Â±0.000 3.889Â±0.000 3.885Â±0.000 3.884Â±0.000

32 3.983Â±0.000 3.908Â±0.000 3.889Â±0.000 3.885Â±0.000 3.884Â±0.000

auxiliary length

18 20 22 k 24 26 28 30 32

24.37Â±0.01 26.38Â±0.01 28.38Â±0.01 30.38Â±0.01 32.38Â±0.01 34.38Â±0.01 36.38Â±0.01 38.38Â±0.01

24.37Â±0.01 26.39Â±0.01 28.39Â±0.01 30.39Â±0.01 32.39Â±0.01 34.39Â±0.01 36.39Â±0.01 38.39Â±0.01

N/A N/A 28.39Â±0.01 30.40Â±0.01 32.40Â±0.01 34.40Â±0.01 36.39Â±0.01 38.39Â±0.01

N/A N/A N/A 30.39Â±0.01 32.40Â±0.01 34.40Â±0.01 36.40Â±0.01 38.39Â±0.01

N/A N/A N/A 30.38Â±0.01 32.39Â±0.01 34.40Â±0.01 36.40Â±0.01 38.39Â±0.01

19

Table 9: Codelengths in terms of bpd and auxiliary length on different h and k on a SUBSET of ImageNet64 dataset. N/A denotes the failure of the compression procedure. The theoretical bpd (nll) is 3.718.

h

6

8

10

12

14

bpd

18 3.829Â±0.000 3.779Â±0.000 3.867Â±0.000

N/A

N/A

20 3.823Â±0.000 3.753Â±0.000 3.760Â±0.000 3.863Â±0.000

N/A

22 3.821Â±0.000 3.746Â±0.000 3.733Â±0.000 3.755Â±0.000 3.861Â±0.000

k 24 3.821Â±0.000 3.744Â±0.000 3.727Â±0.000 3.729Â±0.000 3.754Â±0.000 26 3.821Â±0.000 3.744Â±0.000 3.725Â±0.000 3.722Â±0.000 3.727Â±0.000

28 3.821Â±0.000 3.744Â±0.000 3.725Â±0.000 3.720Â±0.000 3.721Â±0.000

30 3.821Â±0.000 3.744Â±0.000 3.725Â±0.000 3.720Â±0.000 3.719Â±0.000

32 3.821Â±0.000 3.744Â±0.000 3.725Â±0.000 3.720Â±0.000 3.719Â±0.000

auxiliary length

18 20 22 k 24 26 28 30 32

24.40Â±0.01 26.40Â±0.01 28.40Â±0.01 30.40Â±0.01 32.40Â±0.01 34.40Â±0.01 36.40Â±0.01 38.40Â±0.01

24.41Â±0.01 26.41Â±0.01 28.42Â±0.01 30.42Â±0.01 32.42Â±0.01 34.42Â±0.01 36.42Â±0.01 38.42Â±0.01

24.39Â±0.01 26.41Â±0.01 28.42Â±0.01 30.42Â±0.01 32.42Â±0.01 34.42Â±0.01 36.42Â±0.01 38.42Â±0.01

N/A 26.39Â±0.01 28.41Â±0.01 30.42Â±0.01 32.42Â±0.01 34.42Â±0.01 36.42Â±0.01 38.42Â±0.01

N/A N/A 28.39Â±0.01 30.41Â±0.01 32.42Â±0.01 34.42Â±0.01 36.42Â±0.01 38.42Â±0.01

20

