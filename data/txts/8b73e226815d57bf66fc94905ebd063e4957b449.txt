arXiv:2201.11308v1 [cs.CR] 27 Jan 2022

Calibration with Privacy in Peer Review
Wenxin Ding Gautam Kamath â—‹r Weina Wang â—‹r Nihar B. Shahâˆ—
Abstract
Reviewers in peer review are often miscalibrated: they may be strict, lenient, extreme, moderate, etc. A number of algorithms have previously been proposed to calibrate reviews. Such attempts of calibration can however leak sensitive information about which reviewer reviewed which paper. In this paper, we identify this problem of calibration with privacy, and provide a foundational building block to address it. Speciï¬cally, we present a theoretical study of this problem under a simpliï¬ed-yet-challenging model involving two reviewers, two papers, and an MAP-computing adversary. Our main results establish the Pareto frontier of the tradeoï¬€ between privacy (preventing the adversary from inferring reviewer identity) and utility (accepting better papers), and design explicit computationally-eï¬ƒcient algorithms that we prove are Pareto optimal.
1 Introduction
It is well known that scores provided by people are frequently miscalibrated. In the application of peer review, reviewers may be strict, lenient, extreme, moderate, etc. This leads to unfairness in peer review, for instance, disadvantaging papers that happen to go to strict reviewers [1]: â€œthe existence of disparate categories of reviewers creates the potential for unfair treatment of authors. Those whose papers are sent by chance to assassins/demoters are at an unfair disadvantage, while zealots/pushovers give authors an unfair advantage.â€
A number of algorithms [2â€“8] are proposed in the literature to address the problem of miscalibration. There are two key challenges, however, towards any attempts of calibration using such algorithms:
Challenge #1: The calibration algorithms may leak information about which reviewer reviewed which paper. Here is an example showing how a naÂ¨Ä±ve attempt at calibration can compromise privacy. Consider an adversary trying to guess the reviewer of a paper between two possibilities â€“ reviewer X or reviewer Y. The review for the paper is lukewarm, and for simplicity suppose this is the only review. We consider the â€œopen reviewâ€ model where all submitted papers, reviews, and ï¬nal decisions are public (but reviewer identities are not). Also suppose it is known that reviewer X is strict but reviewer Y is not. Then the conference will not accept the paper unless the conference performs a calibration using this information and the reviewer is X. The acceptance of the paper will provide the adversary with the necessary information to infer the reviewer as X.
Challenge #2: The bottleneck of a small number of samples (reviews) per reviewer. Many conferences have each reviewer reviewing only a handful papers (typically 1 to 6 papers), as well as have each paper reviewed by a handful of reviewers. As a consequence, it is often hard to decipher the miscalibration of any reviewer, particularly since human miscalibration can be quite complex [9]. Indeed, program chairs of conferences have tried to use some algorithms to calibrate reviewersâ€™ scores, but have found the outcomes to be unsatisfactory. For instance, John Langford, the program chair of the ICML 2012 conference says that â€œWe experimented with reviewer normalization and generally found it signiï¬cantly harmfulâ€ [10].
Our focus on this paper is challenge #1 of privacy. Towards challenge # 2, we assume that the conference has exogenous information about the miscalibration of reviewers, such as reviewersâ€™ calibration information
âˆ—Wenxin Ding is at the University of Chicago (wenxind@uchicago.edu), Gautam Kamath is at the University of Waterloo (g@csail.mit.edu), and Weina Wang and Nihar B. Shah are at Carnegie Mellon University ({weinaw, nihars}@cs.cmu.edu).
1

from other conferences where they have reviewed. (Appendix A presents simulations illustrating beneï¬ts of calibration with exogeneous information.) Tackling the problem of privacy in calibration that we identify is quite challenging in full generality. In this paper, our goal is to initiate research towards this grander goal by providing a foundational building block for it. We consider a simpliï¬edâ€“yet highly challengingâ€“model with two reviewers, two papers, and (exogenously) known miscalibration functions where an adversary attempts to guess the reviewer assignment based on maximum a posteriori (MAP) computation. We provide a comprehensive analysis under this model. Our contributions are summarized as follows:
â€¢ We identify the problem of privacy in calibration, and we initiate a theoretical study with the formulation of a problem that incorporates various key challenges of the more general setting.
â€¢ We provide explicit computationally-eï¬ƒcient algorithms for calibration with privacy that optimally trades oï¬€ the error of the conference (in terms of accepting the better paper) and the error of the adversary (in terms of guessing the reviewer).
â€¢ We establish the structure of the Pareto optimal curve between the two aforementioned desiderata. We observe that interestingly, there is a linear tradeoï¬€ between the two errors up to a certain point, after which the error of the adversary does not decrease even if the conference adds more randomness in its protocols.
2 Related Work
Peer review is extensively used for evaluating scientiï¬c papers and grant proposals. However, conference peer review also incurs various challenges such as miscalibration [2â€“8, 11, 12], biases [13â€“15], subjectivity [16â€“18], dishonesty [19â€“24], and others. See [25] for a survey.
The problem of miscalibration is well recognized in the literature. A common approach to design calibration algorithms is to assume a certain model of miscalibration, and under the assumed model, estimate the calibrated scores (or the model parameters) from the scores given by reviewers. This line of literature [2â€“8] assumes aï¬ƒne models for miscalibration: they assume that each paper has some â€œtrueâ€ real-valued quality and that the score provided by any reviewer is some aï¬ƒne transform (plus noise) of this true quality. In our formulation (detailed subsequently in Section 3) we also assume papers have true qualities, and a part of our work also assumes aï¬ƒne miscalibrations.
A second line of literature [26â€“28] recognizes the problem of miscalibration, and takes the approach of using only the ranking of papers induced by the scores given by any individual reviewer, or alternatively, asking each reviewer to only provide a ranking of the papers they are reviewing. Using rankings alone thus gets rid of any miscalibrations, but on the downside, can lose some information contained in scores. Moreover, a recent work [11] showed that under certain settings, scores can yield more information than rankings even if the miscalibration is adversarial.
Notably, these works consider addressing miscalibration using data from within the conference at hand, and moreover do not consider the issue of compromise of privacy.
We assume an â€œopen reviewâ€ model where all submitted papers and all reviews are available publicly, but where information of who reviews which paper is not. Such an open review model is gaining increasing popularity: see, for instance, openreview.net and scipost.org. This model is followed in the ICLR conference as well as other venues. In a survey [29] at the ICLR 2013 conference, researchers felt that this open review model leads to beneï¬ts of more accountability of authors (in terms of not submitting below-par papers) as well as reviewers (in terms of giving high-quality reviews). The publicly available data has resulted in another beneï¬t: it has yielded a rich dataset for research on peer review [14, 21, 30â€“33]. A downside of the open review approach is that if a rejected paper is resubmitted elsewhere, the (publicly available) knowledge of previous rejection may bias the reviewer [34].
Our work considers explicitly randomized assignments and decisions. In practice, the assignments and decision protocols are typically deterministic (although some variations naturally arise due to human involvement in various parts of the peer-review process). The assignment of reviewers to papers is done by
2

Notation i âˆˆ {1, 2} j âˆˆ {1, 2} Î¸iâˆ— âˆˆ R Î¸i âˆˆ R A1 and A2 si âˆˆ R Î²j : R â†’ R j âˆˆR fj : R â†’ R
EC âˆˆ [0, 1] EA âˆˆ [0, 1]

Meaning Index for paper Index for reviewer True quality of paper i Estimated quality of paper i The two possible assignments Score received by paper i; S = [s1, s2] Calibration function of reviewer j Noise of reviewer j Marginal probability density function of score given by reviewer j, that is, distribution of Î²j(Î¸âˆ—) where Î¸âˆ— âˆ¼ N (0, 1) Error of the conference Error of the adversary
Table 1: Summary of the main notation used in the paper.

solving a certain optimization problem [35â€“40] involving similarities computed between each reviewer-paper pair [37, 41â€“43]. Decisions are arrived at after discussions between the reviewers. That said, there are notable instances where randomization has been explicitly used in practice in peer review: randomization can help mitigate dishonest behavior [23] and can help make more fair decisions for borderline papers or grants [44, 45]. A recent survey of researchers ï¬nds support for randomized decisions [46]. Finally, the algorithms in the theoretical work [11] comparing scores and rankings in the context of miscalibration also employ randomization.
Issues of privacy in peer review also arise when releasing data to researchers. The program chairs of the WSDM 2017 conference performed a remarkable controlled experiment to test for biases in peer review, and in their paper [13] they point out privacy-related concerns in releasing data: â€œWe would prefer to make available the raw data used in our study, but after some eï¬€ort we have not been able to devise an anonymization scheme that will simultaneously protect the identities of the parties involved and allow accurate aggregate statistical analysis. We are familiar with the literature around privacy preserving dissemination of data for statistical analysis and feel that releasing our data is not possible using current state-of-the-art techniques.â€ We are aware of two past works which deal with privacy in peer review [23, 47]. In particular, both papers consider privacy-preserving release of peer-review data. The paper [47] provides an algorithm to optimize utility when releasing histograms of certain functions of the review scores. The paper [23] uses randomized assignments to guarantee privacy of the reviewer-paper assignment when data pertaining to similarities between reviewerpaper pairs is released.
Diï¬€erential privacy [48] is a popular rigorous notion of data privacy. Roughly speaking, an algorithm is diï¬€erentially private if its distribution over outputs is similar when provided with â€œneighboringâ€ inputs. In our problem with two papers and two reviewers, one can consider neighboring inputs to be those that diï¬€er only in the assignment. We provide a tight characterization of the adversaryâ€™s ability to determine which of the two possible assignments is the true one. Thus, it may be a useful building block towards more complex private calibration schemes. We note that our calibration algorithms are related to a form of randomized response [49], the canonical algorithm for local diï¬€erential privacy [49â€“51]. Though diï¬€erential privacy is not the focus of our work, we further elaborate on this connection in Appendix B.
3 Problem Formulation and Preliminaries
In this section, we present the formal problem speciï¬cation. We will introduce some notation in this section, and this notation is also summarized in Table 1.

3

Papers and reviewers. We consider a setting with two reviewers and two papers. Each paper i âˆˆ {1, 2} has some latent true quality Î¸iâˆ— âˆˆ R. We assume that the qualities Î¸1âˆ— and Î¸2âˆ— are drawn i.i.d. according to the standard normal distribution (and hence we have Î¸1âˆ— = Î¸2âˆ— with probability 1).
Reviewer assignment. Each reviewer reviews one paper and each paper is reviewed by one reviewer. There are thus two possible assignments: we let A1 denote the assignment of reviewer 1 to paper 1 and reviewer 2 to paper 2, and A2 denote the assignment of reviewer 1 to paper 2 and reviewer 2 to paper 1. We assume that the assignment is chosen uniformly at random from these two possibilities. We assume that the true assignment is known (only) to the conference. We let A denote a random variable representing the assignment. Finally, in our exposition we will refer to the realization of A as the â€œtrueâ€ assignment (and the unrealized assignment as the â€œwrongâ€ assignment).
Miscalibration and reviewer scores. For each paper i âˆˆ {1, 2}, we let si denote the score received by by paper i. Note that this notation is not indexed by the reviewer for brevity since each paper receives exactly one review. For convenience, we deï¬ne the vector S = [s1, s2]. Following the popular â€œopen reviewâ€ model (OpenReview.net, scipost.org), we assume that the scores s1 and s2 are known publicly.1
Following [11], we assume that each reviewer j âˆˆ {1, 2} has a function Î²j : R â†’ R which captures their miscalibration. If reviewer j âˆˆ {1, 2} reviews paper i âˆˆ {1, 2}, we assume that the reviewer provides a score si âˆˆ R given as:
si = Î²j (Î¸iâˆ—) + j ,
where j is a zero-mean Gaussian random variable independent of everything else. We assume that 1 and 2 are identically distributed. The value of the noise is unknown but its distribution is publicly known. We call Î²j the reviewerâ€™s miscalibration function for reviewer j. We assume that the functions Î²1 and Î²2 are increasing and invertible. In one part of our work, we further make an assumption that the miscalibration functions are aï¬ƒne, and we detail this subsequently in the associated section. As discussed previously, our aim is to use exogenous information about the reviewer miscalibrations in order to mitigate the miscalibration, and to this end, we assume that the functions Î²1 and Î²2 are known publicly.
For any reviewer j, we let fj denote the marginal probability density function of the ï¬nal score given by that reviewer, that is, fj is the distribution of Î²j(Î¸âˆ—) where Î¸âˆ— âˆ¼ N (0, 1).
Conferenceâ€™s error. The goal of the conference is to accept the paper with the higher true quality argmaxiâˆˆ{1,2} Î¸iâˆ—. Note that even if the noise terms were zero, simply choosing the paper with higher score (i.e., argmaxiâˆˆ{1,2} si) may be erroneous due to the miscalibration of the reviewers. The conference can however calibrate the scores, that is, use the information about the miscalibration functions of the reviewers and the knowledge of the assignment to potentially make a better decision. In our analysis, we will measure the conferenceâ€™s performance towards its goal in terms of two types of errors:
(a) Per-instance error: For any given S = [s1, s2], the per-instance error of the conference is deï¬ned as EC ([s1, s2]) := Pr(conference accepts lower-quality paper | S = [s1, s2]).
(b) Average-case error: The average-case error of the conference is the per-instance error averaged over the distribution of the scores: s1 s2 EC ([s1, s2])fS([s1, s2]) where fS is the p.d.f. of the joint distribution of S = [s1, s2].
In conjunction with the goal of minimizing the error, the conference must also ensure that information about which reviewer reviewed which paper is not leaked.
1Even if the conference operates in a non-open-review setting where the scores are not public, our guarantees on privacy and conferenceâ€™s error continue to hold. However, our algorithm may not be optimal and the suboptimality may depend on assumptions about the adversaryâ€™s knowledge of the scores.
4

Privacy. We assume that the protocols followed by the conference are public. A challenge for the conference is that performing calibration may leak information about the assignment. As a simple example, suppose that reviewer 1 is known to be strict and reviewer 2 is known to be lenient. Suppose that paper 1 is reviewed by reviewer 1 and paper 2 by reviewer 2. Suppose paper 2 receives a higher score than paper 1, but the conference decides to accept paper 1 after performing calibration. This decision leaks information that paper 2 was reviewed by the lenient reviewer, that is, by reviewer 2. Note that this issue of compromise of privacy arises whether or not the reviewer miscalibration functions are known to the conference.
To formalize the notion of privacy, we assume an adversary in the process. The goal of the adversary is to guess the assignment. In addition to knowing the scores received by both papers, the miscalibration functions of both reviewers, the noise distributions, and the ï¬nal decision of the conference, the adversary also knows the calibration strategy used by the conference to make the decision.
The adversary does not know the assignment, and aims to guess the assignment. We consider an adversary with no additional information, in which case, we assume it predicts the assignment via maximum a posteriori (MAP) estimation. Formally, if the conference decides to accept paper P âˆˆ {1, 2}, then the adversary computes:
argmax Pr(A = A | S = [s1, s2], paper P accepted by the conference),
Aâˆˆ{A1 ,A2 }
where A is the random variable representing the assignment. We make no assumptions on the computational power of the adversary and aim to guarantee privacy assuming they can compute the aforementioned argmax.
As in the case of the conferenceâ€™s error, we also measure the error of the adversary in two ways:
(a) Per-instance error: For any given S = [s1, s2], the per-instance error of the adversary is deï¬ned as EA([s1, s2]) := Pr(adversary guesses wrong assignment | S = [s1, s2]).
(b) Average-case error: The average-case error of the adversary is the per-instance error averaged over the distribution of the scores: s1 s2 EA([s1, s2])fS([s1, s2]) where fS is the p.d.f. of the joint distribution of S = [s1, s2].
Goal. Our goal is to design methods to decide which paper to accept in a manner that simultaneously minimizes the conferenceâ€™s error and maximizes the adversaryâ€™s error. The methods will inherently rely on calibrating reviewer decisions to accept the better paper, and hence we sometimes refer to them as the calibration strategy.
The two aforementioned objectives may conï¬‚ict with one another: a decision that reduces the chances of accepting the lower quality paper via calibration can also leak more information about the assignment. In this work, we thus establish the Pareto frontier of this tradeoï¬€. We deï¬ne the Pareto frontier as the set of all points of the (conferenceâ€™s error, adversaryâ€™s error) tradeoï¬€ such that the adversaryâ€™s error cannot be increased without increasing the conferenceâ€™s error. We call a calibration strategy Pareto optimal if for any given threshold on conferenceâ€™s error, it maximizes the adversaryâ€™s error while ensuring that the conferenceâ€™s error does not exceed the given threshold.
4 Main Results
In what follows, we present results for two settings: (1) a noiseless setting, where the noise in the reviewerprovided scores is zero; and (2) a noisy setting, where the noise in a reviewer score has a positive variance. We begin by a few preliminaries which we subsequently use to derive and present our main results.
4.1 Preliminaries
We now formalize the calibration strategies that a conference can follow in a general form, and then derive a speciï¬c form that can be used without loss of optimality. Our subsequent results will then use this form of the calibration strategies.
5

At a high level, the calibration strategies introduce a certain amount of randomness in the acceptance decisions. In the example in the â€˜privacyâ€™ paragraph earlier in this section, suppose the conference does the calibration, and then tosses a coin. With probability 0.9, it accepts the paper it thinks is better and otherwise it accepts the other paper. This randomness ensures that an adversary who observes that paper 1 is accepted cannot be certain that paper 1 was reviewed by reviewer 1, due to the possibility that paper 1 was reviewed by the lenient reviewer 2 but was still accepted due to the randomness. However, due to the randomness introduced, the conference incurs an error in terms of accepting the paper which it thought was actually better. There is thus a tradeoï¬€ between the conferenceâ€™s error and the adversaryâ€™s error, and our goal is to design calibration strategies that are optimal with respect to this tradeoï¬€.
Let us now formalize the notion of a calibration strategy. The conference observes the scores S = [s1, s2] and the assignment A. Given these values, a generic calibration strategy is speciï¬ed by a function g : S Ã—A â†’ [0, 1] â€” the conference accepts accept paper 1 with probability g(S, A) and accepts paper 2 otherwise. Note that the function g is publicly known but its realization is known only to the conference. For any function g used by the conference, the conferenceâ€™s error is then given by
EC (S, A) = (1 âˆ’ g(S, A1)) Pr(A = A1|Î¸1âˆ— > Î¸2âˆ—, S) + (1 âˆ’ g(S, A2)) Pr(A = A2|Î¸1âˆ— > Î¸2âˆ—, S) Pr(Î¸1âˆ— > Î¸2âˆ—|S)
+ g(S, A1) Pr(A = A1|Î¸1âˆ— < Î¸2âˆ—, S) + g(S, A2) Pr(A = A2|Î¸1âˆ— < Î¸2âˆ—, S) Pr(Î¸1âˆ— < Î¸2âˆ—|S).
Having speciï¬ed this general form of calibration strategy, we now discuss a speciï¬c variant. If one did not care about the privacy, then the conferenceâ€™s error can be minimized via maximum a posteriori (MAP) estimation: given scores S and the assignment A, the conference accepts paper 1 if Pr(Î¸1âˆ— > Î¸2âˆ—|S, A) > 0.5 and accepts paper 2 otherwise (breaking ties uniformly at random). Now under our scenario also involving privacy, consider the following class of calibration strategies. The strategy is governed by a function h : S Ã—A â†’ [0, 1]. Given S = [s1, s2] and the assignment A:
â€¢ With probability h(S, A), the conference executes MAP estimation under scores S and the (true) assignment A,
â€¢ otherwise (with probability 1 âˆ’ h(S, A)), the conference executes MAP estimation under scores S and the wrong assignment {A1, A2}\A.
As before, we assume that function h is known publicly but its realization or the random bits are not. A calibration strategy is Pareto optimal if any other strategy that incurs a lower conference error must
also induce a lower error of the adversary, and any other strategy that induces a higher error of the adversary must also incur a higher conference error. The Pareto frontier is the set of all (conference error, adversary error) pairs achieved by Pareto optimal strategies. The following proposition states that without loss of optimality, one can restrict attention to the class of strategies speciï¬ed by functions h.
Proposition 4.1. For any values of error of the conference and error of the adversary (EC, EA) achieved by a calibration strategy g, there exists a function h such that under h, the error of the conference is no larger than EC and the error of the adversary is no smaller than EA.
The proof of this proposition is available in Appendix C.1. Hence, without loss of Pareto optimality, any generic calibration strategy g can be replaced with a strategy involving the calibration function h. Thus, in the sequel we restrict attention to calibration strategies using function h.
4.2 Noiseless Setting
We ï¬rst study the noiseless setting where the noise in the reviewer-provided scores is zero, that is, where 1 = 2 = 0. Observe that in this setting the conference can obtain the true qualities of the papers from the scores by inverting the reviewer functions. We ï¬rst explicitly characterize the Pareto frontier for per-instance errors of the conference and the adversary. Based on this characterization, we then design Pareto optimal strategies for conference calibration with respect to the per-instance error and the average-case error.
6

Error of adversary

min{ğ‘“! ğ‘ ! ğ‘“" ğ‘ " , ğ‘“" ğ‘ ! ğ‘“! ğ‘ " } ğ‘“! ğ‘ ! ğ‘“" ğ‘ " + ğ‘“" ğ‘ ! ğ‘“!(ğ‘ ")
x

Legend: Pareto optimal curve in
x Part 1 of Theorem 4.1
Part 2 of Theorem 4.1

0.5
min{ğ‘“! ğ‘ ! ğ‘“" ğ‘ " , ğ‘“" ğ‘ ! ğ‘“! ğ‘ " } ğ‘“! ğ‘ ! ğ‘“" ğ‘ " + ğ‘“" ğ‘ ! ğ‘“!(ğ‘ ")
Error of conference
Figure 1: Pareto frontier for per-instance errors in the noiseless setting.

4.2.1 Pareto Frontier for Per-Instance Errors

In the following theorem, we present the main result of this section establishing the Pareto frontier for per-instance errors in the noiseless setting.

Theorem 4.2. Consider the peer-review system in the noiseless setting. The Pareto frontier of (per-instance error of the conference, per-instance error of the adversary) with scores S = [s1, s2] is given as follows.

(1) If s1 â‰¥ max{Î²2(Î²1âˆ’1(s2)), Î²1(Î²2âˆ’1(s2))} or s1 â‰¤ min{Î²2(Î²1âˆ’1(s2)), Î²1(Î²2âˆ’1(s2))}, then the Pareto frontier consists of a single point (0, minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} ).

(2)

Otherwise,

if

min{

Î²

2

(Î²

âˆ’ 1

1

(

s2

))

,

Î²1

(Î²

âˆ’ 2

1

(

s2

))

}

<

s1

<

max{

Î²

2

(Î²

âˆ’ 1

1

(

s2

))

,

Î²1

(

Î²

âˆ’1 2

(s2

))

},

then

the

Pareto

frontier of conference error and adversary error is a line segment of slope 1 starting from the origin

(0, 0) to

, . min{f1(s1)f2(s2),f2(s1)f1(s2)} min{f1(s1)f2(s2),f2(s1)f1(s2)}

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

The proof of Theorem 4.2 is provided in Appendix C.2. The Pareto frontier established in Theorem 4.2

is illustrated in Figure 1.

We now unpack the result of Theorem 4.2, beginning with part (1). Recall that in this noiseless setting,

given scores S = [s1, s2] and knowing the reviewersâ€™ miscalibration functions, the conference can estimate

the qualities of papers under each assignment. We use Î¸i âˆˆ R to denote the estimated quality of paper i.

If the conference estimates the qualities assuming that A1 was the actual assignment, we get Î¸1 = Î²1âˆ’1(s1)

and Î¸2 = Î²2âˆ’1(s2). If the conference estimates the qualities assuming that A2 was the actual assignment,

we get Î¸1 = Î²2âˆ’1(s1) and Î¸2 = Î²1âˆ’1(s2).

If

s1

â‰¥

max

{Î²

2

(Î²

âˆ’ 1

1

(s2

))

,

Î²1

(Î²

âˆ’ 2

1

(

s2

))

},

then

Î¸1

â‰¥

Î¸2

under both

assignments

(and

hence

paper

1

should

be

accepted).

Similarly,

if

s1

â‰¤

min

{Î²

2

(Î²

âˆ’1 1

(s2

)),

Î²1

(Î²

âˆ’ 2

1

(s2

))}

,

then

Î¸1 â‰¤ Î¸2 under both assignments (and hence paper 2 should be accepted). Therefore, under the condition of

part (1) of the theorem, the same paper has higher estimated quality under both assignments, and hence that

paper will be accepted irrespective of the function h. Thus, under this condition, the Pareto optimal curve

comprises just a single point where the conference has zero error, and the adversary obtains no additional

information from the acceptance decision as compared to the scores S = [s1, s2]. The error of the adversary is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} when it guesses the assignment using only the scores and not the decision.
Let us now discuss part (2) of Theorem 4.2. For scores S = [s1, s2] that do not satisfy the condition

in part (1), the conference would accept diï¬€erent papers when performing MAP calibration under the two

possible assignments. In this case, the function h does inï¬‚uence the outcomes. The Pareto frontier includes

7

Algorithm 1: Conference calibration with per-instance error in the noiseless setting

Input: scores S = [s1, s2], maximum allowable per-instance error of the conference EC ([s1, s2])

if

s1

â‰¥

max

{Î²

1

(Î²

âˆ’ 2

1

(s2

)),

Î²2

(Î²

âˆ’ 1

1

(s2

))}

then

accept paper 1

else

if

s1

â‰¤

min{

Î²

1

(Î²

âˆ’ 2

1

(

s2

))

,

Î²2

(

Î²

âˆ’1 1

(s2

))

}

then

accept paper 2

else if EC ([s1, s2]) â‰¥ minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} then

choose q1, q2 âˆˆ [0, 1] such that f1(s1)f2(s2)q1 + f2(s1)f1(s2)q2 = max {f1(s1)f2(s2), f2(s1)f1(s2)}

else choose q1, q2 âˆˆ [0, 1] such that EC ([s1, s2]) = 1 âˆ’ f1f(s11(s)f12)f(s22(s)q21)++ff22((ss11))ff11((ss22))q2

end if

the origin since the conference can ensure zero error in this noiseless setting, but this zero-error acceptance

decision will also perfectly reveal the assignment to the adversary since the zero-error decisions would be

diï¬€erent under the two assignments. Then in the proof, we ï¬nd the maximum per-instance error of the

adversary given per-instance error of the conference. We ï¬nd that the adversaryâ€™s error no longer increases

if the conference is allowed an error greater than minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} . At this value of the conferenceâ€™s error, the maximum per-instance error of the adversary is also minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} . We further show in the proof of the theorem that the Pareto frontier is precisely the line segment joining these two points.

Therefore, the Pareto frontier for scores satisfy the condition is a line segment from the origin to the point

, min{f1(s1)f2(s2),f2(s1)f1(s2)} min{f1(s1)f2(s2),f2(s1)f1(s2)}

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

as shown in Figure 1.

4.2.2 Optimal Calibration Strategy under Per-Instance Errors
In the previous section, we characterized the fundamental tradeoï¬€ between the conferenceâ€™s per-instance error and the adversaryâ€™s per-instance error through the Pareto frontier. In this section, we design an explicit calibration strategy that achieves per-instance errors on the Pareto frontier, and is thus optimal for per-instance errors.
Since S is a ï¬xed realization in the analysis of per-instance errors, to simplify the notation we deï¬ne

q1 = h(S, A1) and q2 = h(S, A2).

Under this notation, q1 is the probability with which the conference calibrates under the true assignment when the true assignment is A1, and q2 is the probability with which the conference calibrates under the true assignment when the true assignment is A2. Therefore, from Proposition 4.1, given the maximum allowable error of the conference EC , our goal is to ï¬nd values of q1 and q2 that are Pareto optimal. We present our proposed algorithm for this setting as Algorithm 1.

Theorem 4.3. The calibration algorithm described in Algorithm 1 ensures the maximum per-instance error of the adversary for any given value of the maximum allowable per-instance error EC ([s1, s2]) for the conference, and is hence Pareto optimal.

The proof of Theorem 4.3 is presented in Appendix C.3.

If

s1

â‰¥

max{

Î²

1

(Î²

âˆ’ 2

1

(

s2

))

,

Î²2

(

Î²

âˆ’ 1

1

(s2

))

}

or

s1

â‰¤

min{

Î²

1

(Î²

âˆ’ 2

1

(

s2

))

,

Î²2

(

Î²

âˆ’ 1

1

(

s2

))

},

we

are

in

part

(1)

of

Theorem

4.2.

Under scores that satisfy this

condition, the conference is guaranteed to accept the higher-quality paper and thus has zero error. The error

of the adversary is also ï¬xed because the adversary makes its guess based on the scores only.

Otherwise, for a Pareto optimal calibration strategy, the errors of the conference and the adversary

should stay on the Pareto frontier as in Figure 1. When EC ([s1, s2]) â‰¥ minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} , the conference should choose q1 and q2 such that its per-instance error is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} since further sacriï¬ce of accuracy cannot increase the per-instance error of the adversary as indicated by the Pareto

8

Algorithm 2: Conference calibration with average-case error in the noiseless setting Input: maximum allowable average-case error of the conference EC Let Î¶ = error of the conference for adopting Algorithm 1 with EC ([s1, s2]) = 1 for all [s1, s2] if EC > Î¶ then
the desired conference error is Pareto ineï¬ƒcient and operate at EC = Î¶ else if EC = Î¶ then
run Algorithm 1 with EC ([s1, s2]) = 1 else if EC < Î¶ then
toss a coin that has probability EÎ¶C of head if coin toss outcome is head then
run Algorithm 1 with EC ([s1, s2]) = 1 else
calibrate under true assignment end if end if
frontier. On the other hand, if EC ([s1, s2]) < minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} , the conference can choose q1 and q2 that yields the maximum allowable per-instance error. Since EC ([s1, s2]) < minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} and EC ([s1, s2]) = 1 âˆ’ f1f(s11(s)f12)f(s22(s)q21)++ff22((ss11))ff11((ss22))q2 , we can conclude that f1(s1)f2(s2)q1 + f2(s1)f1(s2)q2 > max {f1(s1)f2(s2), f2(s1)f1(s2)} and the adversary has the same per-instance error under this condition. Therefore, in Algorithm 1, the error of the adversary is the same as the error of the conference and the errors are always on the Pareto frontier.
4.2.3 Optimal Calibration Strategy under Average-case Error
In the previous section, we designed an optimal strategy under per-instance errors. In this section, we design a calibration strategy that achieves optimal average-case errors for the conference with respect to the average-case error of the adversary. Unlike for per-instance error, we do not have a closed form expression for average-case error. We present our proposed algorithm as Algorithm 2. We now present our main result of this subsection, following which we discuss more details of the algorithm this result.
Theorem 4.4. The calibration algorithm described in Algorithm 2 ensures the maximum average-case error of the adversary for any given value of the maximum allowable average-case error EC for the conference, and is hence Pareto optimal.
The proof of Theorem 4.4 is provided in Appendix C.4. In Algorithm 2, running Algorithm 1 with EC ([s1, s2]) = 1 is a strategy that yields no error when the same paper has higher estimated quality under both assignments and otherwise, error of the conference equals error of the adversary. Moreover, both per-instance error of the conference and per-instance error of the adversary is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} . That is, the maximum per-instance error for the adversary. Thus, this strategy is Pareto optimal for any score pair and is also Pareto optimal under its average-error since the error of the adversary is maximized under such average-error of the conference. In proof for optimality of Algorithm 2, we take advantage of the fact that the Pareto frontier is either a point where the conference has no error or an increasing line with slope 1. Under this fact, the optimal average-case error of the conference is where the conference has zero error when the adversary guesses the assignment based on the scores only and has the same error as the adversary otherwise. Therefore, Algorithm 2 makes use of Algorithm 1 with EC ([s1, s2]) = 1 and on average, the error of the conference and the adversary matches the Pareto optimality for the conference.
9

4.3 Noisy Setting
We now study the noisy setting. We consider both reviewersâ€™ miscalibration functions Î²1 and Î²2 to be aï¬ƒne and both reviewersâ€™ noises 1 and 2 to be Gaussian. Furthermore, the distributions of the noise are the same for both reviewers with mean zero and some known variance Ïƒ2. Formally, we assume:
Î²1(Î¸âˆ—) = a1Î¸âˆ— + b1, Î²2(Î¸âˆ—) = a2Î¸âˆ— + b2, 1 âˆ¼ N (0, Ïƒ2), and 2 âˆ¼ N (0, Ïƒ2).
As we will see below, the presence of noise makes the analysis much more complex, even when we assume aï¬ƒne miscalibration, as compared to the noiseless setting.

4.3.1 Pareto Frontier for Per-Instance Errors

We begin by establishing the Pareto frontier for per-instance errors in the noisy case. Let Î¦ denote the cumulative distribution function of the standard normal distribution. Also deï¬ne notation Î¦1 and Î¦2 as:

Î¦1 = Î¦

a2(a21 + Ïƒ2)(s2 âˆ’ b2) âˆ’ a1(a22 + Ïƒ2)(s1 âˆ’ b1) Ïƒ2(a21 + a22 + 2Ïƒ2)(a21 + Ïƒ2)(a22 + Ïƒ2)

Î¦2 = Î¦ a1(a22 + Ïƒ2)(s2 âˆ’ b1) âˆ’ a2(a21 + Ïƒ2)(s1 âˆ’ b2) . Ïƒ2(a21 + a22 + 2Ïƒ2)(a21 + Ïƒ2)(a22 + Ïƒ2)

(4.1a) (4.1b)

Theorem 4.5. Consider the peer-review system in the noisy setting. The Pareto frontier of (per-instance error of the conference, per-instance error of the adversary) with scores S = [s1, s2] is as follows.

(1) If s1 â‰¥ max

+ b , + b a2(a21+Ïƒ2)(s2âˆ’b2)

a1 (a22 +Ïƒ 2 )(s2 âˆ’b1 )

a1 (a22 +Ïƒ 2 )

1

a2 (a21 +Ïƒ 2 )

2

then the Pareto frontier consists of a single point.

or s1 â‰¤ min

+ b , + b , a2(a21+Ïƒ2)(s2âˆ’b2)

a1 (a22 +Ïƒ 2 )(s2 âˆ’b1 )

a1 (a22 +Ïƒ 2 )

1

a2 (a21 +Ïƒ 2 )

2

Speciï¬cally, when s1 â‰¥ max

+ b , + b , a2(a21+Ïƒ2)(s2âˆ’b2)

a1 (a22 +Ïƒ 2 )(s2 âˆ’b1 )

a1 (a22 +Ïƒ 2 )

1

a2 (a21 +Ïƒ 2 )

2

ference error and adversary error is the point f1(fs11()sf12)(fs22()sÎ¦21)++ff22((ss11))ff11((ss22))Î¦2 ,

And similarly, when s1 â‰¤ min

+ b , + b a2(a21+Ïƒ2)(s2âˆ’b2)

a1 (a22 +Ïƒ 2 )(s2 âˆ’b1 )

a1 (a22 +Ïƒ 2 )

1

a2 (a21 +Ïƒ 2 )

2

point

, . f1(s1)f2(s2)(1âˆ’Î¦1)+f2(s1)f1(s2)(1âˆ’Î¦2) min{f1(s1)f2(s2),f2(s1)f1(s2)}

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

the Pareto frontier of con. min{f1 (s1 )f2 (s2 ),f2 (s1 )f1 (s2 )}
f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )
, the Pareto frontier is the

(2) If min

+ b , + b a2(a21+Ïƒ2)(s2âˆ’b2)

a1 (a22 +Ïƒ 2 )(s2 âˆ’b1 )

a1 (a22 +Ïƒ 2 )

1

a2 (a21 +Ïƒ2 )

2

then the Pareto frontier is an increasing line.

< s1 < max

+ b , + b , a2(a21+Ïƒ2)(s2âˆ’b2)

a1 (a22 +Ïƒ 2 )(s2 âˆ’b1 )

a1 (a22 +Ïƒ2 )

1

a2 (a21 +Ïƒ2 )

2

The proof of Theorem 4.5 is provided in Appendix C.5. We now unpack this result and specify precisely

the Pareto frontier in both parts of the theorem.

Given scores S = [s1, s2] and knowing the reviewersâ€™ miscalibration functions, the conference can estimate the qualities of papers under each assignment. Under assignment A1, we have Pr(Î¸1âˆ— > Î¸2âˆ—|A = A1, S = [s1, s2]) = 1 âˆ’ Î¦1. And under assignment A2, we have Pr(Î¸1âˆ— > Î¸2âˆ—|A = A2, S = [s1, s2]) = 1 âˆ’ Î¦2.

Let us now consider part (1) of Theorem 4.5. If the condition speciï¬ed in the statement of the theorem

is

satisï¬ed,

then

we

know

that

either

(Î¦1

â‰¤

1 2

,

Î¦2

â‰¤

12 )

in

which

case

paper

1

has

a

higher

estimated

quality

under

either

assignment,

or

(Î¦1

â‰¥

1 2

,

Î¦2

â‰¥

12 )

in

which

paper

2

has

a

higher

estimated

quality

under

either

assignment. Thus, if the condition in part (1) is met, the same paper has higher estimated quality under

both assignments and hence the decision does not depend on h. Thus, for such pair of scores, the Pareto

optimal situation is where the conference has minimum error and the adversary guesses the assignment based

on the scores alone.

Let us now move to part (2) of Theorem 4.5, and consider parameters that satisfy the condition stated

therein. Under this condition, the conference would accept diï¬€erent papers by calibrating under diï¬€erent

assignments, and the function h needs to be carefully designed. We study the Pareto frontier for scores in

the range.

10

Error of the adversary

%1 ,1 %2 ,2 %1 ,1 %2 ,2 + %2 ,1 %1(,2)

1 : /! 0! /" 0" Î¦! + /" 0! /! 0" (1 âˆ’ Î¦") /! 0! /" 0" + /" 0! /!(0")
2 : /! 0! /" 0" (Î¦!+2Î¦" âˆ’ 1) + /" 0! /! 0" (1 âˆ’ Î¦") /! 0! /" 0" + /" 0! /!(0")

1

2

0.5 Error of the

conference

Figure 2: A Pareto frontier in the noisy setting of part (2) of Theorem 4.5 in the case that f1(s1)f2(s2) <

f2(s1)f1(s2)

and

Î¦1

<

1 2

<

Î¦2

with

0

<

Î¦2

âˆ’

1 2

<

1 2

âˆ’ Î¦1.

The

notations

Î¦1

and

Î¦2

are

deï¬ned

in

(4.1).

We

consider

a

speciï¬c

case

where

f1(s1)f2(s2)

<

f2(s1)f1(s2),

Î¦1

<

1 2

and

Î¦2

>

1 2

with

0

<

Î¦2 âˆ’

1 2

<

1 2

âˆ’

Î¦1.

All other cases can be derived in a similar fashion to the proof in Appendix C.5.

The

Pareto frontier with these assumptions are shown in Figure 2. We ï¬rst ï¬nd the maximum per-instance

error of the adversary given per-instance error of the conference. We ï¬nd that the adversaryâ€™s error no longer increases if the conference increase its error larger than f1(s1)f2(sf21)((Î¦s11)+f22(Î¦s22âˆ’)+1f)+2(fs21()sf11)(fs12()s2)(1âˆ’Î¦2) in this case. The maximum per-instance error of the adversary is f1(s1)ff21((ss21))+ff22((ss21))f1(s2) . Therefore, the Pareto

frontier for scores satisfy the condition is an increasing line from f1(s1f)f12(s(1s2)f)Î¦2(1s+2)f+2(fs21()sf11)(fs12()s(21)âˆ’Î¦2) , 0 to

, . f1(s1)f2(s2)(Î¦1+2Î¦2âˆ’1)+f2(s1)f1(s2)(1âˆ’Î¦2)

f1 (s1 )f2 (s2 )

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

We show the Pareto frontier in the case described above in Figure 2. In all other cases, the shape

of the Pareto frontier is the same as Figure 2 but has diï¬€erent coordinates. The relationship between
f1(s1)f2(s2) and f2(s1)f1(s2) combining with the values of Î¦1 and Î¦2 and their distance to 12 , we have eight diï¬€erent combinations of these values. In all eight cases, the Pareto frontier contains either a single

point or an increasing line depending on the scores. Moreover, the maximum error of the adversary is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} in all cases.

4.3.2 Optimal Calibration Strategy under Per-Instance Errors
In the previous section, we characterized the fundamental tradeoï¬€ between the conferenceâ€™s per-instance error and the adversaryâ€™s per-instance error through the Pareto frontier. In this section, we design a calibration strategy that achieves per-instance errors on the Pareto frontier, meaning that the strategy is optimal under per-instance errors.
Since S is a ï¬xed realization in the analysis of per-instance errors, to simplify the notation we deï¬ne (similar to Section 4.2.2):
q1 = h(S, A1) and q2 = h(S, A2).
Under this notation, given the maximum allowable error of the conference EC, our goal is to ï¬nd values of q1 and q2 that maximize the error of the adversary EA. We continue to use the notations Î¦1 and Î¦2 introduced in 4.1.
We present our proposed algorithm as Algorithm 3.
Theorem 4.6. The calibration algorithm described in Algorithm 3 ensures the maximum per-instance error of the adversary for any given value of the maximum allowable per-instance error EC ([s1, s2]) for the conference, and is hence Pareto optimal.

11

Algorithm 3: Conference calibration with per-instance error in the noisy setting

Input: scores S = [s1, s2], maximum allowable per-instance error of the conference EC ([s1, s2])

if s1 > max

+ b , + b a2(a21+Ïƒ2)(s2âˆ’b2)

a1 (a22 +Ïƒ 2 )(s2 âˆ’b1 )

a1 (a22 +Ïƒ 2 )

1

a2 (a21 +Ïƒ 2 )

2

then

accept paper 1

else if s1 < min

+ b , + b a2(a21+Ïƒ2)(s2âˆ’b2)

a1 (a22 +Ïƒ 2 )(s2 âˆ’b1 )

a1 (a22 +Ïƒ2 )

1

a2 (a21 +Ïƒ2 )

2

then

accept paper 2

else if EC ([s1, s2]) < f1(s1f)f12(s(1s2)f)Î¦2(1s+2)f+2(fs21()sf11)(fs12()s(21)âˆ’Î¦2) then

error conference of cannot be achieved

else if EC ([s1, s2]) â‰¥ f1(s1)f2(sf21)((Î¦s11)+f22(Î¦s22âˆ’)+1f)+2(fs21()sf11)(fs12()s2)(1âˆ’Î¦2) then

choose q1 = 1, q2 = (f2(s1f)1f(1s(1s)2f)2âˆ’(sf21)(+s1f)2f(2s(1s)2f)1)((s12âˆ’) 2Î¦2)

else

choose q1 = 1, q2 = EC ([s1,s2])Â·(f1(s1)f2(s2)+f2(s1)f1(s2))âˆ’(1fâˆ’12(sÎ¦12))ff22((ss21))(f11âˆ’(Î¦s21))âˆ’f2(s1)f1(s2)Î¦2âˆ’(2Î¦1âˆ’1)f1(s1)f2(s2)

end if

The proof of Theorem 4.6 is provided in Appendix C.6. For a moment, consider the case of f1(s1)f2(s2) <

f2(s1)f1(s2)

and

Î¦1

<

1 2

<

Î¦2

with

0

<

Î¦2

âˆ’

1 2

<

1 2

âˆ’ Î¦1,

for

a

Pareto

optimal

calibration

strategy,

the

error of the conference and the adversary should stay on the Pareto frontier as in Figure 2. If the required

error of the conference is less than f1(s1f)f12(s(1s2)f)Î¦2(1s+2)f+2(fs21()sf11)(fs12()s(21)âˆ’Î¦2) , then due to the noise, there is no feasible calibration strategy that satisï¬es this requirement. Otherwise, the error of the conference and the error of

the adversary adhere to the Pareto frontier.

Algorithm 3 follows directly from the Pareto frontier established in Theorem 4.5. The calibration prob-

abilities q1 and q2 are chosen such that the error of the conference and the error of the adversary lie

on the Pareto frontier. The ï¬rst two cases of Algorithm 3 correspond to part (1) of Theorem 4.5 where

the same paper has higher estimated quality under both assignments. In the noisy case, there is a mini-

mum value for the per-instance error of the conference. Therefore, in the third case of Algorithm 3, when

the maximum allowable per-instance error of the conference is too small, the conference cannot achieve

such error. If EC ([s1, s2]) â‰¥ f1(s1)f2(sf21)((Î¦s11)+f22(Î¦s22âˆ’)+1f)+2(fs21()sf11)(fs12()s2)(1âˆ’Î¦2) , the error of the conference should be f1(s1)f2(sf21)((Î¦s11)+f22(Î¦s22âˆ’)+1f)+2(fs21()sf11)(fs12()s2)(1âˆ’Î¦2) to stay Pareto optimal since further sacriï¬ce of accuracy cannot increase error of the adversary. And for the rest of the per-instance error of the conference, we choose q1 and

q2 such that the errors of the conference and the adversary stay on the Pareto frontier in Figure 2.

5 Discussion
Our work is only a starting point towards addressing the important problem of calibration with privacy in its full generality. Several challenges need to be addressed in future work in order to design practical algorithms with guarantees for calibration and privacy. There are open problems pertaining to relaxations of assumptions made in this paper such as that of two reviewers and papers, homogeneity and knowledge of the noise variance, etc. An important open problem pertains to challenge #2 discussed in the introduction, in conjunction with challenge #1. Instead of assuming precise exogenous knowledge of the reviewersâ€™ miscalibration functions, consider having some access to data from other conferences. Then how can one obtain and use meaningful estimates of reviewer miscalibrations from past conferences while guaranteeing privacy of the current as well as past conferences (â€œfederated learning for calibrationâ€)? In any of these endeavors, one may aim to uncover precise fundamental limits and optimal algorithms, or perhaps design algorithms that are readily applicable in practice with some basic theoretical guarantees.

12

Acknowledgments
This work was supported by NSF CAREER award 1942124, NSF grant CIF 1763734, an NSERC Discovery Grant, and a Google Research Scholar Award. Most of this research was done when Wenxin Ding was at Carnegie Mellon University.
References
[1] S. S. Siegelman. â€œAssassins and zealots: Variations in peer reviewâ€. In: Radiology 178.3 (1991), pp. 637â€“ 642.
[2] P. Flach, S. Spiegler, B. GolÂ´enia, S. Price, J. Guiver, R. Herbrich, T. Graepel, and M. Zaki. â€œNovel Tools to Streamline the Conference Review Process: Experiences from SIGKDDâ€™09â€. In: SIGKDD Explor. Newsl. 11.2 (May 2010), pp. 63â€“67.
[3] H. Ge, M. Welling, and Z. Ghahramani. A Bayesian model for calibrating conference review scores. 2013.
[4] M. Roos, J. Rothe, and B. Scheuermann. â€œHow to Calibrate the Scores of Biased Reviewers by Quadratic Programmingâ€. In: AAAI Conference on Artiï¬cial Intelligence. 2011.
[5] M. Roos, J. Rothe, J. Rudolph, B. Scheuermann, and D. Stoyan. â€œA statistical approach to calibrating the scores of biased reviewers: The linear vs. the nonlinear modelâ€. In: Multidisciplinary Workshop on Advances in Preference Handling. 2012.
[6] S. R. Paul. â€œBayesian methods for calibration of examinersâ€. In: British Journal of Mathematical and Statistical Psychology 34.2 (1981), pp. 213â€“223.
[7] Y. Baba and H. Kashima. â€œStatistical Quality Estimation for General Crowdsourcing Tasksâ€. In: KDD. 2013.
[8] R. S. MacKay, R. Kenna, R. J. Low, and S. Parker. â€œCalibration with conï¬dence: A principled method for panel assessmentâ€. In: Royal Society Open Science 4.2 (2017).
[9] L. Brenner, D. Griï¬ƒn, and D. J. Koehler. â€œModeling patterns of probability calibration with random support theory: Diagnosing case-based judgmentâ€. In: Organizational Behavior and Human Decision Processes 97.1 (2005), pp. 64â€“81.
[10] J. Langford. ICML acceptance statistics. http://hunch.net/?p=2517 [Online; accessed 14-May-2021]. 2012.
[11] J. Wang and N. B. Shah. â€œYour 2 is My 1, Your 3 is My 9: Handling Arbitrary Miscalibrations in Ratingsâ€. In: AAMAS. 2019.
[12] N. Shah, B. Tabibian, K. Muandet, I. Guyon, and U. Von Luxburg. â€œDesign and Analysis of the NIPS 2016 Review Processâ€. In: JMLR 19.1 (2018), pp. 1913â€“1946.
[13] A. Tomkins, M. Zhang, and W. D. Heavlin. â€œReviewer bias in single-versus double-blind peer reviewâ€. In: Proceedings of the National Academy of Sciences 114.48 (2017), pp. 12708â€“12713.
[14] E. Manzoor and N. B. Shah. â€œUncovering Latent Biases in Text: Method and Application to Peer Reviewâ€. In: AAAI. 2021.
[15] I. Stelmakh, N. Shah, and A. Singh. â€œOn Testing for Biases in Peer Reviewâ€. In: NeurIPS. 2019. [16] C. J. Lee. â€œCommensuration bias in peer reviewâ€. In: Philosophy of Science 82.5 (2015), pp. 1272â€“1283. [17] R. Noothigattu, N. B. Shah, and A. D. Procaccia. â€œLoss Functions, Axioms, and Peer Reviewâ€. In:
arXiv preprint arXiv:1808.09057 (2018). [18] M. J. Mahoney. â€œPublication prejudices: An experimental study of conï¬rmatory bias in the peer review
systemâ€. In: Cognitive therapy and research 1.2 (1977), pp. 161â€“175.
13

[19] S. Balietti, R. L. Goldstone, and D. Helbing. â€œPeer review and competition in the Art Exhibition Gameâ€. In: Proceedings of the National Academy of Sciences 113.30 (2016), pp. 8414â€“8419.
[20] I. Stelmakh, N. Shah, and A. Singh. â€œCatch Me if I Can: Detecting Strategic Behaviour in Peer Assessmentâ€. In: arXiv (2020).
[21] Y. Xu, H. Zhao, X. Shi, and N. Shah. â€œOn Strategyproof Conference Reviewâ€. In: IJCAI. 2019.
[22] M. L. Littman. â€œCollusion rings threaten the integrity of computer science researchâ€. In: Communications of the ACM 64.6 (2021), pp. 43â€“44.
[23] S. Jecmen, H. Zhang, R. Liu, N. B. Shah, V. Conitzer, and F. Fang. â€œMitigating Manipulation in Peer Review via Randomized Reviewer Assignmentsâ€. In: NeurIPS. 2020.
[24] R. Wu, C. Guo, F. Wu, R. Kidambi, L. van der Maaten, and K. Weinberger. â€œMaking Paper Reviewing Robust to Bid Manipulation Attacksâ€. In: arXiv:2102.06020 (2021).
[25] N. B. Shah. Systemic Challenges and Solutions on Bias and Unfairness in Peer Review. Preprint http://www.cs.cmu.edu/~nihars/preprints/Shah_Survey_PeerReview.pdf. July 2021.
[26] I. Mitliagkas, A. Gopalan, C. Caramanis, and S. Vishwanath. â€œUser rankings from comparisons: Learning permutations in high dimensionsâ€. In: Allerton Conference. 2011.
[27] A. Ammar and D. Shah. â€œEï¬ƒcient rank aggregation using partial dataâ€. In: SIGMETRICS. 2012.
[28] Y. Freund, R. D. Iyer, R. E. Schapire, and Y. Singer. â€œAn Eï¬ƒcient Boosting Algorithm for Combining Preferencesâ€. In: Journal of Machine Learning Research 4 (2003), pp. 933â€“969.
[29] D. Soergel, A. Saunders, and A. McCallum. â€œOpen Scholarship and Peer Review: A Time for Experimentationâ€. In: (2013).
[30] D. Kang, W. Ammar, B. Dalvi, M. van Zuylen, S. Kohlmeier, E. Hovy, and R. Schwartz. â€œA dataset of peer reviews (peerread): Collection, insights and nlp applicationsâ€. In: arXiv preprint arXiv:1804.09635 (2018).
[31] D. Tran, A. Valtchanov, K. Ganapathy, R. Feng, E. Slud, M. Goldblum, and T. Goldstein. â€œAn Open Review of OpenReview: A Critical Analysis of the Machine Learning Conference Review Processâ€. In: arXiv preprint arXiv:2010.05137 (2020).
[32] H. Bharadhwaj, D. Turpin, A. Garg, and A. Anderson. â€œDe-anonymization of authors through arXiv submissions during double-blind reviewâ€. In: arXiv preprint arXiv:2007.00177 (2020).
[33] W. Yuan, P. Liu, and G. Neubig. â€œCan We Automate Scientiï¬c Reviewing?â€ In: arXiv preprint arXiv:2102.00176 (2021).
[34] I. Stelmakh, N. Shah, A. Singh, and H. DaumÂ´e III. â€œPrior and Prejudice: The Novice Reviewersâ€™ Bias against Resubmissions in Conference Peer Reviewâ€. In: CSCW. 2021.
[35] J. Goldsmith and R. H. Sloan. â€œThe AI conference paper assignment problemâ€. In: Proc. AAAI Workshop on Preference Handling for Artiï¬cial Intelligence, Vancouver. 2007, pp. 53â€“57.
[36] C. J. Taylor. â€œOn the optimal assignment of conference papers to reviewersâ€. In: (2008).
[37] L. Charlin and R. S. Zemel. â€œThe Toronto Paper Matching System: An automated paper-reviewer assignment systemâ€. In: ICML Workshop on Peer Reviewing and Publishing Models. 2013.
[38] N. Garg, T. Kavitha, A. Kumar, K. Mehlhorn, and J. Mestre. â€œAssigning Papers to Refereesâ€. In: Algorithmica 58.1 (Sept. 2010), pp. 119â€“136.
[39] I. Stelmakh, N. Shah, and A. Singh. â€œPeerReview4All: Fair and Accurate Reviewer Assignment in Peer Reviewâ€. In: JMLR (2021).
[40] A. Kobren, B. Saha, and A. McCallum. â€œPaper Matching with Local Fairness Constraintsâ€. In: ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2019.
[41] D. Mimno and A. McCallum. â€œExpertise Modeling for Matching Papers with Reviewersâ€. In: KDD. 2007.
14

[42] T. Fiez, N. Shah, and L. Ratliï¬€. â€œA SUPER* Algorithm to Optimize Paper Bidding in Peer Reviewâ€. In: Conference on Uncertainty in Artiï¬cial Intelligence. 2020.
[43] R. Meir, J. Lang, J. Lesca, N. Kaminsky, and N. Mattei. â€œA market-inspired bidding scheme for peer review paper assignmentâ€. In: Games, Agents, and Incentives Workshop at AAMAS. 2020.
[44] M. Liu, V. Choy, P. Clarke, A. Barnett, T. Blakely, and L. Pomeroy. â€œThe acceptability of using a lottery to allocate research funding: A survey of applicantsâ€. In: Research integrity and peer review 5.1 (2020), pp. 1â€“7.
[45] D. S. Chawla. â€œSwiss funder draws lots to make grant decisionsâ€. In: Nature (2021). [46] A. Philipps. â€œResearch funding randomly allocated? A survey of scientistsâ€™ views on peer review and
lotteryâ€. In: Science and Public Policy (2021). [47] W. Ding, N. B. Shah, and W. Wang. â€œOn the Privacy-Utility Tradeoï¬€ in Peer-Review Data Analysisâ€.
In: AAAI Privacy-Preserving Artiï¬cial Intelligence (PPAI-21) workshop. 2020. [48] C. Dwork, F. McSherry, K. Nissim, and A. Smith. â€œCalibrating noise to sensitivity in private data
analysisâ€. In: Journal of Privacy and Conï¬dentiality 7.3 (2016), pp. 17â€“51. [49] S. L. Warner. â€œRandomized Response: A Survey Technique for Eliminating Evasive Answer Biasâ€. In:
Journal of the American Statistical Association 60.309 (1965), pp. 63â€“69. [50] A. Evï¬mievski, J. Gehrke, and R. Srikant. â€œLimiting Privacy Breaches in Privacy Preserving Data
Miningâ€. In: Proceedings of the 22nd ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems. PODS â€™03. New York, NY, USA: ACM, 2003, pp. 211â€“222. [51] S. P. Kasiviswanathan, H. K. Lee, K. Nissim, S. Raskhodnikova, and A. Smith. â€œWhat Can We Learn Privately?â€ In: SIAM Journal on Computing 40.3 (2011), pp. 793â€“826.
Appendices
A Simulations: Correcting miscalibration with and without exogeneous information
In the introduction section in the main text, we discussed two ways of reducing miscalibration: one where only the current conferencesâ€™ data is used and another where miscalibration parameters of reviewers are obtained exogenously (e.g., from previous conferences). In this section, we conduct a simulation-based study to understand the performance of these approaches: What is the reduction in error if correcting for miscalibration? What if the reviewer-calibration parameters are known?
Our main results in the main text was focused on privacy and considered a setting with two reviewers and two papers. In this section we consider a larger number of reviewers and papers. The methods we simulate in this more general setting do not consider privacy.
We ï¬rst describe the simulation setting, and then discuss the results. The code for the simulations is available here: https://github.com/wenxind/calibration-with-privacy-in-peer-review.
Conference review setup: We consider 100 reviewers and 100 papers. We assign reviewers to papers uniformly at random with 3 reviewers per paper and 3 papers per reviewer.
Miscalibration model: We assume each reviewer has a linear miscalibration function: the miscalibration function fj of reviewer j is given by fj(Î¸âˆ—) = ajÎ¸âˆ— + bj where Î¸âˆ— is the true quality of the paper being reviewed. For every paper i, its true quality Î¸iâˆ— is drawn from a Gaussian distribution with mean 0 and variance 1 independent of all else. The scalars aj in the reviewersâ€™ miscalibration functions are i.i.d. exponential random variables with rate 1. The biases bj are i.i.d. Gaussian random variables with mean 0
15

Kendall-tau distance Messy middle error

0.25 0.20 0.15 0.10 0.05 0.00 0.0

No calibration Within-conference calibration Calibration with known parameters
0.1 Var0ia.n2ce o0f .n3oise 0.4 0.5
(a) Kendall-Ï„ distance.

0.4 0.3 0.2 0.1 0.0 0.0

No calibration Within-conference calibration Calibration with known parameters
0.1 Var0ia.n2ce o0f .n3oise 0.4 0.5
(b) Messy middle error.

Figure 3: A simulation of the review process where the reviewers are miscalibrated.

and variance 0.5. The score given by any reviewer j to any paper i is then given as Î¸iâˆ— is ajÎ¸iâˆ— + bj + ij where ij is a Gaussian random variable with mean 0, whose variance is varied in the plots.
Calibration methods: We consider the following three methods to calibrate the decisions.

â€¢ No calibration: The score for each paper is the mean score of the 3 review scores.

â€¢ Within-conference calibration: For each reviewer, we compute the mean score and standard deviation of the 3 review scores given by the reviewer and normalize the 3 scores by subtracting mean and dividing standard deviation. Then the score for each paper is the mean score of the 3 normalized review scores.

â€¢ Calibration with known parameters: We assume that the miscalibration parameters of the reviewers are

known (exogeneously). Then we estimate the quality of each paper via maximum likelihood estimation

as follows. For any paper i, let Ri denote the set of reviewers for paper i. Then the estimate of the

score for any paper i is

jâˆˆRi aj (sjiâˆ’bj )
2

where

sji

denotes

the

score

given

by

reviewer

j

to

paper

i.

jâˆˆRi aj

For each paper, we then take a mean of the calibrated scores across all its reviewers. The papers are then ranked according to these mean scores; we call this the estimated ranking.
Error metrics: We consider two ways of measuring the error between the ranking of the papers in terms of their true scores and the ranking of the papers in terms of their estimated scores.

â€¢ Kendall tau distance: Given two rankings of the papers, the Kendall tau distance between the two ranking is numtobtearl onfumdibsceorrodfanptaiprsairs .
â€¢ Messy middle error: Given two rankings of the 100 papers, suppose that the conference wishes to accept the top 25 papers. Then we consider papers 11-40 as those that are marginal accepts, and we measure the error as the fraction of these papers which are (erroneously) rejected. In other words, the messy middle error equals number of papers whose true ranking is betw3e0en 11â€“40 that are wrongly accepted/rejected .
Results: The results of the simulations are shown in Figure 3. Each point depicts the mean from 100 iterations of these simulations. The error bars are too small to be visible. We see that correcting for miscalibration even without access to the parameters can lead to signiï¬cant reduction in the error as compared to not correcting for the miscalibration. Furthermore, if the parameters were known (e.g., from other conferences) then it can lead to multi-fold further reductions in the error.

16

B Connection to Local Diï¬€erential Privacy
In this section, we discuss the connections between our algorithm and diï¬€erential privacy (DP). We recall the deï¬nition of DP:
Deï¬nition B.1 ([48]). An algorithm M : X n â†’ Y is -diï¬€erentially private (DP) if, for all X, X âˆˆ X n which diï¬€er in one entry (often called neighboring databases) and S âŠ† Y , we have that
Pr[M (X) âˆˆ S] â‰¤ e Pr[M (X ) âˆˆ S].
Roughly speaking, a procedure involving n users is -locally diï¬€erentially private if each user applies an -DP algorithm to their single datapoint and shares only the result with other users or a data curator. The most familiar LDP algorithm is (binary) randomized response.
Deï¬nition B.2. Binary randomized response with parameter Î³ is an algorithm M : {0, 1} â†’ {0, 1}, which, given input x, outputs x with probability 1+1Î³ , and outputs 1 âˆ’ x with probability 1+Î³Î³ .
The following claim is immediate from the deï¬nition of diï¬€erential privacy and randomized response.
Proposition B.3. Binary randomized response with parameter e is -DP.
We now relate randomized response to the algorithms proposed in our setting. The private information for our calibration problem consists solely of the reviewer assignment A, which takes one of two diï¬€erent values (i.e., reviewer 1 is assigned to paper 1 and reviewer 2 is assigned to paper 2, or vice versa). These two reviewer assignments can be considered to be â€œneighboringâ€ datasets, as mentioned in Deï¬nition B.1. All other information (paper scores S and reviewer calibration functions) are assumed to be public.
As argued in Proposition 4.1, it is without loss of optimality to solely consider strategies of the form h, in which the conference calibrates according to the true assignment with probability h(S, A) and according to the false assignment otherwise. This can be rephrased into the language of randomized response by considering the assignment A to be the input bit to binary randomized response, in which it is preserved with probability h(S, A) (in the language of Deï¬nition B.2, h(S, A) = 1+1Î³ ) and ï¬‚ipped otherwise, and then the conference calibrates with the resulting assignment.
We caution that this connection does not directly imply that our algorithms are diï¬€erentially private. This is because the probability h(S, A) is selected in a data-dependent way, whereas diï¬€erential privacy requires it to be data independent. Nevertheless, our work provides tight guarantees on the probability that an MAP adversary can determine the true assignment.
C Appendix: Proofs
In the appendix, we present complete proofs of the results claimed in the main text.
C.1 Proof of Proposition 4.1
The most generic calibration strategy can be represented using a function g such that for any given score and assignment, g outputs a probability for accepting paper 1. In other words, the conference accepts paper 1 with probability g(S, A) and accepts paper 2 with probability 1 âˆ’ g(S, A). We propose a calibration strategy using function h instead of g, where h outputs a probability that the conference calibrates under the true assignment by accepting the paper with higher estimated quality under the true assignment.
Calibrating using the calibration strategy of function h diï¬€ers from calibrating using the calibration strategy of function g only when the same paper has higher estimated quality under both assignments by the MAP. Since otherwise, when calibrating under the true assignment and calibrating assuming the wrong assignment lead to accepting diï¬€erent papers, either paper can have arbitrary non-zero probability of being accepted (their probabilities sum to 1) by adjusting the output of h(S, A1) and h(S, A2). Then it is the same calibration strategy as using function g.
17

Note that the adversary makes its guess using the MAP argmax{A=A1orA=A2} Pr(A = A|D = P, S = [s1, s2]) where D is the random variable for the decision made by the conference (acceptance of paper) and
P is the paper being accepted. By expanding the probability expression, we have that

argmax Pr(A = A|D = P, S = [s1, s2])
A=A1 orA=A2

= argmax Pr(A = A, D = P |S = [s1, s2]) A=A1orA=A2 Pr(D = P |S = [s1, s2])

= argmax Pr(D = P |A = A, S = [s1, s2]) Pr(A = A|S = [s1, s2])

A=A1 orA=A2

Pr(D = P |S = [s1, s2])

= argmax Pr(D = P |A = A, S = [s1, s2]) Pr(A = A|S = [s1, s2]).
A=A1 orA=A2

If the same paper has higher estimated quality under both assignments, and the conference accepts the believed higher-quality paper, then the adversary guesses the assignment based on the scores only. Because the adversary knows the calibration strategy used by the conference, if P is the paper that has higher quality under both assignments, then Pr(D = P |A = A, S = [s1, s2]) = 1 for both A = A1 and A = A2. Therefore, the MAP used by the adversary simpliï¬es to argmaxA=A1orA=A2 Pr(A = A|S = [s1, s2]). In this case, the conference does not have extra privacy leakage by accepting P since the adversary is making its guess based on the information that is already public (the scores). In addition, if the conference has non-zero probability of accepting the other paper, its utility decreases by accepting the lower-quality paper. Even if the conference accepts the lower-quality paper, the error of the adversary remains unchanged as it can use the scores to guess the assignment without being aï¬€ected by the conference decision. Thus, there is no need for the conference to have non-zero probability for accepting the paper that has lower-quality under both assignments.
In conclusion, calibrating using the calibration strategy of function h instead of the calibration strategy of function g does not reduce the optimally of the conference. Therefore, we consider the calibration strategy with function h in our analysis.

C.2 Proof of Theorem 4.2

To ï¬nd the Pareto frontier of per-instance error of the adversary against per-instance error of the conference,

we ï¬rst derive expressions for per-instance error of the conference and the adversary. We ï¬nd a ï¬xed

expression for the error of the conference and calculate the maximum per-instance error of the adversary

in diï¬€erent cases. We then analyze the relation between the errors and complete plots for maximum per-

instance error of the adversary for any per-instance error of conference. Finally, we derive the Pareto frontier

from the plots.

In the noiseless setting, the conference uses the inverse functions of reviewersâ€™ miscalibration functions

and the scores to exactly compute the quality of the papers. If the conference estimates the qualities

assuming that A1 was the actual assignment, we get Î¸1 = Î²1âˆ’1(s1) and Î¸2 = Î²2âˆ’1(s2). If the conference

estimates the qualities assuming that A2 was the actual assignment, we get Î¸1 = Î²2âˆ’1(s1) and Î¸2 = Î²1âˆ’1(s2).

If

s1

>

max

{Î²

2

(Î²

âˆ’ 1

1

(s2

))

,

Î²1

(Î²

âˆ’ 2

1

(

s2

))

},

then

Î¸1

>

Î¸2

under

both

assignments

(and

hence

paper

1

should

be accepted).

Similarly,

if

s1

<

min

{Î²

2

(

Î²

âˆ’1 1

(s2

)),

Î²1

(Î²

âˆ’ 2

1

(s2

))}

,

then

Î¸1

<

Î¸2

under

both

assignments

and hence paper 2 should be accepted.

Therefore,

when

s1

>

max

{Î²

2

(Î²

âˆ’ 1

1

(s2

)),

Î²1

(Î²

âˆ’ 2

1

(s2

))

}

or

s1

<

min

{Î²

2

(

Î²

âˆ’1 1

(s2

))

,

Î²1

(

Î²

âˆ’1 2

(s2

))}

,

which

is

a

subset

of

part

(1)

of

Theorem

4.2,

the

same

paper

has

higher

estimated quality under both assignments, and hence that paper will be accepted irrespective of the function

h. Thus, under this condition, the Pareto optimal curve comprises just a single point where the conference has

zero error, and the adversary obtains no additional information from the acceptance decision as compared

to the scores S = [s1, s2]. The error of the adversary is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} when it guesses the assignment using only the scores and not the decision.

For the rest scores, the conference uses function h to decide acceptance of paper. Since S is a ï¬xed

18

realization in the analysis, we simplify the calibration strategy for the conference as
q1 = h(S, A1) q2 = h(S, A2).
We now consider the rest scores in part (1) of the theorem. If s1 = Î²2(Î²1âˆ’1(s2)), the conference accepts each paper uniform at random if calibrating under A1 and accepts paper 1 if calibrating under A2. Since paper 1 has higher or equal quality than paper 2, the conference only has error when paper 2 is accepted and A = A2.

Pr(conference accepts lower-quality paper|S = [s1, s2]) = Pr(conference accepts lower-quality paper|S = [s1, s2], D = P1) Pr(D = P1|S = [s1, s2])
+ Pr(conference accepts lower-quality paper|S = [s1, s2], D = P2) Pr(D = P2|S = [s1, s2]) = Pr(conference accepts lower-quality paper|S = [s1, s2], D = P2) Pr(D = P2|S = [s1, s2]).
Given that the conference accepts P2, the probability of the conference making error is the probability Pr(A = A2|S = [s1, s2]).

Pr(D = P2|S = [s1, s2])

= Pr(D = P2|S = [s1, s2], A = A1) Pr(A = A1|S = [s1, s2])

+ Pr(D = P2|S = [s1, s2], A = A2) Pr(A = A2|S = [s1, s2])

1

1

= 2 q1 Pr(A = A1|S = [s1, s2]) + 2 (1 âˆ’ q2) Pr(A = A2|S = [s1, s2]).

For the adversary, if paper 1 is accepted, it gains no information on the assignment other than the scores so its error is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} . Otherwise, it guesses A = A1 and its error is Pr(A = A2|S = [s1, s2]). Note that error of the adversary does not exceed minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} since in the worst case for the adversary, it guesses the assignment solely based on the scores and ignore the conference decision.

Pr(adversary guesses assignment wrong|S = [s1, s2])

= Pr(adversary guesses assignment wrong|S = [s1, s2], D = P1) Pr(D = P1|S = [s1, s2])

+ Pr(adversary guesses assignment wrong|S = [s1, s2], D = P2) Pr(D = P2|S = [s1, s2])

= min{f1(s1)f2(s2), f2(s1)f1(s2)} (1 âˆ’ 1 q1) Pr(A = A1|S = [s1, s2]) + ( 1 + 1 q2) Pr(A = A2|S = [s1, s2])

f1(s1)f2(s2) + f2(s1)f1(s2)

2

22

1

1

+ Pr(A = A2|S = [s1, s2]) 2 q1 Pr(A = A1|S = [s1, s2]) + 2 (1 âˆ’ q2) Pr(A = A2|S = [s1, s2])

Therefore, we can minimize the error of the conference to 0 by choosing q1 = 0 and q2 = 1, which results in the conference always accepts paper 1. Then error of the adversary is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} , which is maximized. Further increase of error of the conference cannot increase error of the adversary. So the Pareto

optimal point is (0, minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} ). The same argument works when s1 = Î²1(Î²2âˆ’1(s2)).

In

the

noiseless

setting

where

min{

Î²

2

(

Î²

âˆ’1 1

(s2

))

,

Î²1

(

Î²

âˆ’1 2

(s2

))

}

<

s1

<

max

{Î²

2

(

Î²

âˆ’1 1

(s2

))

,

Î²1

(

Î²

âˆ’1 2

(s2

))}

,

which is part (2) of Theorem 4.2, we ï¬rst ï¬nd the maximum per-instance error of the adversary given

per-instance error of the conference in this range. We will show the proof with the assumptions that Î²2(Î²1âˆ’1(s2)) > Î²1(Î²2âˆ’1(s2)) and f1(s1)f2(s2) > f2(s1)f1(s2). The proof follows the same procedure for other values of Î²2(Î²1âˆ’1(s2)), Î²1(Î²2âˆ’1(s2)), f1(s1)f2(s2), and f2(s1)f1(s2).

19

When the scores satisfy Î²1(Î²2âˆ’1(s2)) < s1 < Î²2(Î²1âˆ’1(s2)), the conference always accepts the higherquality paper if it calibrates under the true assignment, and the conference always accepts the lower-quality paper if it calibrates assuming the wrong assignment. But the conference can calibrate assuming the wrong assignment for the purpose of misleading the adversary. We use A to denote the random variable for the assignment, D to denote the random variable for the conference decision and S is the scores. In addition, we use C to denote the calibration status. If the conference calibrates under the true assignment then C = T . Otherwise, C = F .
Therefore, the error of the conference is computed as

Pr(conference accepts lower-quality paper|S = [s1, s2])

= Pr(C = F |S = [s1, s2])

= Pr(C = F, A = A1|S = [s1, s2]) + Pr(C = F, A = A2|S = [s1, s2])

= Pr(C = F |A = A1, S = [s1, s2]) Pr(A = A1|S = [s1, s2])

+ Pr(C = F |A = A2, S = [s1, s2])P (A = A2|S = [s1, s2])

=(1 âˆ’ q1) Â·

f1(s1)f2(s2)

+ (1 âˆ’ q2) Â·

f2(s1)f1(s2)

f1(s1)f2(s2) + f2(s1)f1(s2)

f1(s1)f2(s2) + f2(s1)f1(s2)

=1 âˆ’ f1(s1)f2(s2)q1 + f2(s1)f1(s2)q2 . f1(s1)f2(s2) + f2(s1)f1(s2)

The adversary uses MAP to guess the assignment. If the two assignments have the same a posteriori
probability, then the adversary makes a random guess between the assignments where either assignment has probability 21 of being guessed. When making a guess, the adversary observes the scores and the conference decision. So the adversary ï¬nds argmax{A=A1orA=A2} Pr(A = A|D = P, S = [s1, s2]) where P is the paper being accepted. Following Section C.1, the adversary ï¬nds

argmax Pr(A = A|D = P, S = [s1, s2])
A=A1 orA=A2
= argmax Pr(D = P |A = A, S = [s1, s2]) Pr(A = A|S = [s1, s2])
A=A1 orA=A2
= argmax (Pr(D = P |A = A, S = [s1, s2], C = T ) Pr(C = T |A = A, S = [s1, s2])
A=A1 orA=A2
+ Pr(D = P |A = A, S, C = F ) Pr(C = F |A = A, S = [s1, s2])) Â· Pr(A = A|S = [s1, s2]) = argmax (Pr(D = P |A = A, S = [s1, s2], C = T ) Â· h(S = [s1, s2], A = A)
A=A1 orA=A2
+ Pr(D = P |A = A, S = [s1, s2], C = F ) Â· (1 âˆ’ h(S = [s1, s2], A = A))) Â· Pr(A = A|S = [s1, s2])
Under our assumptions of Î²2(Î²1âˆ’1(s2)) > Î²1(Î²2âˆ’1(s2)) and f1(s1)f2(s2) > f2(s1)f1(s2), paper 1 has higher estimated quality under A1 and paper 2 has higher estimated quality under A2. Suppose paper 1 is accepted, i.e., D = P1. The value of the above expression under A = A1 is
(Pr(D = P1|A = A1, S = [s1, s2], C = T ) Â· h(S = [s1, s2], A = A1) + Pr(D = P1|A = A1, S = [s1, s2], C = F ) Â· (1 âˆ’ h(S = [s1, s2], A = A1))) Â· Pr(A = A1|S = [s1, s2]) =(q1 + 0) Â· f1(s1)f2(s2) =f1(s1)f2(s2)q1.
On the other hand, suppose paper 1 is accepted, the value of the above expression under A = A2 is
(Pr(D = P1|A = A2, S = [s1, s2], C = T ) Â· h(S = [s1, s2], A = A2) + Pr(D = P1|A = A2, S = [s1, s2], C = F ) Â· (1 âˆ’ h(S = [s1, s2], A = A2))) Â· Pr(A = A2|S = [s1, s2]) =(0 + (1 âˆ’ q2)) Â· f1(s1)f2(s2) =f2(s1)f1(s2)(1 âˆ’ q2).

20

Therefore, when the conference accepts paper 1, if f1(s1)f2(s2)q1 > f2(s1)f1(s2)(1 âˆ’ q2), then the adversary guesses A = A1. Otherwise, it guesses A = A2 except that when f1(s1)f2(s2)q1 = f2(s1)f1(s2)(1 âˆ’ q2), it makes a random guess assigning probability 21 to each assignment. Similarly, if paper 2 is accepted, the adversary compares f1(s1)f2(s2)(1 âˆ’ q1) and f2(s1)f1(s2)q2 where it guesses A = A1 when f1(s1)f2(s2)(1 âˆ’ q1) > f2(s1)f1(s2)q2. There are 2 papers and 2 possible assignments, so we have 4 scenarios combining decisions and assignments.
1. Scenario 1: A = A1 and D = P1 This scenario happens with probability Pr(A = A1, D = P1|S = [s1, s2]) = f1(s1)ff12((ss12))f+2f(2s(2s)1q1)f1(s2) . In this scenario, the adversary guesses wrong if f1(s1)f2(s2)q1 < f2(s1)f1(s2)(1 âˆ’ q2).
2. Scenario 2: A = A1 and D = P2 This scenario happens with probability Pr(A = A1, D = P2|S = [s1, s2]) = f1(sf11)(fs21()sf22)(+s2f)2((1sâˆ’1)qf11)(s2) . In this scenario, the adversary guesses wrong if f1(s1)f2(s2)(1 âˆ’ q1) < f2(s1)f1(s2)q2.
3. Scenario 3: A = A2 and D = P1 This scenario happens with probability Pr(A = A1, D = P1|S = [s1, s2]) = f1(sf12)(fs21()sf21)(+s2f)2((1sâˆ’1)qf21)(s2) . In this scenario, the adversary guesses wrong if f1(s1)f2(s2)q1 > f2(s1)f1(s2)(1 âˆ’ q2).
4. Scenario 4: A = A2 and D = P2 This scenario happens with probability Pr(A = A1, D = P2|S = [s1, s2]) = f1(s1)ff22((ss12))f+1f(2s(2s)1q2)f1(s2) . In this scenario, the adversary guesses wrong if f1(s1)f2(s2)(1 âˆ’ q1) > f2(s1)f1(s2)q2.
To compute the error of the adversary, we need to compare f1(s1)f2(s2) and f2(s1)f1(s2). So as in our assumptions, f1(s1)f2(s2) > f2(s1)f1(s2). From the above 4 scenarios, 2 of them compare f1(s1)f2(s2)q1 with f2(s1)f1(s2)(1âˆ’q2) and 2 of them compare f1(s1)f2(s2)q1 with f1(s1)f2(s2)âˆ’f2(s1)f1(s2)q2. To analyze the error of the adversary, we consider 5 cases of the value of f1(s1)f2(s2)q1 separated by f2(s1)f1(s2)(1 âˆ’ q2) and f1(s1)f2(s2) âˆ’ f2(s1)f1(s2)q2. For each case, we refer to the 4 scenarios of (A, D) above. Also note that EC ([s1, s2]) = 1 âˆ’ f1f(s11(s)f12)f(s22(s)q21)++ff22((ss11))ff11((ss22))q2 as computed above.
â€¢ If f1(s1)f2(s2)q1 < f2(s1)f1(s2) âˆ’ f2(s1)f1(s2)q2, the adversary guesses wrong in scenarios 1 and 4. Error of the adversary EA([s1, s2]) is f1f(s11(s)f12)f(s22(s)q21)++ff22((ss11))ff11((ss22))q2 . Since EC ([s1, s2]) = 1âˆ’ f1f(s11(s)f12)f(s22(s)q21)++ff22((ss11))ff11((ss22))q2 , the relation between error of the adversary and error of the conference is EA([s1, s2]) = 1 âˆ’ EC ([s1, s2]). For 0 â‰¤ f1(s1)f2(s2)q1 < f2(s1)f1(s2) âˆ’ f2(s1)f1(s2)q2, EC ([s1, s2]) âˆˆ ( f1(s1)ff21((ss21))+ff22((ss21))f1(s2) , 1].
â€¢ If f1(s1)f2(s2)q1 = f2(s1)f1(s2) âˆ’ f2(s1)f1(s2)q2, the adversary makes random guess in scenarios 1 and 3 and guesses wrong in scenario 4. Error of the adversary EA([s1, s2]) is f1(s1)ff22((ss21))+ff12((ss21))f1(s2) and error of the conference EC ([s1, s2]) is . f1 (s1 )f2 (s2 )
f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )
â€¢ If f2(s1)f1(s2) âˆ’ f2(s1)f1(s2)q2 < f1(s1)f2(s2)q1 < f1(s1)f2(s2) âˆ’ f2(s1)f1(s2)q2, the adversary guesses wrong in scenarios 3 and 4. Error of the the adversary EA([s1, s2]) is f1(s1)ff22((ss21))+ff12((ss21))f1(s2) , which is constant. In this case, since error of the conference EC ([s1, s2]) = 1 âˆ’ f1f(s11(s)f12)f(s22(s)q21)++ff22((ss11))ff11((ss22))q2 , we can ï¬nd that EC ([s1, s2]) ranges from ( f1(s1)ff22((ss21))+ff12((ss21))f1(s2) to f1(s1)ff21((ss21))+ff22((ss21))f1(s2) ).
â€¢ If f1(s1)f2(s2)q1 = f1(s1)f2(s2) âˆ’ f2(s1)f1(s2)q2, the adversary makes random guess in scenarios 2 and 4 and guesses wrong in scenario 3. Error of the adversary EA([s1, s2]) is f1(s1)ff22((ss21))+ff12((ss21))f1(s2) and error of the conference EC ([s1, s2]) is also f1(s1)ff22((ss21))+ff12((ss21))f1(s2) .
21

Error of the adversary

' %+'

'

0.5

%+'

Error of the 1 conference

(a) Maximum per-instance error of the adversary given perinstance error of the conference when u > v.

% %+'

Error of the adversary

%

0.5

%+'

Error of the 1 conference

(b) Maximum per-instance error of the adversary given perinstance error of the conference when u â‰¤ v

Figure 4: Relation between error of the adversary and error of the conference with u = f1(s1)f2(s2) and v = f2(s1)f1(s2).

â€¢ If f1(s1)f2(s2)q1 > f1(s1)f2(s2) âˆ’ f2(s1)f1(s2)q2, the adversary guesses wrong in scenarios 2 and 3.
Error of the adversary EA([s1, s2]) is 1 âˆ’ f1f(s11(s)f12)f(s22(s)q21)++ff22((ss11))ff11((ss22))q2 , which is the same as the error of the conference EC ([s1, s2]). The relation between error of the adversary and error of the conference is EA([s1, s2]) = EC ([s1, s2]). For 1 â‰¥ f1(s1)f2(s2)q1 > f1(s1)f2(s2) âˆ’ f2(s1)f1(s2)q2, EC ([s1, s2]) âˆˆ [0, f1(s1)ff22((ss21))+ff12((ss21))f1(s2) ).
Therefore, the relation between error of the adversary and error of the conference when f1(s1)f2(s2) > f2(s1)f1(s2) is of the shape of a trapezoid in [0, 1] with the three line segments of the slope +1, 0, and -1 as in Figure 4a. Note that the relation between the per-instance errors does not change with the relation between values of f1(s1)f2(s2) and f2(s1)f1(s2). So Figure 4a is the relation between the errors when u > v. Similarly, Figure 4b is the relation between the errors when u â‰¤ v.
From Figure 4 we see that the conference should keep its per-instance error less than minu{+uv,v} to stay optimal. Because if the error of the conference is greater than minu{+uv,v} , increasing its error does not increase the error of the adversary and thus is not optimal. Thus, the Pareto frontier of per-instance error of the adversary against error of the conference is the ï¬rst line segment with slope 1 in both Figure 4a and Figure 4b when min{Î²2(Î²1âˆ’1(s2)), Î²1(Î²2âˆ’1(s2))} < s1 < max{Î²2(Î²1âˆ’1(s2)), Î²1(Î²2âˆ’1(s2))}.
C.3 Proof of Theorem 4.3
We prove that Algorithm 1 is optimal for each instance of scores S = [s1, s2] with desired error of the conference EC ([s1, s2]) in the noiseless setting.

22

From Theorem 4.2 we know that if a paper has higher estimated quality under both assignments, the

conference should accept the paper. This is the optimal calibration strategy for the conference.

Otherwise

when

min{Î²

2

(Î²

âˆ’ 1

1

(s2

))

,

Î²1

(Î²

âˆ’ 2

1

(s2

))

}

<

s1

<

max

{Î²

2

(Î²

âˆ’ 1

1

(s2

))

,

Î²1

(Î²

âˆ’ 2

1

(

s2

))

},

we

use

the

Pareto frontier in Theorem 4.2 to explain the optimality of our algorithm. Suppose f1(s1)f2(s2) â‰¤ f2(s1)f1(s2),

then the endpoint on the Pareto frontier has both error of the conference and error of the adversary being

f1(s1)ff21((ss21))+ff22((ss21))f1(s2) . If EC ([s1, s2]) < f1(s1)ff21((ss21))+ff22((ss21))f1(s2) , we maximize the error of the adversary by operating on the Pareto frontier. If EC ([s1, s2]) â‰¥ f1(s1)ff21((ss21))+ff22((ss21))f1(s2) , we operate at the endpoint where

error of the adversary is maximum and error of the conference is no larger than the desired EC ([s1, s2]). The

endpoint is the point with minimum error of the conference such that error of the adversary is maximum.

Therefore, it is optimal for the conference.

Similarly, if f1(s1)f2(s2) > f2(s1)f1(s2), the algorithm is also optimal by maximizing error of the adver-

sary under desired error of the conference following the Pareto frontier. Algorithm 1 follows the procedure

by choosing the corresponding q1 and q2 for each point on the Pareto frontier and thus is optimal for the

conference.

C.4 Proof of Theorem 4.4

Algorithm 1 with EC ([s1, s2]) = 1 operates on the endpoint of the Pareto frontier when min{Î²2(Î²1âˆ’1(s2)), Î²1(Î²2âˆ’1(s2))} <

s1

<

max

{Î²

2

(

Î²

âˆ’1 1

(s2

))

,

Î²1

(

Î²

âˆ’1 2

(s2

))}

.

We

use

Î¶

to

denote

the

error

of

running

Algorithm

1

with

EC ([s1, s2])

=

1 for all [s1, s2]. Then we have Algorithm 2 that has a maximum allowable average-case error of the conference

EC as input.

If EC â‰¥ Î¶, we operate at EC = Î¶ by running Algorithm 1 with EC ([s1, s2]) = 1. From Theorem 4.3

we know that Algorithm 1 with EC ([s1, s2]) = 1 is Pareto optimal for all score pairs such that the error of

the adversary is maximized and no smaller error of the conference can achieve the same privacy guarantee.

Increasing the error of the conference will not increase the error of the adversary. Thus, it is Pareto optimal

for the allowable average-case error of the conference.
If EC < Î¶, the coin toss ensures that the average-case error of the conference is Î¶ Â· EÎ¶C + 0 Â· (1 âˆ’ EÎ¶C ) = EC . If we use Î· to denote the average-case error of the adversary when the conference always calibrates under the true assignment, then the average-case error of the adversary when the conference

runs Algorithm 1 with EC ([s1, s2]) = 1 is Î¶ + Î·. Because when the conference always calibrates un-

der

the

true

assignment,

the

adversary

only

makes

error

when

s1

â‰¤

min

{Î²

2

(

Î²

âˆ’1 1

(s2

)),

Î²1

(Î²

âˆ’ 2

1

(s2

))}

or

s1

â‰¥

max

{Î²

2

(Î²

âˆ’1 1

(s2

)),

Î²1

(Î²

âˆ’ 2

1

(s2

))}

.

And if the conference adopts Algorithm 1 with EC ([s1, s2]) = 1,

the adversary has error Î· when s1 â‰¤ min{Î²2(Î²1âˆ’1(s2)), Î²1(Î²2âˆ’1(s2))} or s1 â‰¥ max{Î²2(Î²1âˆ’1(s2)), Î²1(Î²2âˆ’1(s2))}

and

has

error

Î¶

when

min

{

Î²

2

(

Î²

âˆ’1 1

(s2

))

,

Î²1

(

Î²

âˆ’1 2

(s2

))

}

<

s1

<

max{

Î²

2

(

Î²

âˆ’1 1

(s2

))

,

Î²1

(

Î²

âˆ’1 2

(s2

))

}

.

Therefore,

the

average-case

error

of

the

adversary

is

(Î·

+ Î¶) Â·

EC Î¶

+Î·

Â· (1 âˆ’

EÎ¶C )

=

EC

+ Î·.

From Theorem 4.3 we know

that when the conference has per-instance error EC, the maximum per-instance error of the adversary is

EC if min{Î²2(Î²1âˆ’1(s2)), Î²1(Î²2âˆ’1(s2))} < s1 < max{Î²2(Î²1âˆ’1(s2)), Î²1(Î²2âˆ’1(s2))}. In addition, a Pareto optimal strategy when s1 â‰¤ min{Î²2(Î²1âˆ’1(s2)), Î²1(Î²2âˆ’1(s2))} or s1 â‰¥ max{Î²2(Î²1âˆ’1(s2)), Î²1(Î²2âˆ’1(s2))} has error of the

adversary being Î· and error of the conference being 0. Therefore, for the average-case error of the conference

being EC, the average-case error of the adversary is no larger than EC + Î·. Therefore Algorithm 2 is Pareto

optimal.

C.5 Proof of Theorem 4.5

To ï¬nd the Pareto frontier of per-instance error of the adversary against per-instance error of the conference

in the noisy setting, we ï¬rst ï¬nd the maximum per-instance error of the adversary given per-instance error

of the conference in this range.

Prior to computing the errors, we compute the posterior distribution of the quality of the papers given the

assignment and scores. We have Î¸1âˆ—|{S = [s1, s2], A = A1} âˆ¼ N

, a1(s1âˆ’b1) Ïƒ2
a2+Ïƒ2 a2+Ïƒ2

and Î¸1âˆ—|{S = [s1, s2], A =

1

1

A2} âˆ¼ N

, a2(s1âˆ’b2) Ïƒ2
a2+Ïƒ2 a2+Ïƒ2

.

Similarly, Î¸2âˆ—|{S = [s1, s2], A = A1} âˆ¼ N

, a2(s2âˆ’b2) Ïƒ2
a2+Ïƒ2 a2+Ïƒ2

2

2

2

2

and Î¸2âˆ—|{S =

23

[s1, s2], A = A2} âˆ¼ N a1a(21s+2âˆ’Ïƒb21) , a21Ïƒ+2Ïƒ2 . We show calculation for one of the posterior distribution. Note that in continuous space, the probability is taken as the density of the corresponding distribution.
Pr(Î¸1âˆ— = t|S = [s1, s2], A = A1) = Pr(S = [s1, s2]|Î¸1âˆ— = t, A = A1) Â· Pr(Î¸1âˆ— = t|A = A1)
Pr(S = [s1, s2]|A = A1)

Then we separately compute each term in the equation above. Note that s1|{Î¸1âˆ— = t, A = A1} âˆ¼ N (a1t + b1, Ïƒ2) and s1|A = A1 âˆ¼ N (b1, a21 + Ïƒ2). Since s2 is independent of Î¸1âˆ— given that A = A1, s2|{Î¸1âˆ— = t, A = A1} and s2|A = A1 have the same distribution. In addition, Î¸âˆ— and A are independent.

Pr(S = [s1, s2]|Î¸1âˆ— = t, A = A1)

= Pr(S[1] = s1|Î¸1âˆ— = t, A = A1) Â· Pr(S[2] = s2|A = A1)

1

âˆ’ 1 s1âˆ’(a1t+b1) 2

=âˆš e 2

Ïƒ

Â· Pr(S[2] = s2|A = A1)

2Ï€Ïƒ

Pr(Î¸2âˆ— = t|A = A1)

1 =âˆš

e

âˆ’

1 2

t

2

2Ï€

Pr(S = [s1, s2]|A = A1)

= Pr(S[1] = s1|A = A1) Â· Pr(S[2] = s2|A = A1)

=âˆš 2Ï€

1

âˆ’ 12

e

a21 + Ïƒ2

âˆšs1 âˆ’b1 a2 +Ïƒ2 1

2
Â· Pr(S[2] = s2|A = A1)

Therefore, combining the terms we get

Pr(Î¸1âˆ— = t|S = [s1, s2], A = A1)

âˆš1

eâˆ’

1 2

= 2Ï€Ïƒ

s1âˆ’(a1 t+b1) Ïƒ

2

Â· Pr(S[2] = s2|A = A1) Â· âˆš1

e

âˆ’

1 2

t

2

2Ï€

2

âˆ’1

âˆš âˆš1

2
e

2Ï€ a21+Ïƒ2

âˆšs1 âˆ’b1 a2 +Ïƒ2 1

Â· Pr(S[2] = s2|A = A1)

1 =âˆš
2Ï€

a21 + Ïƒ2 eâˆ’ 12 Ïƒ2

âˆš s1âˆ’(a1t+b1) 2+t2âˆ’ Ïƒ

2 s1 âˆ’b1
a2 +Ïƒ2 1

1 =âˆš
2Ï€

a21

+

Ïƒ2

âˆ’
e

1 2

Ïƒ2

tâˆ’ a1a(2s+ 1âˆ’Ïƒ2b1)
1

. 2 a2+Ïƒ2

Â·

1 Ïƒ2

The other three posteriors are computed in a similar fashion. Given the posterior distribution of the qualities, we can compute the posterior probability that one paper
has higher quality than the other.

24

Pr(Î¸1âˆ— > Î¸2âˆ—|A = A1, S = [s1, s2])

= Pr N

a1(s1 âˆ’ b1) Ïƒ2

a2 + Ïƒ2 , a2 + Ïƒ2

1

1

>N

a2(s2 âˆ’ b2) Ïƒ2

a2 + Ïƒ2 , a2 + Ïƒ2

2

2

a1(s1 âˆ’ b1) a2(s2 âˆ’ b2) Ïƒ2

Ïƒ2

= Pr N a2 + Ïƒ2 âˆ’ a2 + Ïƒ2 , a2 + Ïƒ2 + a2 + Ïƒ2 > 0

1

2

1

2

= Pr

a1(s1 âˆ’ b1) a2(s2 âˆ’ b2)

a2 + Ïƒ2 âˆ’ a2 + Ïƒ2 +

1

2

Ïƒ2

Ïƒ2

a2 + Ïƒ2 + a2 + Ïƒ2 N (0, 1) > 0

1

2

= Pr

N (0, 1) > a2(a21 + Ïƒ2)(s2 âˆ’ b2) âˆ’ a1(a22 + Ïƒ2)(s1 âˆ’ b1) Ïƒ2(a21 + a22 + 2Ïƒ2)(a21 + Ïƒ2)(a22 + Ïƒ2)

=1 âˆ’ Î¦

a2(a21 + Ïƒ2)(s2 âˆ’ b2) âˆ’ a1(a22 + Ïƒ2)(s1 âˆ’ b1) Ïƒ2(a21 + a22 + 2Ïƒ2)(a21 + Ïƒ2)(a22 + Ïƒ2)

We use Î¦ to denote the cumulative distribution function of standard Gaussian distribution. Similarly, we can compute that

Pr(Î¸1âˆ— â‰¤ Î¸2âˆ—|A = A1, S = [s1, s2]) = Î¦

a2(a21 + Ïƒ2)(s2 âˆ’ b2) âˆ’ a1(a22 + Ïƒ2)(s1 âˆ’ b1) Ïƒ2(a21 + a22 + 2Ïƒ2)(a21 + Ïƒ2)(a22 + Ïƒ2)

Pr(Î¸1âˆ— > Î¸2âˆ—|A = A2, S = [s1, s2]) = 1 âˆ’ Î¦

a1(a22 + Ïƒ2)(s2 âˆ’ b1) âˆ’ a2(a21 + Ïƒ2)(s1 âˆ’ b2) Ïƒ2(a21 + a22 + 2Ïƒ2)(a21 + Ïƒ2)(a22 + Ïƒ2)

Pr(Î¸1âˆ— â‰¤ Î¸2âˆ—|A = A2, S = [s1, s2]) = Î¦

a1(a22 + Ïƒ2)(s2 âˆ’ b1) âˆ’ a2(a21 + Ïƒ2)(s1 âˆ’ b2) Ïƒ2(a21 + a22 + 2Ïƒ2)(a21 + Ïƒ2)(a22 + Ïƒ2)

For simplicity, let Î¦1 = Î¦

âˆš a2 (a21 +Ïƒ 2 )(s2 âˆ’b2 )âˆ’a1 (a22 +Ïƒ 2 )(s1 âˆ’b1 )
Ïƒ 2 (a21 +a22 +2Ïƒ 2 )(a21 +Ïƒ 2 )(a22 +Ïƒ 2 )

and Î¦2 = Î¦

âˆš . a1(a22+Ïƒ2)(s2âˆ’b1)âˆ’a2(a21+Ïƒ2)(s1âˆ’b2)
Ïƒ 2 (a21 +a22 +2Ïƒ 2 )(a21 +Ïƒ2 )(a22 +Ïƒ 2 )

Since the conference does calibration using the posterior probabilities, the values of Î¦1 and Î¦2 determines

the conference decision. By Proposition 4.1, we know that the conference should accept the paper with

higher estimated quality under both assignments without any calibration. Therefore, if Î¦1 and Î¦2 are both

less than 12 , the conference should accept paper 1. Similarly, if Î¦1 and Î¦2 are both greater than 12 , the

conference

should

accept

paper

2.

Otherwise,

when

Î¦1 âˆ’

1 2

and

Î¦2 âˆ’

1 2

have

diï¬€erent

signs,

the

conference

should do calibration with function h. As before, since S is a ï¬xed realization in the analysis, we simplify

the calibration strategy for the conference as

q1 = h(S, A1) q2 = h(S, A2).

We ï¬rst consider part (1) of the theorem. If s1 > max a2(aa211+(aÏƒ222+)(Ïƒs22)âˆ’b2) + b1, a1(aa222+(aÏƒ212+)(Ïƒs22)âˆ’b1) + b2 ,

which

is

when

Î¦1

â‰¤

1 2

and

Î¦2

â‰¤

12 ,

the

conference

accepts

paper

1

and

the

adversary

guesses

the

assignment

based on the scores only. Then the error of the conference is the probability that paper 2 has higher quality.

Pr(Î¸1âˆ— < Î¸2âˆ—|S = [s1, s2]) = Pr(Î¸1âˆ— < Î¸2âˆ—|A = A1, S = [s1, s2]) Â· Pr(A = A1|S = [s1, s2])
+ Pr(Î¸1âˆ— < Î¸2âˆ—|A = A2, S = [s1, s2]) Â· Pr(A = A2|S = [s1, s2])

=Î¦1 Â·

f1(s1)f2(s2)

+ Î¦2 Â·

f2(s1)f1(s2)

f1(s1)f2(s2) + f2(s1)f1(s2)

f1(s1)f2(s2) + f2(s1)f1(s2)

25

Similarly, if s1 < min a2(aa211+(aÏƒ222+)(Ïƒs22)âˆ’b2) + b1, a1(aa222+(aÏƒ212+)(Ïƒs22)âˆ’b1) + b2 , which is when Î¦1 â‰¥ 12 and Î¦2 â‰¥ 12 , the conference accepts paper 2 and the error of the conference is the probability that paper 1 has higher
quality.

Pr(Î¸1âˆ— > Î¸2âˆ—|S = [s1, s2]) = Pr(Î¸1âˆ— > Î¸2âˆ—|A = A1, S = [s1, s2]) Â· Pr(A = A1|S = [s1, s2])
+ Pr(Î¸1âˆ— > Î¸2âˆ—|A = A2, S = [s1, s2]) Â· Pr(A = A2|S = [s1, s2])

=(1 âˆ’ Î¦1) Â·

f1(s1)f2(s2)

+ (1 âˆ’ Î¦2) Â·

f2(s1)f1(s2)

f1(s1)f2(s2) + f2(s1)f1(s2)

f1(s1)f2(s2) + f2(s1)f1(s2)

In both cases, error of the adversary is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} , which is the error when the adversary guesses the assignment based on scores only.
We now consider the rest scores in part (1) of the theorem. If s1 = max a2(aa211+(aÏƒ222+)(Ïƒs22)âˆ’b2) + b1, a1(aa222+(aÏƒ212+)(Ïƒs22)âˆ’b1) + b2 , without loss of generality, we assume max a2(aa211+(aÏƒ222+)(Ïƒs22)âˆ’b2) + b1, a1(aa222+(aÏƒ212+)(Ïƒs22)âˆ’b1) + b2 = Î²2(Î²1âˆ’1(s2)), then the conference accepts each paper uniform at random if calibrating under A1 and accepts paper 1 if calibrat-
ing under A2. Since paper 1 has higher or equal quality than paper 2, the conference only has error when
paper 2 is accepted and A = A2.

Pr(conference accepts lower-quality paper|S = [s1, s2])
= Pr(conference accepts lower-quality paper|S = [s1, s2], D = P1) Pr(D = P1|S = [s1, s2])
+ Pr(conference accepts lower-quality paper|S = [s1, s2], D = P2) Pr(D = P2|S = [s1, s2]) = Pr(Î¸1âˆ— < Î¸2âˆ—|S = [s1, s2]) Pr(D = P1|S = [s1, s2])
+ Pr(Î¸1âˆ— > Î¸2âˆ—|S = [s1, s2]) Pr(D = P2|S = [s1, s2]).
Note that in this case, Pr(Î¸1âˆ— < Î¸2âˆ—|S = [s1, s2]) < Pr(Î¸1âˆ— > Î¸2âˆ—|S = [s1, s2]). By similar calculation as in Appendix C.3, we have

1

1

Pr(D = P1|S = [s1, s2]) = 2 (1 âˆ’ q1) Pr(A = A1|S = [s1, s2]) + 2 q2 Pr(A = A2|S = [s1, s2])

1

1

Pr(D = P2|S = [s1, s2]) = 2 q1 Pr(A = A1|S = [s1, s2]) + 2 (1 âˆ’ q2) Pr(A = A2|S = [s1, s2]).

Error of the conference is then a convex combination of Pr(Î¸1âˆ— < Î¸2âˆ—|S = [s1, s2]) and Pr(Î¸1âˆ— > Î¸2âˆ—|S = [s1, s2]) and is minimized when the weight of Pr(Î¸1âˆ— > Î¸2âˆ—|S = [s1, s2]) is 0.
For the adversary, if paper 1 is accepted, it gains no information on the assignment other than the scores so its error is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} . Otherwise, it guesses A = A1 and its error is Pr(A = A2|S = [s1, s2]). Note that error of the adversary does not exceed minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} since in the worst case for the adversary, it guesses the assignment solely based on the scores and ignore the conference decision.

Pr(adversary guesses assignment wrong|S = [s1, s2])

= Pr(adversary guesses assignment wrong|S = [s1, s2], D = P1) Pr(D = P1|S = [s1, s2])

+ Pr(adversary guesses assignment wrong|S = [s1, s2], D = P2) Pr(D = P2|S = [s1, s2])

= min{f1(s1)f2(s2), f2(s1)f1(s2)} (1 âˆ’ 1 q1) Pr(A = A1|S = [s1, s2]) + ( 1 + 1 q2) Pr(A = A2|S = [s1, s2])

f1(s1)f2(s2) + f2(s1)f1(s2)

2

22

1

1

+ Pr(A = A2|S = [s1, s2]) 2 q1 Pr(A = A1|S = [s1, s2]) + 2 (1 âˆ’ q2) Pr(A = A2|S = [s1, s2])

26

Therefore, we can minimize the error of the conference to 0 by choosing q1 = 0 and q2 = 1, which results

in the conference always accepts paper 1. Then error of the adversary is minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} , which is

maximized. Further increase of error of the conference cannot increase error of the adversary. So the Pareto

optimal point is (Î¦1 Â· f1(s1)ff21((ss21))+ff22((ss21))f1(s2) + Î¦2 Â· f1(s1)ff22((ss21))+ff12((ss21))f1(s2) , minf1{(fs11()sf12)(fs22()s+2)f,2f(2s(1s)1f)1f(1s(2s)2)} ). The

same argument follows when s1 = min a2(aa211+(aÏƒ222+)(Ïƒs22)âˆ’b2) + b1, a1(aa222+(aÏƒ212+)(Ïƒs22)âˆ’b1) + b2 .

We then look at part (2) of the theorem where the scores lie in the region min a2(aa211+(aÏƒ222+)(Ïƒs22)âˆ’b2) + b1, a1(aa222+(aÏƒ212+)(Ïƒs22)âˆ’b1) + b2 <

s1 < max a2(aa211+(aÏƒ222+)(Ïƒs22)âˆ’b2) + b1, a1(aa222+(aÏƒ212+)(Ïƒs22)âˆ’b1) + b2 . We will then show the proof with the assumptions

that

f1(s1)f2(s2)

<

f2(s1)f1(s2)

and

Î¦1

=

1 2

âˆ’ Ï•1

and

Î¦2

=

1 2

+ Ï•2

with

0

<

Ï•2

<

Ï•1.

The

analysis

is

of

the

same

procedure

for

diï¬€erent

assumptions

on

the

values

of

f1(s1)f2(s2),

f2(s1)f1(s2),

Î¦1

and

Î¦2

with

Î¦1

âˆ’

1 2

and

Î¦2 âˆ’

1 2

having

diï¬€erent

signs.

The

notations

are

of

the

same

meaning

as

in

Section

C.3.

In

the

noisy

set-

ting, even if the conference calibrates under the true assignment, there is still possibility to accept the lower-

quality paper due to the noise in the scores given by the reviewers. Note that with the assumptions and when

min

+ b , + b a2(a21+Ïƒ2)(s2âˆ’b2)

a1 (a22 +Ïƒ 2 )(s2 âˆ’b1 )

a1 (a22 +Ïƒ 2 )

1

a2 (a21 +Ïƒ 2 )

2

< s1 < max

+ b , + b , a2(a21+Ïƒ2)(s2âˆ’b2)

a1 (a22 +Ïƒ 2 )(s2 âˆ’b1 )

a1 (a22 +Ïƒ2 )

1

a2 (a21 +Ïƒ2 )

2

the conference accepts paper 1 if calibrates under A1 and accepts paper 2 if calibrates under A2 by the

assumptions on Î¦1 and Î¦2. So we have

Pr(conference accepts lower-quality paper|S = [s1, s2])
= Pr(conference accepts P1, Î¸1âˆ— < Î¸2âˆ—|S = [s1, s2]) + Pr(conference accepts P2, Î¸1âˆ— > Î¸2âˆ—|S = [s1, s2]) = Pr(conference accepts P1|Î¸1âˆ— < Î¸2âˆ—, S = [s1, s2]) Â· Pr(Î¸1âˆ— < Î¸2âˆ—|S = [s1, s2])
+ Pr(conference accepts P2|Î¸1âˆ— > Î¸2âˆ—, S = [s1, s2]) Â· Pr(Î¸1âˆ— > Î¸2âˆ—|S = [s1, s2]).

We then expand each of the two terms.

Pr(conference accepts P1|Î¸1âˆ— < Î¸2âˆ—, S = [s1, s2])

= Pr(conference accepts P1, A = A1|Î¸1âˆ— < Î¸2âˆ—, S = [s1, s2]) + Pr(conference accepts P1, A = A2|Î¸1âˆ— < Î¸2âˆ—, S = [s1, s2])

= Pr(conference accepts P1|A = A1, Î¸1âˆ— < Î¸2âˆ—, S = [s1, s2]) Â· P (A = A1|Î¸1âˆ— < Î¸2âˆ—, S = [s1, s2])

+ Pr(conference accepts P1|A = A2, Î¸1âˆ— < Î¸2âˆ—, S = [s1, s2]) Â· Pr(A = A2|Î¸1âˆ— < Î¸2âˆ—, S = [s1, s2])

= Pr(C = T |A = A1, Î¸1âˆ— < Î¸2âˆ—, S = [s1, s2]) Pr(A = A1|Î¸1âˆ— < Î¸2âˆ—, S = [s1, s2])

+ Pr(C = F |A = A2, Î¸1âˆ— < Î¸2âˆ—, S = [s1, s2]) Pr(A = A2|Î¸1âˆ— < Î¸2âˆ—, S = [s1, s2])

=q1 Pr(A = A1|Î¸1âˆ— < Î¸2âˆ—, S = [s1, s2]) + (1 âˆ’ q2) Pr(A = A2|Î¸1âˆ— < Î¸2âˆ—, S = [s1, s2])

Pr(A = A1, Î¸1âˆ— < Î¸2âˆ—|S = [s1, s2])

Pr(A = A2, Î¸1âˆ— < Î¸2âˆ—|S = [s1, s2])

=q1 Pr(Î¸âˆ— < Î¸âˆ—|S = [s1, s2]) + (1 âˆ’ q2) Pr(Î¸âˆ— < Î¸âˆ—|S = [s1, s2])

1

2

1

2

Pr(Î¸1âˆ— < Î¸2âˆ—|A = A1, S = [s1, s2]) Â· Pr(A = A1|S = [s1, s2])

=q1

Pr(Î¸âˆ— < Î¸âˆ—|S = [s1, s2])

1

2

Pr(Î¸1âˆ— < Î¸2âˆ—|A = A2, S = [s1, s2]) Â· Pr(A = A2|S = [s1, s2])

+ (1 âˆ’ q2)

Pr(Î¸âˆ— < Î¸âˆ—|S = [s1, s2])

.

1

2

Similarly,

Pr(conference accepts P2|Î¸1âˆ— > Î¸2âˆ—, S = [s1, s2])

Pr(Î¸1âˆ— > Î¸2âˆ—|A = A1, S = [s1, s2]) Â· Pr(A = A1|S = [s1, s2])

=(1 âˆ’ q1)

Pr(Î¸âˆ— > Î¸âˆ—|S = [s1, s2])

1

2

Pr(Î¸1âˆ— > Î¸2âˆ—|A = A2, S = [s1, s2]) Â· Pr(A = A2|S = [s1, s2])

+ q2

Pr(Î¸âˆ— > Î¸âˆ—|S = [s1, s2])

1

2

27

Therefore, we have

Pr(conference accepts lower-quality paper|S = [s1, s2])

=q1 Pr(Î¸1âˆ— < Î¸2âˆ—|A = A1, S = [s1, s2]) Â· Pr(A = A1|S = [s1, s2]) + (1 âˆ’ q2) Pr(Î¸1âˆ— < Î¸2âˆ—|A = A2, S = [s1, s2]) Â· Pr(A = A2|S = [s1, s2]) + (1 âˆ’ q1) Pr(Î¸1âˆ— > Î¸2âˆ—|A = A1, S = [s1, s2]) Â· Pr(A = A1|S = [s1, s2]) + q2 Pr(Î¸1âˆ— > Î¸2âˆ—|A = A2, S = [s1, s2]) Â· Pr(A = A2|S = [s1, s2])

= f1(s1)f2(s2)

Â· (q1Î¦1 + (1 âˆ’ q1)(1 âˆ’ Î¦1))

f1(s1)f2(s2) + f2(s1)f1(s2)

+ f2(s1)f1(s2) Â· ((1 âˆ’ q2)Î¦2 + q2(1 âˆ’ Î¦2)). f1(s1)f2(s2) + f2(s1)f1(s2)

Under

the

assumptions

that

Î¦1

=

1 2

âˆ’ Ï•1

and

Î¦2

=

1 2

+ Ï•2

where

0

<

Ï•2

<

Ï•1

and

f1(s1)f2(s2)

<

f2(s1)f1(s2), we analyze the per-instance error of the adversary similar to the procedure in Section C.2.

There are 4 scenarios combining the decision and the true assignment.

1. Scenario 1: A = A1 and D = P1
This scenario happens with probability Pr(A = A1, D = P1|S = [s1, s2]) = f1(s1)ff12((ss12))f+2f(2s(2s)1q1)f1(s2) . In this scenario, the adversary guesses wrong if q1f1(s1)f2(s2) < (1 âˆ’ q2)f2(s1)f1(s2).

2. Scenario 2: A = A1 and D = P2
This scenario happens with probability Pr(A = A1, D = P1|S = [s1, s2]) = f1(sf11)(fs21()sf22)(+s2f)2((1sâˆ’1)qf11)(s2) . In this scenario, the adversary guesses wrong if (1 âˆ’ q1)f1(s1)f2(s2) < q2f2(s1)f1(s2).

3. Scenario 3: A = A2 and D = P1
This scenario happens with probability Pr(A = A1, D = P1|S = [s1, s2]) = f1(sf12)(fs21()sf21)(+s2f)2((1sâˆ’1)qf21)(s2) . In this scenario, the adversary guesses wrong if q1f1(s1)f2(s2) > (1 âˆ’ q2)f2(s1)f1(s2).

4. Scenario 4: A = A2 and D = P2
This scenario happens with probability Pr(A = A1, D = P1|S = [s1, s2]) = f1(s1)ff22((ss12))f+1f(2s(2s)1q2)f1(s2) . In this scenario, the adversary guesses wrong if (1 âˆ’ q1)f1(s1)f2(s2) > q2f2(s1)f1(s2).

To compute the error of the adversary, we need to compare f1(s1)f2(s2) and f2(s1)f1(s2). So we suppose f1(s1)f2(s2) < f2(s1)f1(s2). From the above 4 scenarios, 2 of them compare f1(s1)f2(s2)q1 with f2(s1)f1(s2)(1 âˆ’ q2) and 2 of them compare f1(s1)f2(s2)q1 with f1(s1)f2(s2) âˆ’ f2(s1)f1(s2)q2. To analyze the error of the adversary, we consider 5 cases of the value of f1(s1)f2(s2)q1 separated by f2(s1)f1(s2)(1 âˆ’ q2) and f1(s1)f2(s2) âˆ’ f2(s1)f1(s2)q2. We refer to the 4 scenarios of (A, D) above.

â€¢ If q1f1(s1)f2(s2) < f1(s1)f2(s2) âˆ’ q2f2(s1)f1(s2), the adversary guesses wrong in scenarios 1 and 4. Error of the adversary EA([s1, s2]) is q1ff11((ss11))ff22((ss22))++fq22f(s21(s)f11)f(s12(s)2) .

â€¢ If q1f1(s1)f2(s2) = f1(s1)f2(s2) âˆ’ q2f2(s1)f1(s2), the adversary makes random guess in scenarios 2

and 4 and guesses wrong in scenario 1. Error of the adversary EA([s1, s2]) is f1(s1)qf12f(1s(2s)1+)ff22((ss12))f1(s2) +

( + ) = . 1

(1âˆ’q1 )f1 (s1 )f2 (s2 )

2 f1(s1)f2(s2)+f2(s1)f1(s2)

q2 f2 (s1 )f1 (s2 ) f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

f1 (s1 )f2 (s2 ) f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

â€¢ If f1(s1)f2(s2) âˆ’ q2f2(s1)f1(s2) < q1f1(s1)f2(s2) < f2(s1)f1(s2) âˆ’ q2f2(s1)f1(s2), the adversary guesses wrong in scenarios 1 and 2. Error of the adversary EA([s1, s2]) is f1(s1)ff21((ss21))+ff22((ss21))f1(s2) .

â€¢ If q1f1(s1)f2(s2) = f2(s1)f1(s2) âˆ’ q2f2(s1)f1(s2), the adversary makes random guess in scenarios 1

and 3 and guesses wrong in scenario 2. Error of the adversary EA([s1, s2]) is f1(s(11)âˆ’f2q(1s)2f)1+(sf12)(fs21()sf21)(s2) +

( + ) = . 1

q1 f1 (s1 )f2 (s2 )

2 f1(s1)f2(s2)+f2(s1)f1(s2)

(1âˆ’q2 )f2 (s1 )f1 (s2 ) f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

f1 (s1 )f2 (s2 ) f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

28

â€¢ If q1f1(s1)f2(s2) > f2(s1)f1(s2) âˆ’ q2f2(s1)f1(s2), the adversary guesses wrong in scenarios 2 and 3. Error of the adversary EA([s1, s2]) is 1 âˆ’ q1ff11((ss11))ff22((ss22))++fq22f(s21(s)f11)f(s12(s)2) .
To ï¬nd the maximum error of the adversary given error of the conference, we solve an optimization problem. In order to formulate the optimization problem, we can combine the 5 cases above into 3 cases for simplicity.

â€¢ If q1f1(s1)f2(s2) â‰¤ f1(s1)f2(s2)âˆ’q2f2(s1)f1(s2), error of the adversary EA([s1, s2]) is q1ff11((ss11))ff22((ss22))++qf22f(s21(s)f11)f(s12(s)2) .
â€¢ If f1(s1)f2(s2) âˆ’ q2f2(s1)f1(s2) â‰¤ q1f1(s1)f2(s2) â‰¤ f2(s1)f1(s2) âˆ’ q2f2(s1)f1(s2), error of the adversary EA([s1, s2]) is f1(s1)ff21((ss21))+ff22((ss21))f1(s2) .

â€¢ If q1f1(s1)f2(s2) â‰¥ f2(s1)f1(s2)âˆ’q2f2(s1)f1(s2), error of the adversary EA([s1, s2]) is 1âˆ’ q1ff11((ss11))ff22((ss22))++qf22f(s21(s)f11)f(s12(s)2) .

We let T (EC ) = EC (u + v) âˆ’ u Â· (1 âˆ’ Î¦1) âˆ’ v Â· Î¦2 to be a function that takes the error of the conference as input.

â€¢ Maximize q1ff11((ss11))ff22((ss22))++fq22f(s21(s)f11)f(s12(s)2) subject to EC ([s1, s2])(f1(s1)f2(s2) + f2(s1)f1(s2)) âˆ’ f1(s1)f2(s2) Â· (1 âˆ’ Î¦1) âˆ’ f2(s1)f1(s2) Â· Î¦2 = f1(s1)f2(s2)(2Î¦1 âˆ’ 1)q1 + f2(s1)f1(s2) Â· (1 âˆ’ 2Î¦2)q2 and q1f1(s1)f2(s2) â‰¤ f1(s1)f2(s2) âˆ’ q2f2(s1)f1(s2).
The maximum occurs at q1f1(s1)f2(s2) = f1(s1)f2(s2) âˆ’ q2f2(s1)f1(s2). Then the intersection of the two lines is q1 = 1 âˆ’ (2Î¦1âˆ’(21Î¦)u1âˆ’+T2Î¦(E2Câˆ’(2[)su1,s2])) and q2 = (2Î¦1âˆ’(21Î¦)u1âˆ’+T2Î¦(E2Câˆ’(2[s)v1,s2])) .

â€“ If the intersection point can be reached, q1, q2 âˆˆ [0, 1], (2Î¦1 âˆ’ 1)u â‰¤ T (EC ([s1, s2])) â‰¤ (1 âˆ’ 2Î¦2)u,

then error of the conference EC ([s1, s2]) ranges from f1(s1)ff12((ss12))f+2(fs22()sÎ¦1)1f1(s2) + f1(s1)ff22((ss12))f+1(fs22()sÎ¦1)2f1(s2)

to + . f1(s1)f2(s2)(2âˆ’Î¦1âˆ’2Î¦2)
f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

f2 (s1 )f1 (s2 )Î¦2 f1 (s1 )f2 (s2 )+f2 (s1 )f1 (s2 )

Error of the adversary EA([s1, s2]) is f1(s1)ff21((ss21))+ff22((ss21))f1(s2) .

â€“ If the intersection point can not be reached and T (EC ([s1, s2])) < (2Î¦1 âˆ’ 1)u, then no q1, q2 are qualiï¬ed for the constraints.

â€“ If the intersection point can not be reached and T (EC ([s1, s2])) > (1 âˆ’ 2Î¦2)u.

âˆ— If (1 âˆ’ 2Î¦2)u < T (EC ([s1, s2])) â‰¤ 0 then the maximum is reached when q1 = 0 and q2 = T ((E1Câˆ’(2[sÎ¦12,s)v2])) .

Error

of

the

conference

EC ([s1, s2])

ranges

from

(2âˆ’Î¦1 âˆ’2Î¦2 )u+Î¦2 v u+v

(when

T (EC ([s1, s2]))

=

(1 âˆ’ 2Î¦2)u)

to

(1âˆ’Î¦1 )u+Î¦2 v u+v

(when

T (EC ([s1, s2])) = 0).

Error of the adversary EA([s1, s2]) is (T1(âˆ’E2CÎ¦([2s)1(,us+2]v))) , ranges from u+u v (when T (EC ([s1, s2])) =

(1 âˆ’ 2Î¦2)u) to 0 (when T (EC ([s1, s2])) = 0).

âˆ— If T (EC ([s1, s2])) > 0 then no q1, q2 are qualiï¬ed for the constraints.

â€¢ Error of the adversary EA([s1, s2]) is f1(s1)ff21((ss21))+ff22((ss21))f1(s2) subject to f1(s1)f2(s2) âˆ’ q2f2(s1)f1(s2) â‰¤ q1f1(s1)f2(s2) â‰¤ f2(s1)f1(s2) âˆ’ q2f2(s1)f1(s2).

From Figure 5 we can see that error of the conference EC ([s1, s2]) has its extremes at q1 = 0, q2 =

u v

and

q1

=

1, q2

=

1âˆ’

uv .

Therefore, error of the conference ranges from (2âˆ’Î¦1âˆ’u2+Î¦v2)u+Î¦2v to

(Î¦1+2Î¦2âˆ’u1+)uv+(1âˆ’Î¦2)v .

â€¢ Maximize 1âˆ’ q1ff11((ss11))ff22((ss22))++qf22f(s21(s)f11)f(s12(s)2) subject to EC ([s1, s2])(f1(s1)f2(s2)+f2(s1)f1(s2))âˆ’f1(s1)f2(s2)Â· (1 âˆ’ Î¦1) âˆ’ f2(s1)f1(s2) Â· Î¦2 = f1(s1)f2(s2)(2Î¦1 âˆ’ 1)q1 + f2(s1)f1(s2) Â· (1 âˆ’ 2Î¦2)q2 and q1f1(s1)f2(s2) â‰¥ f2(s1)f1(s2) âˆ’ q2f2(s1)f1(s2).
The maximum occurs at q1f1(s1)f2(s2) = f2(s1)f1(s2) âˆ’ q2f2(s1)f1(s2). Then the intersection of the two lines is q1 = (1âˆ’2Î¦(22âˆ’)v2âˆ’Î¦T1âˆ’(E2CÎ¦(2[s)u1,s2])) and q2 = T (EC((2[sâˆ’12,sÎ¦21])âˆ’)âˆ’2Î¦(22Î¦)v1âˆ’1)v .

29

!!
1
% '

Line to maximize/minimize intersection

'

!"

1%

Figure 5: A diagram illustrates the optimization problem in this case.

â€“ If the intersection point can be reached, q1, q2 âˆˆ [0, 1], (1 âˆ’ 2Î¦2)v âˆ’ (2 âˆ’ 2Î¦1 âˆ’ 2Î¦2)u â‰¤ T (EC ([s1, s2])) â‰¤ (1âˆ’2Î¦2)v, then error of the conference EC ([s1, s2]) ranges from f1(sf11)(fs21()sf22)(+s2f)2((1sâˆ’1)Î¦f11)(s2) + f1(sf12)(fs21()sf21)(+s2f)2((1sâˆ’1)Î¦f21)(s2) (when T (EC ([s1, s2])) = (1âˆ’2Î¦2)v) to ff11((ss11))ff22((ss22))+(Î¦f21(+s21)Î¦f21âˆ’(s12)) + f1(sf12)(fs21()sf21)(+s2f)2((1sâˆ’1)Î¦f21)(s2) (when T (EC ([s1, s2])) = (1 âˆ’ 2Î¦2)v âˆ’ (2 âˆ’ 2Î¦1 âˆ’ 2Î¦2)u).
Error of the adversary EA([s1, s2]) is f1(s1)ff21((ss21))+ff22((ss21))f1(s2) .
â€“ If the intersection point can not be reached and T (EC ([s1, s2])) > (1 âˆ’ 2Î¦2)v, then no q1, q2 are qualiï¬ed for the constraints.

â€“ If the intersection point can not be reached and T (EC ([s1, s2])) < (1 âˆ’ 2Î¦2)v âˆ’ (2 âˆ’ 2Î¦1 âˆ’ 2Î¦2)u.

âˆ— If (2Î¦1 âˆ’1)u+(1âˆ’2Î¦2)v â‰¤ T (EC ([s1, s2])) < (1âˆ’2Î¦2)v âˆ’(2âˆ’2Î¦1 âˆ’2Î¦2)u then the maximum

is reached when q1 = 1 and q2 = T (EC ([s1(1,sâˆ’22])Î¦)âˆ’2)(v2Î¦1âˆ’1)u .

Error

of

the

conference

EC ([s1, s2])

ranges

from

(Î¦1 +2Î¦2 âˆ’1)u+(1âˆ’Î¦2 )v u+v

(when

T (EC ([s1, s2]))

=

(1âˆ’2Î¦2)vâˆ’(2âˆ’2Î¦1 âˆ’2Î¦2)u)

to

Î¦1 u+(1âˆ’Î¦2 )v u+v

(when

T (EC ([s1, s2]))

=

(2Î¦1 âˆ’1)u+(1âˆ’2Î¦2)v).

Error of the adversary EA([s1, s2]) is 1 âˆ’ T (EC ([s1(,1sâˆ’2]2)Î¦)+2()2(uâˆ’+2vÎ¦)1âˆ’2Î¦2)u , ranges from u+u v (when

T (EC ([s1, s2])) = (1 âˆ’ 2Î¦2)v âˆ’ (2 âˆ’ 2Î¦1 âˆ’ 2Î¦2)u) to 0 (when T (EC ([s1, s2])) = (2Î¦1 âˆ’ 1)u +

(1 âˆ’ 2Î¦2)v).

âˆ— If T (EC ([s1, s2])) < (2Î¦1 âˆ’ 1)u + (1 âˆ’ 2Î¦2)v then no q1, q2 are qualiï¬ed for the constraints.

Therefore,

the

relation

between

error

of

the

adversary

and

error

of

the

conference

when

Î¦1

=

1 2

âˆ’ Ï•1

and

Î¦2

=

1 2

+ Ï•2

where

0

<

Ï•2

<

Ï•1

and

f1(s1)f2(s2)

<

f2(s1)f1(s2)

is

of

the

shape

of

a

trapezoid

in

[0, 1]

as

in

Figure 6. Note that the relation between the per-instance errors does not change with the relation between

values of f1(s1)f2(s2) and f2(s1)f1(s2) or with the values of Î¦1 and Î¦2.
From Figure 6 we see that the conference should keep its per-instance error between uÎ¦1+uv+(1vâˆ’Î¦2) and u(Î¦1+2Î¦2uâˆ’+1v)+v(1âˆ’Î¦2) to stay optimal. The conference cannot have its error less than uÎ¦1+uv+(1vâˆ’Î¦2) due to the reviewersâ€™ noise. If error of the conference is greater than u(Î¦1+2Î¦2uâˆ’+1v)+v(1âˆ’Î¦2) , increasing its error does not increase error the adversary and thus is not optimal. Thus, the Pareto frontier of per-instance error of

the adversary against error of the conference is the ï¬rst line segment with positive slope in Figure 6 when

min

+ b , + b a2(a21+Ïƒ2)(s2âˆ’b2)

a1 (a22 +Ïƒ 2 )(s2 âˆ’b1 )

a1 (a22 +Ïƒ 2 )

1

a2 (a21 +Ïƒ 2 )

2

< s1 < max

+ b , + b . a2(a21+Ïƒ2)(s2âˆ’b2)

a1 (a22 +Ïƒ 2 )(s2 âˆ’b1 )

a1 (a22 +Ïƒ 2 )

1

a2 (a21 +Ïƒ 2 )

2

30

Error of the adversary

% %+'

1

2 0.5 3

4 Error of the

conference

Figure 6: Maximum per-instance error of the adversary given per-instance error of the conference when

u

<

v,

Î¦1

=

1 2

âˆ’ Ï•1

and

Î¦2

=

1 2

+ Ï•2

with

0

<

Ï•2

<

Ï•1.

The

coordinates

in

the

plot

are:

â—‹1

=

uÎ¦1+uv+(1vâˆ’Î¦2) ,

â—‹2 = u(Î¦1+2Î¦2uâˆ’+1v)+v(1âˆ’Î¦2) , â—‹3 = u(2âˆ’Î¦1âˆ’u+2Î¦v 2)+vÎ¦2 , â—‹4 = u(1âˆ’uÎ¦+1)v+vÎ¦2 .

C.6 Proof of Theorem 4.6

We prove that Algorithm 3 is optimal for each instance of scores S = [s1, s2] with desired error of the

conference

EC ([s1, s2])

in

the

noisy

setting.

We

carry

the

assumptions

from

Section

C.5

that

Î¦1

=

1 2

âˆ’ Ï•1

and

Î¦2

=

1 2

+

Ï•2

where

0

<

Ï•2

<

Ï•1

and

f1(s1)f2(s2)

<

f2(s1)f1(s2).

From Proposition 4.1 we know that if a paper has higher estimated quality under both assignments, the

conference should accept the paper. This is the optimal calibration strategy for the conference.
Otherwise when the scores are in the region min a2(aa211+(aÏƒ222+)(Ïƒs22)âˆ’b2) + b1, a1(aa222+(aÏƒ212+)(Ïƒs22)âˆ’b1) + b2 < s1 < max a2(aa211+(aÏƒ222+)(Ïƒs22)âˆ’b2) + b1, a1(aa222+(aÏƒ212+)(Ïƒs22)âˆ’b1) + b2 , we use the Pareto frontiers analyze the optimality of our algorithm. Theorem 4.5 shows that the Pareto frontier in the noiseless setting within this region. The

analysis is similar to the one in the noiseless setting in Section C.3.

Suppose f1(s1)f2(s2) < f2(s1)f1(s2), then the endpoint on the Pareto frontier has error of the adversary being f1(s1)ff21((ss21))+ff22((ss21))f1(s2) and error of the conference being f1(s1)f2(Î¦f11+(s21Î¦)f22âˆ’+1f)+2(fs21()sf11)(fs12()s2)(1âˆ’Î¦2) . If f1(s1f)f12(s(1s2)f)Î¦2(1s+2)f+2(fs21()sf11)(fs12()s(21)âˆ’Î¦2) â‰¤ EC ([s1, s2]) < f1(s1)f2(sf21)((Î¦s11)+f22(Î¦s22âˆ’)+1f)+2(fs21()sf11)(fs12()s2)(1âˆ’Î¦2) , we maximize the error of the adversary by operating on the Pareto frontier. If EC ([s1, s2]) â‰¥ f1(s1)f2(sf21)((Î¦s11)+f22(Î¦s22âˆ’)+1f)+2(fs21()sf11)(fs12()s2)(1âˆ’Î¦2) , we operate at the endpoint where error of the adversary is maximum and error of the conference is no larger

than the desired EC ([s1, s2]). The endpoint is the point with minimum error of the conference such that

error of the adversary is maximum. Therefore, it is optimal for the conference.

Algorithm 3 follows the procedure by choosing the corresponding q1 and q2 for each point on the Pareto

frontier and thus is optimal for the conference.

31

