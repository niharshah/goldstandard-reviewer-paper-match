Improving Fake News Detection by Using an Entity-enhanced
Framework to Fuse Diverse Multimodal Clues
Peng Qi1,2,3, Juan Cao1,2, Xirong Li4, Huan Liu5, Qiang Sheng1,2, Xiaoyue Mi1,2, Qin He6, Yongbiao Lv6, Chenyang Guo6, Yingchao Yu6
1Key Lab of Intelligent Information Processing, Institute of Computing Technology, CAS, Beijing, China 2University of Chinese Academy of Sciences 3Institute of Artificial Intelligence, Hebi, China
4Key Lab of DEKE, Renmin University of China, Beijing, China 5Zhengzhou University, Zhengzhou, China 6Hangzhou ZhongkeRuijian Technology Co., Ltd., Hangzhou, China
{qipeng,caojuan,shengqiang18z,mixiaoyue19s}@ict.ac.cn,xirong@ruc.edu.cn,liuhuan_2012@hotmail.com, {heqin,lvyongbiao,guochenyang,yuyingchao}@ruijianai.com

arXiv:2108.10509v1 [cs.MM] 24 Aug 2021

ABSTRACT
Recently, fake news with text and images have achieved more effective diffusion than text-only fake news, raising a severe issue of multimodal fake news detection. Current studies on this issue have made significant contributions to developing multimodal models, but they are defective in modeling the multimodal content sufficiently. Most of them only preliminarily model the basic semantics of the images as a supplement to the text, which limits their performance on detection. In this paper, we find three valuable text-image correlations in multimodal fake news: entity inconsistency, mutual enhancement, and text complementation. To effectively capture these multimodal clues, we innovatively extract visual entities (such as celebrities and landmarks) to understand the news-related highlevel semantics of images, and then model the multimodal entity inconsistency and mutual enhancement with the help of visual entities. Moreover, we extract the embedded text in images as the complementation of the original text. All things considered, we propose a novel entity-enhanced multimodal fusion framework, which simultaneously models three cross-modal correlations to detect diverse multimodal fake news. Extensive experiments demonstrate the superiority of our model compared to the state of the art.
CCS CONCEPTS
â€¢ Information systems â†’ Multimedia information systems; Social networks.
KEYWORDS
fake news detection; multimodal fusion; visual entity; social media
ACM Reference Format: Peng Qi, Juan Cao, Xirong Li, Huan Liu, Qiang Sheng, Xiaoyue Mi, Qin He, Yongbiao Lv, Chenyang Guo, Yingchao Yu. 2021. Improving Fake News Detection by Using an Entity-enhanced Framework to Fuse Diverse Multimodal Clues. In Proceedings of the 29th ACM International Conference on
Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. MM â€™21, October 20â€“24, 2021, Virtual Event, China Â© 2021 Association for Computing Machinery. ACM ISBN 978-1-4503-8651-7/21/10. . . $15.00 https://doi.org/10.1145/3474085.3481548

Multimedia (MM â€™21), October 20â€“24, 2021, Virtual Event, China. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3474085.3481548
1 INTRODUCTION
The rising prevalence of fake news and its alarming real-world impacts have motivated both academia and industry to develop automatic methods to detect fake news (i.e., designing a classifier to judge a piece of given news as real or fake) [8, 11, 21, 31, 35]. Traditional approaches [4, 15, 18, 19] typically focus on the textual content, which is the main description form of news events. With the recent evolution of fake news from text-only posts to multimedia posts with images or videos [3], approaches based on multimodal content demonstrate promising detection performance [7, 9, 23, 26, 32]. This paper targets multimodal fake news detection, which is utilizing information of multiple modalities (here, text and images) to detect fake news.
Despite recent advancements in developing multimodal models to detect fake news, existing works model the multimodal content insufficiently. Most of them only preliminarily model the basic semantics of the images as the complement of the text, ignoring the characteristics of multimodal fake news. Specifically, some prior arts [23, 26, 27] obtain the multimodal representations by simply concatenating the textual features with visual features extracted from VGG19 [22] that is pre-trained on ImageNet [5].
To make up for this omission, we explore three valuable textimage correlations in multimodal fake news, which provide diverse multimodal clues. a) Text and images have inconsistent entities, which is a potential indicator for multimodal fake news. Wrongly reposting outdated images is a typical way to make up multimodal fake news [1, 2, 20]. However, it is difficult to find both semantically pertinent and non-manipulated images to support these non-factual stories in fake news, causing the inconsistency between text and images. For example, as shown in Figure 1(a), the text describes a piece of news about "Dallas Jones" while the attached image is the arrest scene of another person. b) Text and
images enhance each other by spotting the important features. News text and images are related in high-level semantics, and the aligned parts usually reflect the key elements of news. In this kind of multimodal fake news, the text provides main clues for detection, while images help select the key clues in the text. As Figure 1(b) shows, the Nazi flag in the image corresponds to the important entity "Nazi" in the text, which is the key controversial point of this news post. c) The embedded text in images

Visual Entity: Cuba Gooding Jr.

Visual Entity: Nazi

Dallas Jones, the Biden campaignâ€™s Texas political director, was arrested.
(a) Entity Inconsistenty

Poroshenko praised the Ukrainian puppet army that joined the Nazis in World War II for saving the world and invited them to participate in the Victory Day celebration.
(b) Mutual Enhancement

Recognized Text in the Image Reuters (September 11) reported that the Chinese and Japanese fleets fired at each other in the waters off the Diaoyu Islands. (Translated from Chinese)

Is a war really coming?
(c) Text Complementation
Figure 1: Three valuable text-image correlations in multimodal fake news, which provide diverse clues for detection.
provides complementary information for the original text. According to our preliminary statistics on the Weibo dataset [9], more than 20% of multimodal fake news spreads in the form of image. This refers to news that the embedded text in the image tells the complete fake news story while the original text often is comment (see Figure 1(c)). In this kind of fake news, the clues lie in the combination of the original text and the embedded text in the image.
In addition to the diversity of multimodal clues, another challenge of fusing multimodal information for detection lies in the heterogeneity of multimodal data. Current works focus on the general objects of news images by pre-trained VGG19 or Faster R-CNN, while the news text is in a more abstract semantic level based on named entities1. Due to this semantic gap, current works are hard to reason effectively between text and images for exploiting multimodal clues. For example, as shown in Figure 1(a), we canâ€™t reveal the multimodal inconsistency as clues to detect this news as fake if we only recognize the celebrity in the image as "person" instead of "Cuba Gooding Jr.".
To address this challenge, we innovatively import the visual entities to model the high-level semantics of news images. The visual entities consist of words describing named entities recognized from the images (such as celebrity and landmark) and some news-related visual concepts. They are important for mining the multimodal clues because they 1) contain rich visual semantics
1A narrow definition of name entities are objects that can be denoted with a proper name such as persons, organizations, and places [17].

and thus help understand the multimodal news, and 2) bridge the high-level semantic correlations of news text and images.
All things considered, we propose a novel framework for multimodal fake news detection, named as EM-FEND (Entity-enhanced Multimodal FakE News Detection) (shown in Figure 2), which fuses diverse multimodal clues to detect multimodal fake news. Specifically, 1) in the stage of Multimodal Feature Extraction, in addition to extract the basic visual features through fine-tuned VGG19, we explicitly extract visual entities and the embedded text in images to model the high-level visual semantics. Besides, we explicitly extract textual entities to capture the key elements of news events. 2) In the stage of Multimodal Feature Fusion, we model three types of cross-modal correlations in multimodal fake news to fuse diverse multimodal clues for detection. First, to model the text complementation, we concatenate the original text and the OCR text in images as the composed text and feed it into BERT to obtain the fused textual features. Second, we use co-attention transformers between textual features with visual entities and visual CNN features to model the multimodal mutual enhancement at different visual semantic levels. Third, we measure the multimodal entity inconsistency by calculating the similarity of textual and visual entities. And then, we fuse the above multimodal features by concatenation. 3) In the stage of Classification, the fused multimodal features are used to distinguish the fake and real news. Our main contributions are summarized as follows:
â€¢ We find three valuable text-image correlations in multimodal fake news, and propose a unified framework to fuse these multimodal clues simultaneously.
â€¢ To our best knowledge, we are the first to import the visual entities into multimodal fake news detection, which helps to understand the news-related high-level semantics of images and bridge the high-level semantic correlations of news text and images.
â€¢ Both offline and online evaluations demonstrate the superiority of our model compared to the state of the art.
2 RELATED WORK
We will briefly review existing works on multimodal fake news detection (see Table 1) and explain our novelties accordingly.
The commonly used multimodal fusion framework for detection is to extract general visual features from pre-trained VGG19 [22] and then simply concatenate them with textual features. Based on this framework, Wang et al. [26] imported the event classification as an auxiliary task of fake news classification to guide the learning of event-invariant multimodal features for better generalizability. Then, Wang et al. [27] proposed a meta neural process approach to detect fake news on emergent events. Dhruv et al. [7] revised this framework into a multimodal variational autoencoder to learn a shared representation of multimodal contents for classification. Singhal et al. [23] first imported pre-trained language models (that is BERT, here) into this multimodal framework. Despite the advancements made by these works, they ignore the complex cross-modal correlations in fake news, which limits the effectiveness of multimodal content in detection.
Wrongly reposting irrelevant images is a typical way to make up multimodal fake news, and thus some works focus on measuring

Text Input

Ori-Text
What a pity! One of my favorite actors!

Textual Entities (TE)
Person Place â€¦

Image Input
OCR Text Hollywood movie star Nicholas Cage died on January 17, 2013â€¦
Visual Entities (VE) Celebrity Landmark â€¦
VGG19 Features (VF)

Complementation
Ori-Text Text
OCR Text

BERT Concat

Enhancement
Text

BERT

VE

VE

Text-VE

Co-Attention Text

Text

Text-VF

VF Co-Attention VF

Inconsistency
TE VE

Component Text

Vector

REAL FAKE

Encoder

Multimodal Feature Extraction

Multimodal Feature Fusion

Classification

Figure 2: Architecture of the proposed framework EM-FEND. In the stage of Multimodal Feature Extraction, we explicitly extract the textual and visual entities to model the key news elements, and extract the OCR text and visual CNN features of the input image. In the stage of Multimodal Feature Fusion, we model three text-image correlations, that is text complementation, mutual enhancement, and entity inconsistency. Finally, these multimodal features are fused by concatenation for Classification.

the multimodal consistency for detection. Zhou et al. [34] used the image captioning model to translate the images into sentences and then computed the multimodal inconsistency by measuring the sentence similarity between the original text and the generated image captions. However, the translation performance is limited by the discrepancy between the training corpus of the image captioning model and the real-world news corpus, which further impairs the performance of cross-modal consistency measurement. Xue et al. [29] transformed the textual and visual features into a common feature space by weight sharing and then computed the cosine similarity of transformed multimodal features. Nevertheless, it is still hard to capture the multimodal inconsistency because of the semantic gap between textual and visual features.
On the other hand, some researchers proposed well-designed methods to model multimodal mutual enhancement. Jin et al. [9] proposed a neuron-level attention mechanism, and Zhang et al. [32] used the attention mechanism and multi-channel CNN to fuse multimodal information. These two works focus on the unidirectional enhancement of multimodal content, that is, highlighting the important image regions under textual guidance. Further, Song et al. [24] utilized the co-attention transformer to model the bidirectional enhancement between text and images. Wang et al. [28] extracted objects of the images and then use GCN to model the correlation between words and object labels. Similarly, Li et al. [12] extracted objects and then used the Capsule network to fuse the nouns and

visual features of these objects. Nevertheless, these methods ignore the cross-modal enhancement on high-level semantics.
To sum up, there are two main drawbacks of existing works: 1) They do not consider these three cross-modal correlations simultaneously, and totally ignore the text complementation between the original text and the embedded text, and 2) model the cross-modal correlations based on the basic semantic features of the images, ignoring the news-related high-level visual semantics. To address these issues, we explicitly extract the visual entities and model the multimodal inconsistency and enhancement based on the multimodal entities. Moreover, we extract the embedded text in the images and model the text complementation. All things considered, we design a unified framework to fuse these multimodal clues for detection.
3 ENTITY-ENHANCED MULTIMODAL FAKE NEWS DETECTION
3.1 Model Overview
The goal of the proposed EM-FEND framework is to predict whether the given news is real or fake by utilizing its text ğ‘‡ and the attached image ğ¼ 2. As shown in Figure 2, EM-FEND includes three modules to fuse diverse multimodal clues for fake news detection: 1) Multimodal feature extraction, which extracts the textual and visual
2Our model is applicable to news that contains multiple images, but for simplification we assume that only a single image is present in a piece of news.

Table 1: Comparison between EM-FEND and the state of the art for multimodal fake news detection. These compared methods do not consider three cross-modal correlations at the same time.

Methods
EANN[26] metaFEND[27] MVAE[7] SpotFake[23] SAFE[34]
MCNN[29] attRNN[9] MKEMN[32]
CARMN[24] KMGCN[28] EMAF[12]
EM-FEND(ours)

Backbone

Text Text-CNN Text-CNN Bi-LSTM BERT
Text-CNN
BERT +Bi-GRU Bi-LSTM

Image VGG19 VGG19 VGG19 VGG19 image2sentence +Text-CNN ResNet50 +Attention VGG19

Bi-GRU VGG19

BERT BERT
BERT

VGG19
YOLOv3 Faster-RCNN VGG19 +entity detector +OCR model

Fusion concat concat variational autoencoder concat
concat+multi-loss
attention+multi-loss
neuron-level attention attention +multi-channel CNN co-attention transformer +multi-channel CNN GCN Capsule
co-attention transformer

Cross-modal Correlations

inconsistency -

enhancement -

text complementation -

text-imagecaption

-

-

text-visfea

-

-

-

text->visfea

-

-

text->visfea

-

-

text<->visfea

-

-

text<->objects

-

-

text<->object fea

-

text-visentity

text<->visfea

+

text<->visentity

entities, the embedded text in the image, and the visual CNN features (Section 3.2); 2) Multimodal feature fusion, which models three types of cross-modal correlations, including entity inconsistency, mutual enhancement, and complementation (Section 3.3); and 3) Classification, which uses the obtained multimodal representation to perform binary classification (Section 3.4). We will introduce the above modules in detail.
3.2 Multimodal Feature Extraction
3.2.1 Text Input. Textual Entities. As a special narrative style, news usually
contains named entities such as persons and locations. These entities are of importance in understanding the news semantics and also helpful in detecting fake news. Thus, we explicitly extract the person entities ğ‘·ğ‘‡ and location entities ğ‘³ğ‘‡ by recognizing corresponding proper nouns in the text. For better understanding the news events, we employ the part-of-speech tagging to extract all nouns as a general textual context ğ‘ªğ‘‡ .
3.2.2 Image Input. Visual CNN Features. Following previous works, we adopt
VGG19 to extract the visual features. Unlike these works, we finetune the pre-trained VGG19 on the given dataset to flexibly capture the low-level characteristics of the images from the specific data source to help detection. For example, the image quality is a powerful feature for distinguishing fake news and real news posts on social media, while it is less effective for detecting fake news articles on formal news sites. Then, we extract the visual features of the input image from the output of the last layer of VGG19. Considering that different regions in the image may show different patterns, we split the original image into 7 Ã— 7 regions, and then obtain the

corresponding visual features sequence ğ‘¯ğ‘‰ = [ğ’“1, ..., ğ’“ğ‘›], ğ‘› = 49, where ğ’“ğ‘– represents the feature of the ğ‘–-th region in the image.
Visual Entities. Similar to the text, news images also contain newsworthy visual entities, which are important for semantic understanding and fake news detection. Specifically, we extract four types of visual entities: 1) celebrities and landmarks; 2) organizations, such as Nazi, Buddhism and police, by detecting flags or clothes; 3) eye-striking visual concepts, such as violence, bloodiness, and disaster [20]; and 4) general objects and scenes. Due to the high accuracy requirements for pre-trained models and the lacking of relevant publicly available datasets, we use public APIs3 to detect visual entities instead of re-implement these models. Finally, we obtain the person entities ğ‘·ğ‘‰ , location entities ğ‘³ğ‘‰ , and other newsrelated visual concepts with corresponding probability as a more general image context ğ‘ªğ‘‰ .
Embedded Text. In addition to the original input text, text embedded in images is also important because it usually contains important information missed by the original text. We extract the embedded text ğ‘‚ of the input image by applying the optical character recognition (OCR) model4.
3.3 Multimodal Feature Fusion
3.3.1 Text Complementation. As the main body of multimodal news, the text provides rich clues for the judgment of news credibility. For fake news in social media, in addition to the original text, the embedded text in images is also important in understanding the news semantics and providing clues for detection. In many situations, the key clues for detection lie in the embedded text, while the original text is just a comment about the news event. Therefore, the
3https://ai.baidu.com/tech/imagecensoring, https://ai.baidu.com/tech/imagerecognition 4 https://ai.baidu.com/tech/ocr/general

ğ‘¯ğ‘»â†ğ‘½

ğ‘¯ğ‘½â†ğ‘»

Add & Norm Feed Forward

Add & Norm Feed Forward

Add & Norm
Multi-Head Attention
ğ‘‰" ğ¾" ğ‘„!

Add & Norm
Multi-Head Attention ğ‘„# ğ¾! ğ‘‰!

Textual ğ‘¯ğ‘»

Visual ğ‘¯ğ‘½

Figure 3: Multimodal co-attention transformer layer.

original and the embedded text should be modeled jointly to obtain the whole semantics of the news event. Most existing methods use recurrent or convolutional neural networks to model the contextual information of the textual sequence. Recently, pre-trained language models have shown strong ability in modeling text. Thus, we feed the original text ğ‘‡ and embedded text ğ‘‚ into the pre-trained BERT [6] separated by [ğ‘†ğ¸ğ‘ƒ], that is

ğ‘¯ğ‘‡ = BERT( [ğ¶ğ¿ğ‘†]ğ‘‡ [ğ‘†ğ¸ğ‘ƒ]ğ‘‚ [ğ‘†ğ¸ğ‘ƒ]).

(1)

Then we obtain the textual feature ğ‘¯ğ‘‡ = [ğ’˜1, ..., ğ’˜ğ‘›], where ğ’˜ğ‘– represents the feature of the ğ‘–-th word in the composed text and ğ‘›
is the length of the composed text.

3.3.2 Mutual Enhancement. In multimodal news, important news elements mentioned in the text are usually illustrated and emphasized by images and vice versa. Thus, the text and images could spot the important features respectively by aligning with each other. Inspired by the successes of the co-attention mechanism in VQA tasks [13, 14], we use the multimodal co-attention transformer between textual features with visual entities and visual CNN features to model multimodal alignment at different visual levels.
Multimodal Co-attention Transformer (MCT). As shown in Figure 3, we use a two-stream transformer to process the textual and visual information simultaneously, and modify the standard query-conditioned key-value attention mechanism [25] to develop a multimodal co-attentional transformer module. The queries from each modality are passed to the other modalityâ€™s multi-headed attention block, and consequentially this transformer layer produces image-enhanced textual features and text-enhanced visual features.
MCT between Textual Features and Visual Entities.After obtaining the visual entities ğ‘½ ğ‘¬ = [ğ‘·ğ‘‰ , ğ‘³ğ‘‰ , ğ‘ªğ‘‰ ], we employ pretrained BERT to obtain their embeddings ğ‘¯ğ‘‰ ğ¸ . And thus, the textual features and visual entitiesâ€™ embeddings could be fused in similar BERT-constructed feature spaces, alleviating the problem of multimodal feature heterogeneity. The aligned words and visual entities usually reflect the key elements of the news, and thus we use the multimodal co-attention transformer to fuse these features. Specifically, we feed the textual features ğ‘¯ğ‘‡ and the visual entities features ğ‘¯ğ‘‰ ğ¸ into the first co-attention transformer in Figure 2, obtaining the textual representation enhanced by visual entities

ğ‘¯ğ‘‡ â†ğ‘‰ ğ¸ and text-enhanced visual entities representation ğ‘¯ğ‘‰ ğ¸â†ğ‘‡ . We apply the average operation on the latter and then obtain the final representation of visual entities ğ’™ğ‘£ğ‘’ .
MCT between Textual Features and Visual CNN Features. Visual entities focus on the local high-level semantics of the images, while ignoring the global low-level visual features. As a supplement, we use the multimodal co-attention transformer to model the correlations between textual features and visual CNN features. Specifically, we feed ğ‘¯ğ‘‡ â†ğ‘‰ ğ¸ and the visual CNN features ğ‘¯ğ‘‰ into the second co-attention transformer, obtaining the textual representation enhanced by both visual entities and visual CNN features ğ‘¯ğ‘‡ â†(ğ‘‰ ğ¸,ğ‘‰ ) and text-enhanced visual representation ğ‘¯ğ‘‰ â†ğ‘‡ . We apply the average operation on the above features to obtain the final representation of the text and image, that is ğ’™ğ‘¡ and ğ’™ğ‘£, respectively.

3.3.3 Entity Inconsistency Measurement. Multimodal entity inconsistency is a potential indicator for multimodal fake news. For example, if the person mentioned in the text is inconsistent with the recognized celebrity in the image, this news post may be fake with misused images (see Figure 1(a)). Motivated by MÃ¼ller-Budack et al. [16], we measure the multimodal entity inconsistency of person, location, and a more general event context. There are two challenges for this measurement: the first one is the heterogeneity of textual and visual features. Unlike previous works that calculate the multimodal similarity in transformed [29] or visual feature spaces[16], we calculate the similarity of multimodal entities in textual feature space based on their word embeddings. Second, news text usually contains more entities and information than the companying images, and thus some textual entities could be without the aligned visual entities. Considering that fake news commonly tampers only one entity type to maintain credibility, we consider the multimodal news as entity inconsistent only when there are no aligned multimodal entities.
Taking person entity as an example, we define the cross-modal person similarity as the maximum similarity among all pairs of textual and visual person entities. Since neural networks have inevitable errors when detecting visual entities, the confidence is considered when computing the similarity. Formally, we define ğ’• and ğ’— as the feature vectors of the textual and visual entities. For a news post with ğ‘»ğ‘ and ğ‘½ğ‘ , we calculate the cross-modal person similarity as

ğ‘

âˆ‘ï¸

ğ’• Â·ğ’—

= max( ğœŒ (ğ’—)

),

(2)

ğ‘¥ğ‘ 
ğ’• âˆˆğ‘»ğ‘

âˆ¥ğ’• âˆ¥âˆ¥ğ’—âˆ¥

ğ’— âˆˆğ‘½ğ‘

where ğœŒ (ğ’—) represents the probability of visual entity ğ’—. For news

that lacks textual or visual entities, we set the similarity as 1 to

indicate no effective clue about multimodal inconsistency for fake

news detection. Similarly, we compute the cross-modal location

similarity

ğ‘™
ğ‘¥ğ‘ 

and

context

similarity

ğ‘¥ğ‘ ğ‘ ,

and

then

concatenate

them

to form the entity consistency feature ğ’™ğ‘  = [ğ‘¥ğ‘ ğ‘, ğ‘¥ğ‘ ğ‘™ , ğ‘¥ğ‘ ğ‘ ].

Finally, we concatenate the final representation of the text ğ’™ğ‘¡ ,

that of visual entities ğ’™ğ‘£ğ‘’ , that of the image ğ’™ğ‘£, and the multimodal

entity consistency feature ğ’™ğ‘  to obtain the final multimodal repre-

sentation as

ğ’™ğ‘š = concat(ğ’™ğ‘¡ , ğ’™ğ‘£ğ‘’, ğ’™ğ‘£, ğ’™ğ‘  ).

(3)

3.4 Classification

Till now, we have obtained the final multimodal representation ğ’™ğ‘š,

which models the input multimodal news from multiple perspec-

tives. We use a fully connected layer with softmax activation to

project the multimodal feature vector ğ’™ğ‘š into the target space of

two classes: real and fake news, and gain the probability distribu-

tions:

ğ’‘ = softmax(ğ‘¾ğ’™ğ‘š + ğ’ƒ),

(4)

where ğ’‘ = [ğ‘0, ğ‘1] is the predicted probability vector with ğ‘0 and ğ‘1 indicate the predicted probability of label being 0 (real news) and 1 (fake news), respectively. ğ‘¾ is the weight matrix and ğ’ƒ is the
bias term. Thus, for each news post, the goal is to minimize the
binary cross-entropy loss function as follows,

Lğ‘ = âˆ’[ğ‘¦ log ğ‘0 + (1 âˆ’ ğ‘¦) log ğ‘1],

(5)

where ğ‘¦ âˆˆ {0, 1} denotes the ground-truth label.

4 EXPERIMENTS
In this section, we conduct experiments to evaluate the effectiveness of the proposed EM-FEND. Specifically, we aim to answer the following evaluation questions:
â€¢ EQ1: Can EM-FEND improve the classification performance of distinguishing multimodal fake and real news?
â€¢ EQ2: How effective are various visual features (especially the visual entities) and cross-modal correlations in improving the performance of EM-FEND?
â€¢ EQ3: How does EM-FEND perform in online fake news detection?

4.1 Datasets
To prove the generalization of the proposed EM-FEND, we conduct experiments on two real-world datasets of different languages.
4.1.1 Chinese Dataset. The Chinese dataset is constructed on the Chinese Sina Weibo microblogging platform by Jin et al. [9] and has been broadly used in existing works [7, 23, 26]. The fake news posts are verified by the official rumor debunking website of Weibo5, which serves as a reputable source to collect fake news posts in literature. The real news posts are collected from Weibo during the same period as the fake news and are verified by Xinhua News Agency, an authoritative news agency in China. This dataset has been preprocessed to ensure that each post corresponds to an image. In total, this dataset includes 4,749 fake news posts and 4,779 real news posts with corresponding images.
4.1.2 English Dataset. The English dataset is proposed by Yang et al. [30]. The fake news is crawled from news websites that are manually assessed as low credibility6. And the real news is crawled from well-known authoritative news websites such as the New York Times. After removing text-only news, non-English news, and news with unavailable images, we obtain 2,844 fake news articles and 2,825 real news articles, each corresponding to an image.
To prevent the model from overfitting on event topics, we first use the K-means algorithm to find the common events and split the data into training, validation and testing sets based on these
5 https://service.account.weibo.com 6 https://www.kaggle.com/mrisdal/fake-news

event clusters to ensure that there is no event overlap among these sets [26]. The training, validation, and testing sets contain data approximately with a ratio of 3:1:1. We use the Accuracy (Acc.) and Precision (Prec.), Recall and F1 score of the fake-news class as evaluation metrics.
4.2 Implementation Details
We use the pre-trained BERT models7 (i.e., bert-base-chinese and bert-base-uncased) to obtain the textual representation. The maximum sequence length is 256 for both datasets. For models that are not based on BERT, we use publicly available Word2Vec models89 to obtain the word embeddings. For detecting textual entities, we use public API10 and the open-sourced library Spacy11 for Chinese and English news, respectively. In the co-attention transformer block, we employ 8 heads and the hidden size is set as 256 and 128 for EM-FEND and EM-FEND-base, respectively. The hidden size of LSTM in the EM-FEND-base is 128. We use a batch size of 64 instances in the training process. The model is trained for 100 epochs with early stopping to prevent overfitting. We use ReLU as the non-linear activation function and use Adam[10] algorithm to optimize the loss function. The dropout rate is set as 0.3.
4.3 Comparison Methods
To validate the effectiveness of the proposed EM-FEND framework, we compare it with several representative methods including singlemodality and multimodal methods as follows: Single-modality Methods
â€¢ Bi-LSTM: uses a network based on the bidirectional LSTM to classify the given piece of news.
â€¢ BERT: uses a pre-trained BERT to obtain the representation of the given piece of news and a fully connected layer to make classifications.
â€¢ VGG19: fine-tunes VGG19 to model news images for classifications.
Multimodal Methods
â€¢ attRNN- [9]: proposes an innovative RNN with an attention mechanism for effectively fusing multimodal features. In detail, it produces the joint features of text and social context by an LSTM network and fuses them with visual features by utilizing the neural-level attention from the outputs of the LSTM. For a fair comparison, we remove the part dealing with social context features.
â€¢ MVAE [7]: utilizes a multimodal variational autoencoder trained jointly with a fake news detector to learn a shared representation of multimodal content for fake news detection. It is composed of textual and visual encoders and corresponding decoders, and a fake news detector.
â€¢ MKN [32]: retrieves concepts of textual entities from external knowledge graphs and proposes a multi-channel wordknowledge-visual-aligned CNN for fusing multimodal information. The original model MKEMN uses an event memory
7 https://github.com/google-research/bert 8 https://ai.tencent.com/ailab/nlp/en/embedding.html 9 https://github.com/mmihaltz/word2vec-GoogleNews-vectors 10 https://ai.baidu.com/tech/nlp_basic/lexical 11 https://spacy.io/

Table 2: Performance comparison for multimodal fake news detection on two real-world datasets.

Chinese

Methods
Bi-LSTM BERT VGG19 attRNN-[9] MVAE[7] MKN[32] SAFE[34] EM-FEND-base (Ours) SpotFake[23] CARMN [24] EM-FEND (Ours) Bi-LSTM BERT VGG19 attRNN-[9] MVAE[7] MKN[32] SAFE[34] EM-FEND-base (Ours) SpotFake[23] CARMN [24] EM-FEND (Ours)

Acc. 0.785 0.830 0.730 0.808 0.797 0.805 0.790 0.852 0.852 0.865
0.904 0.864 0.873 0.773 0.872 0.879 0.889 0.909 0.943 0.899 0.937
0.975

Prec. 0.851
0.977 0.789 0.882 0.827 0.865 0.886 0.841 0.854 0.933 0.897 0.877 0.869 0.783 0.861 0.902 0.846 0.922 0.926 0.879 0.934
0.978

Recall 0.692 0.675 0.626 0.711 0.751 0.722 0.665 0.853 0.850 0.774
0.904 0.843 0.875 0.747 0.882 0.848 0.929 0.890 0.961 0.923 0.940
0.973

F1 0.763 0.798 0.698 0.787 0.787 0.787 0.760 0.847 0.852 0.846
0.901 0.859 0.872 0.764 0.871 0.874 0.886 0.906 0.943 0.901 0.937
0.975

English

network to detect fake news events. Because we focus on detecting fake news at the post level, we use the building block MKN of MKEMN, which deals with fake news posts, as a compared method. â€¢ SAFE [34]: translates the input image into a sentence, and computes the multimodal relevance based on the sentence similarity as the auxiliary loss for the fake news classification. â€¢ SpotFake [23]: concatenates the textual and visual features obtained from pre-trained BERT and VGG19 respectively for classification. â€¢ CARMN [24]: proposes a cross-modal attention residual network to fuse multimodal features. We use the pre-trained BERT to obtain the textual representation.
Considering that using pre-trained language models to extract textual features usually improves the detection performance of models even without significant changes on the model structure [6], we design a reduced variant of the proposed EM-FEND model to ensure the fairness of comparisons.
â€¢ EM-FEND-base: uses a Bi-LSTM with pre-trained Word2Vec models to replace BERT in EM-FEND when obtaining the textual features. The embeddings of textual and visual entities are also obtained by pre-trained Word2Vec models.
4.4 Performance Comparison (EQ1)
We compare EM-FEND with representative methods introduced in Section 4.3. The results are presented in Table 2, from which we can draw the following observations:

English Chinese

Table 3: Ablation study on various visual features.

Methods EM-FEND w/o visual entities w/o OCR text w/o FT VGG feature EM-FEND w/o visual entities w/o OCR text w/o FT VGG feature

Acc.
0.904 0.886 0.882 0.773
0.975 0.953 0.970 0.970

Prec. 0.897
0.930 0.902 0.783
0.978 0.954 0.967 0.954

Recall
0.904 0.823 0.845 0.747
0.973 0.950 0.972 0.988

F1
0.901 0.873 0.873 0.764
0.975 0.952 0.969 0.971

â€¢ EM-FEND is much better than other methods on both datasets, no matter whether or not to adopt BERT as the textual feature extractor. It validates that EM-FEND can effectively capture important multimodal clues that existing works ignore to detect fake news. Specifically, EM-FEND and EM-FEND-base outperform the corresponding state-of-the-art methods by at least 3.8 and 3.4 percentage points in accuracy, respectively.
â€¢ Methods based on textual modality are better than the visual modality, proving that the text provides more rich clues than images. Multimodal methods are generally better than methods based on single-modality, indicating the complementarity of multimodal features.
â€¢ Pre-trained language models (i.e., BERT) can improve the performance of our method. It is mainly due to the strong ability of transformers in modeling context and the abundant knowledge injected in the pre-trained models.
4.5 Ablation Study (EQ2)
We design two groups of ablation experiments to evaluate the effectiveness of different components in EM-FEND. Specifically, we design several internal models for comparison, which are simplified variations of EM-FEND with certain visual features removed:
â€¢ w/o visual entities: EM-FEND without the visual entities extraction, and the following co-attention transformer between textual features and visual entities and entity inconsistency measurement module.
â€¢ w/o OCR text: EM-FEND without the OCR text. â€¢ w/o fine-tuned (FT) VGG feature: We extract visual features
from pre-trained VGG19 without fine-tuning.
Similarly, we design the following variants of EM-FEND to prove the effectiveness of different cross-modal correlations:
â€¢ w/o co-attention-ve: EM-FEND without the co-attention transformer between textual features and visual entities.
â€¢ w/o co-attention-vf: EM-FEND without the co-attention transformer between textual and visual CNN features.
â€¢ w/o entity inconsistency measurement: EM-FEND without the entity inconsistency measurement module.
The results of the ablation study are reported in Table 3 and Table 4. We have the following observations:
1) Visual Features: All of these three visual features are important for fake news detection. However, the most important visual features on these two datasets are different: fine-tuned VGG features in the Chinese dataset and visual entities in the English dataset.

English Chinese
True Positive Rate

Table 4: Ablation study on various cross-modal correlations.

Methods EM-FEND w/o entity consistency w/o co-attention-ve w/o co-attention-vf EM-FEND w/o entity consistency w/o co-attention-ve w/o co-attention-vf

Acc.
0.904 0.899 0.890 0.886
0.975 0.962 0.959 0.930

Prec. 0.897
0.932 0.914 0.901
0.978 0.977 0.953 0.937

Recall
0.904 0.849 0.851 0.855
0.973 0.945 0.966 0.920

F1
0.901 0.889 0.881 0.878
0.975 0.961 0.959 0.928

This phenomenon results from the differences in data sources between these two datasets. The Chinese dataset is collected from the social media platform, and thus the multimodal fake news is more likely to show characteristics of low image quality brought by wide propagation. Differently, the English dataset originates from the formal news websites, of which the news has high-quality and informative images. Thus, the high-level visual semantic features are more important than low-level visual features for detecting this kind of multimodal fake news. This phenomenon also proves the generalization ability of EM-FEND in detecting different types of multimodal fake news.
2) Cross-modal Correlations: Other than visual features, the various cross-modal correlations are also important for achieving the best performance of EM-FEND. If we remove one of them, the performance will drop by a certain degree. Specifically, i) the accuracy is lower than the complete model by at least 1.4 percentage points in accuracy when we replace the single co-attention transformer module with the average operation, proving that the co-attention transformer can effectively fuse multimodal features by capturing the multimodal alignment; ii) The influence of entity consistency is smaller than other cross-modal correlations, probably due to the sparsity of visual entities and the noises brought by entity detectors.
4.6 Robustness to Imbalanced Online Data
(EQ3)
In real-world scenarios, the number of fake news is much lower than real news, which means that the online news data that needs to be detected is unbalanced. We collect news from an online fake news detection system like [33] during 9 months. After removing news posts without text or images and duplicated posts, we obtain 217 multimodal fake news posts and 3353 real news posts annotated by experts, with a ratio of 1:15 approximately. It is worth noting that itâ€™s more difficult to distinguish these fake and real news than distinguishing that in datasets used in Section 4.1, because these real news posts originate from suspicious news and usually show typical patterns of fake news.
To evaluate the robustness of EM-FEND to imbalanced online data, we compare EM-FEND with CARMN [24], the best competitor to EM-FEND (Table 2), in the imbalanced dataset. Figure 4 shows the ROC curves of these two models, from which we observe that EM-FEND outperforms CARMN in online data.

1.0 0.8 0.6 0.4 0.2 0.0
0.0

ROC Curve

CARMN (AUC= 0.696) EM-FEND (AUC= 0.843)

0.2

0.4

0.6

0.8

1.0

False Positive Rate

Figure 4: ROC curves of EM-FEND and CARMN.

4.7 Case Study
In this part, we show some cases to intuitively show the behaviors of entity inconsistency measurement module in EM-FEND. Specifically, we list several representative multimodal fake news that are measured as low person consistency in Figure 5. It shows that this module can effectively measure the multimodal entity inconsistency as easily understanding explanations for the modelâ€™s decisions about fake news.

Dennis

Wenwen Song

Yuxi Zhou, Yuhan Zhou

Paul Walker is still alive! awarded â€œMoved China Ten Characters in 2013 â€œ for reporting six senior dd

Hongxia Zhao was awarded â€œMoved China Ten Characters in 2013 â€œ for reporting six senior officials in Chongqing.

Twins Yuqing Sun and Yuting Sun lost last Monday. Please contact the police if you find them!

Figure 5: Some fake news with low multimodal person consistency. In these cases, the person entity mentioned in the text is inconsistent with that recognized in the image.

5 CONCLUSION
In this paper, we find three valuable cross-modal correlations in multimodal fake news on social media, that is entity inconsistency, mutual enhancement and text complementation, which provides diverse multimodal clues. Also, we reveal the importance of visual entities in understanding news-related visual semantics and capturing these multimodal clues. Accordingly, we propose a novel entity-enhanced multimodal fusion framework named EM-FEND to simultaneously model three cross-modal correlations. Extensive experiments have proved the effectiveness of EM-FEND.
ACKNOWLEDGMENTS
This work was supported by the National Key Research and Development Program of China (2017YFC0820604), and the National Natural Science Foundation of China (U1703261, 62172420).

REFERENCES
[1] Christina Boididou, Katerina Andreadou, Symeon Papadopoulos, Duc-Tien DangNguyen, Giulia Boato, Michael Riegler, Yiannis Kompatsiaris, et al. 2015. Verifying Multimedia Use at MediaEval 2015. In Working Notes Proceedings of the MediaEval 2015 Workshop.
[2] Christina Boididou, Symeon Papadopoulos, Duc-Tien Dang-Nguyen, Giulia Boato, Michael Riegler, Stuart E. Middleton, Andreas Petlund, Yiannis Kompatsiaris, et al. 2016. Verifying Multimedia Use at MediaEval 2016. In Working Notes Proceedings of the MediaEval 2016 Workshop.
[3] Juan Cao, Peng Qi, Qiang Sheng, Tianyun Yang, Junbo Guo, and Jintao Li. 2020. Exploring the Role of Visual Content in Fake News Detection. Disinformation, Misinformation, and Fake News in Social Media (2020), 141â€“161.
[4] Carlos Castillo, Marcelo Mendoza, and Barbara Poblete. 2011. Information Credibility on Twitter. In Proceedings of the 20th International Conference on World Wide Web. 675â€“684.
[5] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. ImageNet: A large-scale Hierarchical Image Database. In 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. 248â€“255.
[6] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In
Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 4171â€“4186. [7] Khattar Dhruv, Goud Jaipal Singh, Gupta Manish, and Varma Vasudeva. 2019. MVAE: Multimodal Variational Autoencoder for Fake News Detection. In The World Wide Web Conference. 2915â€“2921. [8] Bin Guo, Yasan Ding, Lina Yao, Yunji Liang, and Zhiwen Yu. 2020. The Future of False Information Detection on Social Media: New Perspectives and Trends. Comput. Surveys 53, 4 (2020), 1â€“36. [9] Zhiwei Jin, Juan Cao, Han Guo, Yongdong Zhang, and Jiebo Luo. 2017. Multimodal Fusion with Recurrent Neural Networks for Rumor Detection on Microblogs. In Proceedings of the 25th ACM International Conference on Multimedia. 795â€“816. [10] Diederik P Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In 3rd International Conference on Learning Representations. [11] Srijan Kumar and Neil Shah. 2018. False Information on Web and Social Media: A Survey. arXiv preprint arXiv:1804.08559 (2018). [12] Peiguang Li, Xian Sun, Hongfeng Yu, Yu Tian, Fanglong Yao, and Guangluan Xu. 2021. Entity-Oriented Multi-Modal Alignment and Fusion Network for Fake News Detection. IEEE Transactions on Multimedia (2021). [13] Jiasen Lu, Dhruv Batra, Devi Parikh, and Stefan Lee. 2019. ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks. In Advances in Neural Information Processing Systems. 13â€“23. [14] Jiasen Lu, Jianwei Yang, Dhruv Batra, and Devi Parikh. 2016. Hierarchical Question-Image Co-Attention for Visual Question Answering. In Proceedings of the 30th International Conference on Neural Information Processing Systems. 289â€“297. [15] Jing Ma, Wei Gao, Prasenjit Mitra, Sejeong Kwon, Bernard J Jansen, Kam-Fai Wong, and Meeyoung Cha. 2016. Detecting Rumors from Microblogs with Recurrent Neural Networks. In Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence. 3818â€“3824. [16] Eric MÃ¼ller-Budack, Jonas Theiner, Sebastian Diering, Maximilian Idahl, and Ralph Ewerth. 2020. Multimodal Analytics for Real-world News Using Measures of Cross-modal Entity Consistency. In Proceedings of the 2020 International Conference on Multimedia Retrieval. 16â€“25. [17] David Nadeau and Satoshi Sekine. 2007. A Survey of Named Entity Recognition and Classification. Lingvisticae Investigationes 30, 1 (2007), 3â€“26. [18] VerÃ³nica PÃ©rez-Rosas, Bennett Kleinberg, Alexandra Lefevre, and Rada Mihalcea. 2018. Automatic Detection of Fake News. In Proceedings of the 27th International Conference on Computational Linguistics. 3391â€“3401.

[19] Vahed Qazvinian, Emily Rosengren, Dragomir Radev, and Qiaozhu Mei. 2011. Rumor has it: Identifying Misinformation in Microblogs. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing. 1589â€“1599.
[20] Peng Qi, Juan Cao, Tianyun Yang, Junbo Guo, and Jintao Li. 2019. Exploiting Multi-domain Visual Information for Fake News Detection. In IEEE International Conference on Data Mining. 518â€“527.
[21] Kai Shu, Amy Sliva, Suhang Wang, Jiliang Tang, and Huan Liu. 2017. Fake News Detection on Social Media: A Data Mining Perspective. ACM SIGKDD Explorations Newsletter 19, 1 (2017), 22â€“36.
[22] Karen Simonyan and Andrew Zisserman. 2015. Very Deep Convolutional Networks for Large-Scale Image Recognition. In 3rd International Conference on Learning Representations.
[23] Shivangi Singhal, Rajiv Ratn Shah, Tanmoy Chakraborty, Ponnurangam Kumaraguru, and Shinâ€™ichi Satoh. 2019. SpotFake: A Multi-modal Framework for Fake News Detection. In Fifth IEEE International Conference on Multimedia Big Data. 39â€“47.
[24] Chenguang Song, Nianwen Ning, Yunlei Zhang, and Bin Wu. 2021. A Multimodal Fake News Detection Model Based on Crossmodal Attention Residual and Multichannel Convolutional Neural Networks. Information Processing & Management 58, 1 (2021), 102437.
[25] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Åukasz Kaiser, and Illia Polosukhin. 2017. Attention Is All You Need. In Advances in Neural Information Processing Systems. 5998â€“6008.
[26] Yaqing Wang, Fenglong Ma, Zhiwei Jin, Ye Yuan, Guangxu Xun, Kishlay Jha, Lu Su, and Jing Gao. 2018. EANN: Event Adversarial Neural Networks for MultiModal Fake News Detection. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 849â€“857.
[27] Yaqing Wang, Fenglong Ma, Haoyu Wang, Kishlay Jha, and Jing Gao. 2021. Multimodal Emergent Fake News Detection via Meta Neural Process Networks. In
Proceedings of the 27th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. [28] Youze Wang, Shengsheng Qian, Jun Hu, Quan Fang, and Changsheng Xu. 2020. Fake News Detection via Knowledge-Driven Multimodal Graph Convolutional Networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval. 540â€“547. [29] Junxiao Xue, Yabo Wang, Yichen Tian, Yafei Li, Lei Shi, and Lin Wei. 2021. Detecting Fake News by Exploring the Consistency of Multimodal Data. Information Processing and Management 58, 5 (2021), 102610. [30] Yang Yang, Lei Zheng, Jiawei Zhang, Qingcai Cui, Zhoujun Li, and Philip S Yu. 2018. TI-CNN: Convolutional Neural Networks for Fake News Detection. arXiv preprint arXiv:1806.00749 (2018). [31] Reza Zafarani, Xinyi Zhou, Kai Shu, and Huan Liu. 2019. Fake News Research: Theories, Detection Strategies, and Open Problems. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 3207â€“3208. [32] Huaiwen Zhang, Quan Fang, Shengsheng Qian, and Changsheng Xu. 2019. Multimodal Knowledge-aware Event Memory Network for Social Media Rumor Detection. In Proceedings of the 27th ACM International Conference on Multimedia. 1942â€“1951. [33] Xing Zhou, Juan Cao, Zhiwei Jin, Fei Xie, Yu Su, Dafeng Chu, Xuehui Cao, and Junqiang Zhang. 2015. Real-time News Certification System on Sina Weibo. In Proceedings of the 24th International Conference on World Wide Web. 983â€“988. [34] Xinyi Zhou, Jindi Wu, and Reza Zafarani. 2020. SAFE: Similarity-Aware Multimodal Fake News Detection. In Pacific-Asia Conference on Knowledge Discovery and Data Mining. 354â€“367. [35] Arkaitz Zubiaga, Ahmet Aker, Kalina Bontcheva, Maria Liakata, and Rob Procter. 2018. Detection and Resolution of Rumours in Social Media: A Survey. Comput. Surveys 51, 2 (2018), 32.
,

